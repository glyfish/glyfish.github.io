---
title: Metropolis Hastings Sampling
key: 20180721
image: /assets/posts/metropolis_hastings_sampling/norma_proposal_acceptance.png
author: Troy Stribling
permlink: /metropolis_hastings_sampling.html
comments: false
---

[Metropolis Hastings Sampling](https://en.wikipedia.org/wiki/Metropolisâ€“Hastings_algorithm) is a method for obtaining samples for known target
probability distribution using samples from some other proposal distribution. It is similar to
[Rejection Sampling]({{ site.baseurl }}{% link _posts/2018-07-29-rejection_sampling.md %}) in providing a
criteria for acceptance of a proposal sample as a target sample but instead of discarding the
samples that do not meet the acceptance criteria the sample
from the previous time step is replicated. Another difference is that Metropolis Hastings samples are modeled as a [Markov Chain](https://en.wikipedia.org/wiki/Markov_chain) where the target distribution
is the [Markov Chain Equilibrium Distribution]({{ site.baseurl }}{% link _posts/2018-08-16-continuous_state_markov_chain_equilibrium.md %}). As a consequence
the previous sample is used as part of the acceptance criteria when generating the next sample.
It will be seen this has the advantage of permitting dynamical adjustment of some proposal distribution
parameters as each sample is generated, which in effect eliminates parameters as model inputs.  
This is is an improvement over Rejection Sampling, where it was
[previously shown]({{ site.baseurl }}{% link _posts/2018-07-29-rejection_sampling.md %}) that
slight variations in proposal distribution parameters can significantly impact performance.
A downside of the Markov Chain representation is that
[autocorrelation]({{ site.baseurl }}{% link _posts/2018-08-25-discrete_cross_correlation_theorem.md %}) can develop in the samples
which is not the case in Rejection Sampling.

<!--more-->

## Algorithm

The [Metropolis Sampling Algorithm](https://www.google.com/search?hl=en&source=hp&ei=O-CGW-qAIMWosgXf9ofQDA&q=Equation+of+state+calculations+by+fast+computing+machines&oq=Equation+of+state+calculations+by+fast+computing+machines&gs_l=psy-ab.3..35i39k1j0i22i30k1l2.1983.1983.0.2488.3.2.0.0.0.0.91.91.1.2.0....0...1.2.64.psy-ab..1.2.180.6...89.Y99UmLWMZD0) was
originally developed by physicist studying simulations of equation of state at the dawn of the computer age.
It is the first a a class of sampling algorithms referred to a [Monte Carlo Markov Chain](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo).
A couple of decades later the algorithm was generalized and given a firmer theoretical foundation becoming the [Metropolis Hastings Sampling Algorithm](https://www.google.com/search?client=safari&rls=en&ei=Xt-GW5GyLOWwtgX38az4Dg&q=Monte+Carlo+Sampling+Methods+Using+Markov+Chains&oq=Monte+Carlo+Sampling+Methods+Using+Markov+Chains&gs_l=psy-ab.3..0j0i22i30k1l2.79402.79402.0.79877.1.1.0.0.0.0.95.95.1.1.0....0...1.2.64.psy-ab..0.1.95....0.99vsUPrnsUQ).
After a few more decades this work became widely used in simulating [Bayesian Posterior Distributions](https://en.wikipedia.org/wiki/Posterior_probability)
in Probabilistic Programming DSLs such as [`pymc`](https://en.wikipedia.org/wiki/PyMC3). This section provides an overview of the algorithm
to motivate details of the theory and examples discussed in following sections.

Let {% katex %}f(y){% endkatex %} denote the target distribution. The algorithm constructs a Markov Chain with
[equilibrium distribution]({{ site.baseurl }}{% link _posts/2018-08-16-continuous_state_markov_chain_equilibrium.md %}),
{% katex %}\pi_{E}{% endkatex %}, such that,

{% katex display %}
f(y) = \pi_{E}(y).
{% endkatex %}

The equilibrium [stochastic kernel]({{ site.baseurl }}{% link _posts/2018-08-16-continuous_state_markov_chain_equilibrium.md %}),
{% katex %}p(x,y){% endkatex %} for the Markov Chain must satisfy,

{% katex display %}
\pi_{E}(y) = \int_{-\infty}^{\infty} p(x, y) \pi_{E}(x) dx\ \ \ \ \ (1).
{% endkatex %}

To generate samples for {% katex %}p(x, y){% endkatex %} samples from a proposal Markov Chain with stochastic kernel {% katex %}q(x, y){% endkatex %}
are produced. Let {% katex %}x{% endkatex %} denote the state of the {% katex %}p(x, y){% endkatex %} Markov Chain at the previous
time step, {% katex %}t-1{% endkatex %} and {% katex %}y{% endkatex %} represent the yet to be determined state at time
{% katex %}t{% endkatex %}. Consider a proposal sample, {% katex %}y^{\ast}{% endkatex %}, generated by {% katex %}q(x, y){% endkatex %}.
Define an acceptance function, {% katex %}\alpha(x, y^{\ast}){% endkatex %}, that satisfies,

{% katex display %}
0\ \leq\ \alpha(x, y^{\ast})\ \leq 1\ \ \ \ \ (2),
{% endkatex %}

and an *acceptance* random variable, {% katex %}U{% endkatex %}, with distribution
{% katex %}\textbf{Uniform}(0,\ 1){% endkatex %}
independent of {% katex %}y^{\ast}{% endkatex %}. Now, if the following inequality is satisfied,

{% katex display %}
U\ \leq\ \alpha(x, y^{\ast}),
{% endkatex %}

*accept* the proposed sample, {% katex %}y=y^{\ast}{% endkatex %}, as a sample of {% katex %}p(x, y){% endkatex %}. If the inequality
is not satisfied then *reject* the sample by replicating the state from the previous time step, {% katex %}y=x{% endkatex %}.

It will be shown that,

{% katex display %}
\alpha(x, y) = \text{min}\left\{\frac{f(y)q(y,x)}{f(x)q(x,y)}, 1\right\}\ \ \ \ \ (3).
{% endkatex %}

The algorithm can be summarized by the following steps that are repeated for each sample.

1. Generate samples of {% katex %}y^{\ast}{% endkatex %} conditioned on {% katex %}x{% endkatex %}
and independently generate samples of {% katex %}U{% endkatex %}.
2. If {% katex %}U\ \leq\ \alpha(x, y^{\ast}){% endkatex %} then {% katex %}y = y^{\ast}{% endkatex %}.
3. If {% katex %}U\ >\ \alpha(x, y^{\ast}){% endkatex %} then {% katex %}y = x{% endkatex %}.

This is similar to [Rejection Sampling]({{ site.baseurl }}{% link _posts/2018-07-29-rejection_sampling.md %}) with a more complex acceptance function and different rejection procedure but the implementation
remains simple.

## Theory

Metropolis Hastings Sampling has a simple implementation but the theory that provides
validation of the algorithm is more complicated than required for both
[Rejection Sampling]({{ site.baseurl }}{% link _posts/2018-07-29-rejection_sampling.md %}) and
[Inverse CDF Sampling]({{ site.baseurl }}{% link _posts/2018-07-21-inverse_cdf_sampling.md %}).
Here the proof that the algorithm produces the desired result is accomplished in four steps.
The first will show that distributions and stochastic kernels that satisfy Time Reversal Symmetry,
also referred to as Detailed Balance, are equilibrium solutions that satisfy equation
{% katex %}(1).{% endkatex %} Next, the stochastic kernel resulting from the algorithm is derived
and followed by a proof that a distribution that satisfies Time Reversal Symmetry with the resulting
stochastic kernel is a solution to equation {% katex %}(1){% endkatex %}. Finally, the
expression for {% katex %}\alpha(x,y){% endkatex %} from equation {% katex %}(3){% endkatex %} will
be derived.

### Time Reversal Symmetry

Consider a stochastic kernel {% katex %}p(x,y){% endkatex %} and distribution {% katex %}\pi_(y){% endkatex %}
where {% katex %}x{% endkatex %} is the state of the Markov Chain generated by the kernel at
{% katex %}t-1{% endkatex %} and {% katex %}y{% endkatex %} the
state at time {% katex %}t{% endkatex %}. Consider a chain of {% katex %}N{% endkatex %} steps.
The expected number of transitions from {% katex %}x{% endkatex %} to {% katex %}y{% endkatex %} will satisfy,

{% katex display %}
N_{y}=N \pi_(y) p(x, y).
{% endkatex %}

It follows that the rate of transition from {% katex %}x{% endkatex %} to {% katex %}y{% endkatex %} is
given by {% katex %}\pi(y) p(x,y){% endkatex %}. The transition rate for the Markov Chain obtained by
reversing time, that is the chain transitions from {% katex %}y{% endkatex %} to {% katex %}x{% endkatex %}
will be {% katex %}\pi(x) p(y, x){% endkatex %}.

Time Reversal Symmetry implies that the transition rate for the time reversed Markov Chain is the same as the
forward time chain, namely,

{% katex display %}
\pi(y) p(x, y) = \pi_(x) p(y,x)\ \ \ \ \ (3).
{% endkatex %}

If Time Reversal Symmetry is assumed it follows that,

{% katex display %}
\begin{aligned}
\int_{-\infty}^{\infty} p(x, y) \pi(x) dx &= \int_{-\infty}^{\infty} p(y, x) \pi(y) dx \\
&= \pi(y) \int_{-\infty}^{\infty} p(y, x) dx \\
&= \pi (y),
\end{aligned}
{% endkatex %}

where the last step is a result of the definition of a stochastic kernel,
{% katex %}\int_{-\infty}^{\infty} p(y, x) dx = 1{% endkatex %}. This any distribution and kernel satisfying
equation {% katex %}(3){% endkatex %} is an equilibrium solution since it will also satisfy
equation {% katex %}(1){% endkatex %}

### Stochastic Kernel

In a [previous post]({{ site.baseurl }}{% link _posts/2018-07-29-rejection_sampling.md %}) it was shown
that a stochastic kernel can be interpreted as probability density conditioned of the state
at the previous time step,

{% katex display %}
p(x,y) = f(y\mid x).
{% endkatex %}

It follows that the [Cumulative Probability Distribution (CDF)]({{ site.baseurl }}{% link _posts/2018-07-21-inverse_cdf_sampling.md %}) of obtaining a sample {% katex %}y{% endkatex %}
for a given {% katex %}x{% endkatex %} is given by,

{% katex display %}
\begin{aligned}
P\left[ Y\ \leq\ y\ \mid\ X=x \right] &= \int_{-\infty}^{y} f(w\mid x) dw \\
&= \int_{-\infty}^{y} p(x,w) dw.
\end{aligned}
{% endkatex %}

Let {% katex %}U{% endkatex %} represent the {% katex %}\textbf{Uniform}(0, 1){% endkatex %} acceptance
random variable. A proposal sample, {% katex %}y^{\ast}{% endkatex %} conditioned
on {% katex %}x{% endkatex %}, is generated by {% katex %}q(x,y){% endkatex %} independent of
{% katex %}U{% endkatex %} and accepted if,

{% katex display %}
U\ \leq\ \alpha(x, y^{\ast}),
{% endkatex %}

then {% katex %}y=y^{\ast}{% endkatex %}. The proposal is rejected if,

{% katex display %}
U\ >\ \alpha(x, y^{\ast}),
{% endkatex %}

then {% katex %}y=x{% endkatex %}. Now, using the
[Law of Total Probability](https://en.wikipedia.org/wiki/Law_of_total_probability) to condition on
{% katex %}U{% endkatex %} the stochastic kernel CDF becomes,

{% katex display %}
\begin{aligned}
P\left[ Y\ \leq\ y\ \mid\ X=x \right]\ &=\ P\left[Y\ \leq\ y\ \mid\ U\ \leq\ \alpha(x, y^{\ast}),\ X=x \right]\ P\left[U\ \leq\ \alpha(x, y^{\ast})\ \mid\ X=x \right] \\
&\ + P\left[Y\ \leq\ y\ \mid\ U\ >\ \alpha(x, y^{\ast}),\ X=x \right]\ P\left[U\ >\ \alpha(x, y^{\ast})\ \mid\ X=x \right].
\end{aligned}\ \ \ \ \ (4).
{% endkatex %}

The first term is the probability that the proposed sample is accepted and the second term the
probability that it is rejected. Consider the first term where
{% katex %}U\ \leq\ \alpha(x, y^{\ast}){% endkatex %} and {% katex %}y=y^{\ast}{% endkatex %},

{% katex display %}
P\left[Y\ \leq\ y,\ U\ \leq\ \alpha(x, y^{\ast})\ \mid\ X=x \right]\ =\ P\left[Y\ \leq\ y\ \mid\ U\ \leq\ \alpha(x, y^{\ast}),\ X=x \right]\ P\left[U\ \leq\ \alpha(x, y^{\ast})\ \mid\ X=x \right]\ \ \ \ \ (5),
{% endkatex %}

which follows from the definition of
[Conditional Probability](https://en.wikipedia.org/wiki/Conditional_probability).

The algorithm assumes that {% katex %}U{% endkatex %} is independent of {% katex %}y^{\ast}{% endkatex %} conditioned on {% katex %}x{% endkatex %}. It follows that the joint density is
given by,

{% katex display %}
\begin{aligned}
h(y^{\ast}, u\mid x) &= g(u)f(y^{\ast}\mid x) \\
&= q(x, y^{\ast}),
\end{aligned}
{% endkatex %}

where the last step follows by noting that the density of {% katex %}U{% endkatex %} is given by
{% katex %}g(u)=1{% endkatex %}, since {% katex %}\textbf{Uniform}(0,1),{% endkatex %} and the density
of {% katex %}y^{\ast}{% endkatex %} conditioned on {% katex %}x{% endkatex %} is given by the
proposal stochastic kernel {% katex %}f(y^{\ast}\mid x)=q(x, y^{\ast}){% endkatex %}. Using this
result to continue gives the acceptance probability term for the stochastic kernel CDF from
equation {% katex %}(4){% endkatex %},

{% katex display %}
\begin{aligned}
P\left[Y\ \leq\ y,\ U\ \leq\ \alpha(x, y^{\ast})\ \mid\ X=x \right] &= \int_{-\infty}^{y}\int_{0}^{\alpha(x, y^{\ast})} h(y^{\ast}, u\mid x) du dy^{\ast} \\
&= \int_{-\infty}^{y}\int_{0}^{\alpha(x, y^{\ast})} q(x, y^{\ast}) du dy^{\ast} \\
& =  \int_{-\infty}^{y} \alpha(x, y^{\ast}) q(x, y^{\ast}) dy^{\ast}
\end{aligned}\ \ \ \ \ (6).
{% endkatex %}

Next, consider the second term in equation {% katex %}(4){% endkatex %}, which represents the case where
{% katex %}y^{\ast}{% endkatex %} is rejected as a sample of {% katex %}y{% endkatex %}
since {% katex %}y^{\ast}{% endkatex %} is rejected {% katex %}y=x{% endkatex %}.
It follows that any value of {% katex %}y^{\ast}{% endkatex %} is possible so
the integral over {% katex %}y^{\ast}{% endkatex %} needs to be over its entire range. Using the previous
result for the joint density {% katex %}h(y^{\ast}, u\mid x){% endkatex %}. gives

{% katex display %}
\begin{aligned}
P\left[Y\ = x,\ U\ >\ \alpha(x, y^{\ast})\ \mid\ X=x \right] &= \int_{-\infty}^{\infty}\int_{\alpha(x, y^{\ast})}^{1} h(y^{\ast}, u\mid x) du dy^{\ast} \\
&= \int_{-\infty}^{\infty}\int_{\alpha(x, y^{\ast})}^{1} q(x, y^{\ast}) du dy^{\ast} \\
&= \int_{-\infty}^{\infty}\left[ 1-\alpha(x, y^{\ast})\right] q(x, y^{\ast}) dy^{\ast} \\
&= \int_{-\infty}^{\infty}\ q(x, y^{\ast}) dy^{\ast} - \int_{-\infty}^{\infty}\alpha(x, y^{\ast}) q(x, y^{\ast}) dy^{\ast} \\
&= 1 - \int_{-\infty}^{\infty}\alpha(x, y^{\ast}) q(x, y^{\ast}) dy^{\ast}
\end{aligned}\ \ \ \ \ (7)
{% endkatex %}

since {% katex %}\int_{-\infty}^{\infty}\ q(x, y^{\ast}) dy^{\ast}=1{% endkatex %}. Simplify
things by defining the rejection probability density by,

{% katex display %}
f_{R}(x) = 1 - \int_{-\infty}^{\infty}\alpha(x, y) q(x, y) dy\ \ \ \ \ (8).
{% endkatex %}

Equation {% katex %}(7){% endkatex %} needs to be written as an integral over
{% katex %}y{% endkatex %} to continue with the evaluation of equation {% katex %}(5){% endkatex %}. This
is accomplished by use of the [Dirac Delta Function](https://en.wikipedia.org/wiki/Dirac_delta_function)
which is defined by,

{% katex display %}
\int_{-\infty}^{\infty} f(y^{\ast})\delta(y^{\ast}-x) dy^{\ast} = f(x).
{% endkatex %}

If use is made of equation {% katex %}(8){% endkatex %} and the Dirac Delta Function it follows that
equation {% katex %}(7){% endkatex %} becomes,

{% katex display %}
P\left[Y\ \leq\ y,\ U\ >\ \alpha(x, y^{\ast})\ \mid\ X=x \right] = \int_{-\infty}^{y} f_{R}(y^{\ast})\delta(y^{\ast}-x) dy^{\ast}\ \ \ \ \ (9).
{% endkatex %}

The upper range of the limit was changed to conform to the limits of the CDF. This is acceptable
since if {% katex %}y\ <\ x{% endkatex %} the probability of rejection is 0. The Metropolis Hastings
stochastic kernel can now by constructed by assembling the results obtained in
equations {% katex %}(6){% endkatex %} and {% katex %}(9){% endkatex %} and revisiting equation
{% katex %}(5){% endkatex %},

{% katex display %}
\begin{aligned}
\int_{-\infty}^{y} p(x,w) dw & = P\left[ Y\ \leq\ y\ \mid\ X=x \right] \\
&= P\left[Y\ \leq\ y,\ U\ \leq\ \alpha(x, y^{\ast})\ \mid\ X=x \right] + P\left[Y\ \leq\ y,\ U\ >\ \alpha(x, y^{\ast})\ \mid\ X=x \right] \\
&= \int_{-\infty}^{y} \alpha(x, y^{\ast}) q(x, y^{\ast}) dy^{\ast} + \int_{-\infty}^{y} f_{R}(y^{\ast})\delta(y^{\ast}-x) dy^{\ast} \\
&= \int_{-\infty}^{y} \left[ \alpha(x, y^{\ast}) q(x, y^{\ast}) + f_{R}(y^{\ast})\delta(y^{\ast}-x)\right] dy^{\ast}
\end{aligned}
{% endkatex %}

Finally, the desired result is obtained by collecting the terms under a single integration variable,

{% katex display %}
\begin{gathered}
p(x,y) = \alpha(x, y) q(x, y) + f_{R}(y)\delta(y-x) \\
f_{R}(x) = 1 - \int_{-\infty}^{\infty}\alpha(x, y) q(x, y) dy
\end{gathered}\ \ \ \ \ (10)
{% endkatex %}

It is also interesting to verify that the kernel satisfies the stochastic property, namely,

{% katex display %}
\begin{aligned}
\int_{-\infty}^{\infty} p(x,y) dy &= \int_{-\infty}^{\infty}\left[ \alpha(x, y) q(x, y) + f_{R}(y)\delta(y-x)\right] dy \\
&= \int_{-\infty}^{\infty}\alpha(x, y) q(x, y) dy - f_{R}(x) \\
&= \int_{-\infty}^{\infty}\alpha(x, y) q(x, y) dy + 1 - \int_{-\infty}^{\infty}\alpha(x, y) q(x, y) dy \\
&= 1
\end{aligned}
{% endkatex %}

which is the desired result.

### Equilibrium

It can now be shown that the Metropolis Hastings stochastic kernel from equation {% katex %}(10){% endkatex %}
is an equilibrium solution by evaluating the integral from equation {% katex %}(1){% endkatex %} which
defines equilibrium. Additionally, time Reversal Symmetry must also be assumed,

{% katex display %}
\pi(x)\alpha(x,y)q(x,y) = \pi(y)\alpha(y,x)q(y,x)\ \ \ \ \ (11),
{% endkatex %}

where {% katex %}\alpha(x,y){% endkatex %} is the acceptance function from equation
{% katex %}(1){% endkatex %}, {% katex %}q(x,y){% endkatex %} is the stochastic kernel for the
proposal Markov Chain, {% katex %}\pi(y){% endkatex %} is the distribution, {% katex %}y{% endkatex %} is
the state of the target Markov Chain at time step {% katex %}t{% endkatex %} and {% katex %}x{% endkatex %}
the state at time {% katex %}t-1{% endkatex %}.

Now, starting with equation {% katex %}(1){% endkatex %},

{% katex display %}
\begin{aligned}
\int_{-\infty}^{\infty} p(x, y) \pi(x) dx &= \int_{-\infty}^{\infty}\left[ \alpha(x, y) q(x, y) + f_{R}(y)\delta(y-x)\right] \pi(x) dx \\
&= \int_{-\infty}^{\infty}\alpha(x, y) q(x, y) \pi(x) dx + f_{R}(y)\pi(y) \\
&= \int_{-\infty}^{\infty}\alpha(x, y) q(x, y) \pi(x) dx + \left[1 - \int_{-\infty}^{\infty}\alpha(y, w) q(y, w) dw \right]\pi(y) \\
&= \pi(y)+\int_{-\infty}^{\infty}\alpha(x, y) q(x, y) \pi(x) dx - \int_{-\infty}^{\infty}\pi(y)\alpha(y, w) q(y, w) dw \\
&= \pi(y)+\int_{-\infty}^{\infty}\alpha(x, y) q(x, y) \pi(x) dx - \int_{-\infty}^{\infty}\pi(w)\alpha(w, y) q(w, y) dw \\
&= \pi(y),
\end{aligned}
{% endkatex %}

where the last steps follow from substituting equation {% katex %}(11){% endkatex %} into the last term
leading to the desired result.

### Derivation of {% katex %}\alpha(x,y){% endkatex %}

It has been shown that the Metropolis Hastings algorithm generates a Markov Chain with an equilibrium
distribution equal to the target distribution. This has been accomplished by only requiring that
the acceptance function, {% katex %}\alpha(x,y){% endkatex %}, satisfy Time Reversal Symmetry
as specified by equation {% katex %}(11){% endkatex %} without giving and explicit form. Here
an expression for {% katex %}\alpha(x,y){% endkatex %} is derived with the aim of driving arbitrary
proposal Markov Chains toward a states satisfying Time Reversal.

For an arbitrary proposal stochastic kernel, {% katex %}q(x,y){% endkatex %}, Time Reversal Symmetry
will not be satisfied, so either {% katex %}\pi(x)q(x,y)\ >\ \pi(y)q(y,x){% endkatex %} or
{% katex %}\pi(x)q(x,y)\ <\ \pi(y)q(y,x){% endkatex %} will be true. Assume the first condition is valid.
If this is the case transitions from {% katex %}x{% endkatex %} to {% katex %}y{% endkatex %} occur more
frequently than transitions from {% katex %}y{% endkatex %} to {% katex %}x{% endkatex %}. To correct for
the imbalance the number of transitions from {% katex %}x{% endkatex %} to {% katex %}y{% endkatex %} needs
to be decreased and the number of transition from {% katex %}y{% endkatex %} to {% katex %}x{% endkatex %}
increased. This can be accomplished by setting {% katex %}\alpha(y,x)=1{% endkatex %} in equation
{% katex %}(11){% endkatex %} to obtain,

{% katex display %}
\pi(x)\alpha(x,y)q(x,y) = \pi(y)q(y,x).
{% endkatex %}

Solving this equation for {% katex %}\alpha(x,y){% endkatex %} gives,

{% katex display %}
\alpha(x,y) = \frac{\pi(y)q(y,x)}{\pi(x)q(x,y)}.
{% endkatex %}

Similarly if the second condition, {% katex %}\pi(x)q(x,y)\ <\ \pi(y)q(y,x){% endkatex %}, is satisfied
by the proposal stochastic kernel the number of transitions from {% katex %}x{% endkatex %} to
{% katex %}y{% endkatex %} needs to be increased and the transitions from {% katex %}y{% endkatex %} to
{% katex %}x{% endkatex %} decreased. Setting {% katex %}\alpha(x,y)=1{% endkatex %} in equation
{% katex %}(11){% endkatex %} produces the desired result, namely,

{% katex display %}
\pi(x)q(x,y) = \pi(y)\alpha(y,x)q(y,x).
{% endkatex %}

Solving for {% katex %}\alpha(y,x){% endkatex %} gives,

{% katex display %}
\alpha(y,x) = \frac{\pi(x)q(x,y)}{\pi(y)q(y,x)},
{% endkatex %}

which is the time revered version of the first result. Equation {% katex %}(3){% endkatex %} follows
when the constraint from equation {% katex %}(2){% endkatex %},
{% katex %}0\ \leq\ \alpha(x, y^{\ast})\ \leq 1{% endkatex %}, is considered equation
{% katex %}(3){% endkatex %} follows,

{% katex display %}
\alpha(x, y) = \text{min}\left\{\frac{f(y)q(y,x)}{f(x)q(x,y)}, 1\right\}.
{% endkatex %}

## Example

As and example implementation of the Metropolis Hastings algorithm a
[{% katex %}\textbf{Weibull}{% endkatex %}](https://en.wikipedia.org/wiki/Weibull_distribution)
target distribution and
[{% katex %}\textbf{Normal}{% endkatex %}](https://en.wikipedia.org/wiki/Normal_distribution)
proposal distribution are considered. The {% katex %}\textbf{Weibull}{% endkatex %} distribution PDF is defined by,

{% katex display %}
f_X(x; k, \lambda) =
\begin{cases}
\frac{k}{\lambda}\left(\frac{x}{\lambda} \right)^{k-1} e^{-\left(x/\lambda\right)^k} & x\ \geq\ 0 \\
0 & x < 0
\end{cases} \ \ \ \ \ (12),
{% endkatex %}

where {% katex %}k\ >\ 0{% endkatex %} is the shape parameter and {%katex %}\lambda\ >\ 0{% endkatex %} the scale parameter. The first and second moments are,

{% katex display %}
\begin{aligned}
\mu & = \lambda\Gamma\left(1+\frac{1}{k}\right) \\
\sigma^2 & = \lambda^2\left[\Gamma\left(1+\frac{2}{k}\right)-\left(\Gamma\left(1+\frac{1}{k}\right)\right)^2\right]
\end{aligned} \ \ \ \ \ (13),
{% endkatex %}

where {% katex %}\Gamma(x){% endkatex %} is the [Gamma function](https://en.wikipedia.org/wiki/Gamma_function). The following plot illustrates the variation in the {% katex %}\textbf{Weibull}{% endkatex %} distribution
for a fixed value of the scale parameter of {% katex %}\lambda=1{% endkatex %} as the shape parameter,
{% katex %}k{% endkatex %}, is varied.
The following sections will assume that {% katex %}\lambda=1{% endkatex %} and {% katex %}k=5{% endkatex %}.

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/weibull_distribution_parameters.png">

The Normal distribution is defined by the PDF,

{% katex display %}
f_X(x; \mu, \sigma^2) =\frac{1}{\sqrt{2\pi\sigma^2}}e^{(x-\mu)^2/2\sigma^2}\ \ \ \ \ (14),
{% endkatex %}

where {% katex %}\mu{% endkatex %} is the location parameter and first moment and
{% katex %}\sigma^2{% endkatex %} is the scale parameter and second moment. The following plot illustrates
variation in the PDF and the scale and location parameter are varied.

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_distribution_parameters.png">

### Proposal Distribution Stochastic Kernel

The Metropolis Hastings algorithm requires a stochastic kernel based on the proposal distribution. Here
the proposal stochastic kernel is based on the difference equation,

{% katex display %}
X_{t} = X_{t-1} + \varepsilon_{t},
{% endkatex %}

where {% katex %}t=0,\ 1,\ 2,\ldots{% endkatex %} and the {% katex %}\varepsilon_{t}{% endkatex %} are identically distributed independent {% katex %}\textbf{Normal}{% endkatex %}
random variables with zero mean and variance, {% katex %}\sigma^2{% endkatex %}.
It is a special case of the [AR(1)](https://en.wikipedia.org/wiki/Autoregressive_model) random process.
Let {% katex %}y=X_{t}{% endkatex %} and {% katex %}x=X_{t-1}{% endkatex %} then the equation above becomes,

{% katex display %}
y-x=\varepsilon_{t}.
{% endkatex %}

Substitution into equation {% katex %}(14){% endkatex %} gives the stochastic kernel,

{% katex display %}
q(x,y) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-(y-x)^2/2\sigma^2}\ \ \ \ \ (15),
{% endkatex %}

The form of {% katex %}q(x,y){% endkatex %} is a {% katex %}\textbf{Normal}{% endkatex %} distribution with
{% katex %}\mu=x{% endkatex %}. This eliminates {% katex %}\mu{% endkatex %} as a free parameter.
The only free parameter in the model is the standard deviation, {% katex %}\sigma{% endkatex %}. In
the implementation {% katex %}\sigma{% endkatex %} is referred to as the `stepsize`. The plot below
shows how {% katex %}q(x,y){% endkatex %} varies with each step in a simulation. The first five steps
are shown for an initial condition {% katex %}X_{0}=0{% endkatex %} and `stepsize=1.0`.

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_examples.png">

It is seen that the distribution is recentered at each step about the the previous value. This behavior
is a consequence of the assuming a {% katex %}\textbf{Normal}{% endkatex %} proposal distribution.
Using some other form for a proposal could use a different parameterization.

A [Rejection Sampling]({{ site.baseurl }}{% link _posts/2018-07-29-rejection_sampling.md %}) implementation
using the same proposal and target distributions has both {% katex %}\mu{% endkatex %} and
{% katex %}\sigma{% endkatex %} as free parameters. Modeling the sampling process as a Markov Chain
has eliminated a parameter.

### Implementation

Metropolis Hastings Sampling is simple to implement. This section will describe an implementation
in Python using libraries available in `numpy`. Below a sampler for  {% katex %}q(x,y){% endkatex %}
using the `numpy` `normal` random number generator.

```python
import numpy

def qsample(x, stepsize):
    return numpy.random.normal(x, stepsize)
```

`qsample(x, stepsize)` takes two arguments as input. The first is `x` the previous state and the second the `stepsize`.
`x` is used as the `loc` parameter and `stepsize` the `scale` parameter in the call to the `numpy`
`normal` random number generator.

Simulations of time series using `qsample(x, stepsize)` can be performed using the code below where
first the simulation parameters are specified and followed by allocation of storage for the result.
Finally, the simulation is initialized and `nsamples` samples are generated.

```python
stepsize = 1.0
x0 = 0.0
nsamples = 500
x = numpy.zero(nsamples)

x[0] = x0
for j in range(1, nsamples):
    x[j] = qsample(x[j-1], stepsize)
```

The following plot shows time series generated by three separate runs of the code listed above.

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_time_series.png">

The Python implementation of the steps performed by Metropolis Hastings Sampling discussed in the
**Algorithm** section is shown below.

```python
def metropolis_hastings(f, q, qsample, stepsize, nsample, x0):
    x = x0
    samples = numpy.zeros(nsample)
    for i in range(nsample):
        u = numpy.random.rand()
        y_star = qsample(x, stepsize)
        fy_star = f(y_star)
        fx = p(x)
        Î± = (fy_star*q(y_star, x, stepsize)) / (fx*q(x, y_star, stepsize))
        if u < Î±:
            x = y_star
        samples[i] = x
    return samples
```

`metropolis_hastings(f, q, qsample, stepsize, nsample, x0)` takes five arguments as input that are
described in the table below.

| Argument | Description |
| :-----: | :---- |
| `f` | The target distribution which is assumed to support an interface taking a the previous state, `x`, as a floating point argument. In this example equation {% katex %}(12){% endkatex %} is used.|
| `q` | The proposal stochastic kernel which is assumed to support an interface taking the previous state, `x`, and the `stepsize` both as floating point arguments. In this example equation {% katex %}(15){% endkatex %} is used.|
| `qsample` | A random number generator based on the proposal stochastic kernel {% katex %}q(x,y){% endkatex %} which is assumed to support an interface taking the previous state, `x`, and the `stepsize` both as floating point arguments. The implementation used in this example by the function `qsample(x, stepsize)` previously discussed.|
| `stepsize` | The scale parameter used by the proposal distribution.|
| `nsample` | The number of samples desired.|
| `x0` | The initial target sample value.|

The execution of `metropolis_hastings(f, q, qsample, stepsize, nsample, x0)` begins by allocation of storage for
the result and the initialization of the result Markov Chain. A loop is then executed `nsample` times
where each iteration generates the next sample. Within the loop the acceptance random variable
with distribution {% katex %}\textbf{Uniform}(0,\ 1){% endkatex %} is generated using the `numpy` random number
generator. Next, a proposal sample is generated using `qsample(x, stepsize)` followed by evaluation
of the acceptance function {% katex %}\alpha(x,y){% endkatex %}. Finally, the acceptance criteria is
evaluated leading the sample being rejected or accepted.

## Simulations

Here the results of simulations performed using the previously described
`metropolis_hastings(f, q, qsample, stepsize, nsample, x0)` Python implementation of the Metropolis Hastings
algorithm are discussed. The simulations assume the {% katex %}\textbf{Weibull}{% endkatex %} target distribution
from equation {% katex %}(12){% endkatex %} with {% katex %}\lambda=1{% endkatex %} and
{% katex %}k=5{% endkatex %} and the {% katex %}\textbf{Normal}{% endkatex %} stochastic kernel from
equation {% katex %}(14){% endkatex %}. Simulations that scan 4 orders of magnitude of `setpsize`
are compared with the goal of determining the value leading the best performance. The criteria for
evaluating performance include the time for convergence of the first and seconds moments computed from
samples to the corresponding target distribution values, the fit of
the sampled distribution to the target PDF, the percentage of accepted proposal samples and the timescale
for the decay of time series autocorrelation.

### Performance

The plot below shows the percentage of proposal samples accepted as a function of `stepsize` for
simulations with `stepsize` ranging from {% katex %}10^{-3}{% endkatex %} to {% katex %}10^{1}{% endkatex %}.
The simulation believed to be the best performing accepted {% katex %}82\%{% endkatex %} of the proposed
samples and had a stepsize of {% katex %}0.121{% endkatex %}. This simulation is indicated by the orange point
in the plot. For all simulations discussed in this section `x0=1.0`.

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/norma_proposal_acceptance.png">

On examination of the plot it is seen that for `stepsize` smaller than
{% katex %}0.121{% endkatex %}, the simulations to the left of the orange symbol, the accepted percentage of
proposal samples very quickly approach {% katex %}100\%{% endkatex %} while for `stepsize` larger than
{% katex %}0.121{% endkatex %}, the simulations to the right of the orange symbol, the accepted
percentage approaches {% katex %}0\%{% endkatex %} as a power law.

To get a sense of why this happens the `stepsize` is compared to the standard deviation
of the target distribution computed from equation {% katex %}(13){% endkatex %}, using the assumed values for
{% katex %}\lambda{% endkatex %} and {% katex %}k{% endkatex %}, gives {% katex %}0.21{% endkatex %}.
This value is the same order of magnitude of the best performing `stepsize` determined from simulations.
Comparing the `stepsize` to the target standard deviation in the large and small limits
provides an interpretation of the results. For small `stepsize` relative to the target standard deviation the proposal variance is
much smaller then the target variance. Because of this the steps taken by the proposal Markov Chain are small leading
to a exploration of the target distribution that never goes far from the initial value. The samples produced will have
the proposal distribution since nearly all proposals are accepted. This is seen in the first of the following
plots where time series examples for different `stepsize` values for the last {% katex %}500{% endkatex %} steps
for a {% katex %}51000{% endkatex %} sample simulation are shown. The small variance seen in the first
plot is a consequence of the small `stepsize` leading to very small deviations from the initial value `x0=1`. In the
opposite limit where the `stepsize` becomes large relative to the target standard deviation the steps taken by the proposal
Markov Chain are so large that they are frequently rejected since low probability target events are oversampled. This effect is seen in
last time series plot shown below. There long runs where the series has a constant value are clearly visible. The
best value of `stepsize` relative to the target standard deviation occurs when they are about the same size. The middle plot
below has the optimal `stepsize` of {% katex %}0.121{% endkatex %} accepted {% katex %}82\%{% endkatex %} of the proposed
samples. It clearly has a more authentic look than the other two simulations which are at extreme values of the
percentage accepted.

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_time_series_stepsize_comparison.png">

A measure of simulation performance is the rate of convergence of distribution moments computed from
samples to the
target distribution values. The next two plots show convergence of the cumulative sample mean,
{% katex %}\mu{% endkatex %}, and standard deviation, {% katex %}\sigma{% endkatex %}, to the target
distribution values computed from
equation {% katex %}(13){% endkatex %} for three values of `stepsize` that compare
simulations at both the
small and large extremes with the optimal `stepsize` of {% katex %}0.121{% endkatex %}.
For both {% katex %}\mu{% endkatex %}
and {% katex %}\sigma{% endkatex %} the small `stepsize` example is clearly the worst performing. After
{% katex %}10^5{% endkatex %} time steps there is no indication of convergence. There is no significant difference  between the
other two simulations. Both are showing convergence after {% katex %}O(10^4){% endkatex %} samples.

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_sigma_convergence_stepsize_comparison.png">

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_mean_convergence_stepsize_comparison.png">

A consequence of using a Markov Chain to generate samples is that autocorrelation is built into the model.
This is considered an undesirable artifact since in general independent and identically distributed samples
are desired. It follows that there is a preference for rapid decorrelation of samples. The following plot
shows the autocorrelation coefficient for the three values of `stepsize` previously discussed.
The autocorrelation coefficient of a time series, {% katex %}f{% endkatex %}, provides a measure
*similarity* or *dependence* of the series past and future and is defined by,

{% katex display %}
\gamma_{\tau} = \frac{1}{\sigma_{f}^2}\sum_{n=0}^{t} \left(f_{n} - \mu_f \right) \left(f_{n+\tau} - \mu_f\right),
{% endkatex %}

where {% katex %}\mu_{f}{% endkatex %} and {% katex %}\sigma_{f}{% endkatex %} are the time series mean and
standard deviation respectively. Calculation of autocorrelation was discussed in a
[previous post]({{ site.baseurl }}{% link _posts/2018-08-25-discrete_cross_correlation_theorem.md %}).
The small `stepsize` simulation has a very slowly decaying autocorrelation. For time lags of up to 100
steps it has decayed by only a few precent. This behavior is expected since for small
`stepsize` the resulting samples are from the proposal Markov Chain, with stochastic
kernel shown in equation {% katex %}(15){% endkatex %} which is independent of {% katex %}\tau{% endkatex %}
{% katex %}\gamma_{\tau}=1{% endkatex %}. The other simulations have a similar decorrelation rate of {% katex %}O(10){% endkatex %} time steps,
though for the larger `stepsize` the decorrelation rate is slightly faster.

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_autocorrelation_convergence_stepsize_comparison.png">

The following three plots compare histograms computed from simulations of {% katex %}10^5{% endkatex %} samples with the target
{% katex %}\textbf{Weibull}{% endkatex %} distribution from equation {% katex %}(12){% endkatex %} for the same `stepsize`
values used in the previous comparisons. The first plot shows the small `stepsize` simulation with a very high acceptance rate.
For this case the simulated histogram is nowhere close to reproducing the target distribution. The last plot is the large `stepsize` simulation
with a very large rejection rate. When compared with optimal `stepsize` of {% katex %}0.121{% endkatex %} simulation shown in the middle plot
the larger `stepsize` simulation is not as smooth but is acceptable. The degraded performance of larger `stepsize` simulation
will be a consequence of rejection of many more proposal samples leading to long stretches repeated values. For the
optimal `stepsize` simulation almost {% katex %}10{% endkatex %} times more sample are available in the histogram caclculation.

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_sampled_pdf-99.png">

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_sampled_pdf-82.png">

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_sampled_pdf-12.png">

In summary a collection of simulations using the Metropolis Hastings algorithm to sample a target
{% katex %}\texfbf{Weibull}{% endkatex %} distribution using a {% katex %}\textbf{Normal}{% endkatex %}
proposal distribution have been performed that scan the `stepsize` parameter for a fixed initial value
of `x0=1.0` in an effort to determine the best performing `stepsize`. Best performing was determined by considering
the total percentage of accepted samples, the *quality* of the generated time series, the convergence of first
and second moments to the known target values, the decorrelation timescale and fit of sample histograms to
the target distribution. The best performing `stepsize` was found to have a value of {% katex %}0.121{% endkatex %}
which is near the standard deviation of the target distribution. For values of `stepsize` smaller than the best
performing `stepsize` the performance was clearly inferior on all counts. The number of accepted proposals was high,
the time series look like the proposal distribution, convergence of moments is very slow, samples remain correlated
over long time scales and the distributions computed from samples look nothing like the target distribution.
When the same comparison is made to simulations with a larger `stepsize` the results were less conclusive.
Larger values of `stepsize` accept fewer proposal samples. This causes degradation of the time series since there
are many long runs of repeated values. In comparisons of convergence of distribution moments and autocorrelation
there was no significant differences but calculation of the distribution using histograms on sample data were not
as good since an order of magnitude less data was used in the calculation because of the high rejection percentage.

### Burn In

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_burnin-mean-convergence.png">

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_burnin-sigma-convergence.png">

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_burnin-autocorrelation.png">

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_sampled_pdf_burnin-x-3.png">

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_burnin-removed-mean-convergence.png">

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_burnin_removed-sigma-convergence.png">

<img class="post-image" src="/assets/posts/metropolis_hastings_sampling/normal_proposal_sampled_pdf_burnin-removed-x-3.png">

## Conclusions

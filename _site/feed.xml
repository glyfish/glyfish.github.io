<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-11-17T14:22:24-08:00</updated><id>http://localhost:4000/</id><title type="html">gly.fish</title><subtitle></subtitle><entry><title type="html">Metropolis Hastings Sampling</title><link href="http://localhost:4000/2018/09/08/metropolis_hastings_sampling.html" rel="alternate" type="text/html" title="Metropolis Hastings Sampling" /><published>2018-09-08T00:00:00-07:00</published><updated>2018-09-08T00:00:00-07:00</updated><id>http://localhost:4000/2018/09/08/metropolis_hastings_sampling</id><content type="html" xml:base="http://localhost:4000/2018/09/08/metropolis_hastings_sampling.html">[Metropolis Hastings Sampling](https://en.wikipedia.org/wiki/Metropolis–Hastings_algorithm) is a method for obtaining samples for a known target
probability distribution using samples from some other proposal distribution. It is similar to
[Rejection Sampling]({{ site.baseurl }}{% link _posts/2018-07-29-rejection_sampling.md %}) in providing a
criteria for acceptance of a proposal sample as a target sample but instead of discarding the
samples that do not meet the acceptance criteria the sample
from the previous time step is replicated. Another difference is that Metropolis Hastings samples are modeled as a [Markov Chain](https://en.wikipedia.org/wiki/Markov_chain) where the target distribution
is the
[Markov Chain Equilibrium Distribution]({{ site.baseurl }}{% link _posts/2018-08-16-continuous_state_markov_chain_equilibrium.md %}).
As a consequence
the previous sample is used as part of the acceptance criteria when generating the next sample.
It will be seen this has the advantage of permitting adjustment of some proposal distribution
parameters as each sample is generated, which in effect eliminates parameter inputs.  
This is is an improvement over Rejection Sampling, where it was
[previously shown]({{ site.baseurl }}{% link _posts/2018-07-29-rejection_sampling.md %}) that
slight variations in proposal distribution parameters can significantly impact performance.
A downside of the Markov Chain representation is that
[autocorrelation]({{ site.baseurl }}{% link _posts/2018-08-25-discrete_cross_correlation_theorem.md %}) can develop in the samples
which is not the case in Rejection Sampling.

&lt;!--more--&gt;

## Algorithm

The [Metropolis Sampling Algorithm](https://www.google.com/search?hl=en&amp;source=hp&amp;ei=O-CGW-qAIMWosgXf9ofQDA&amp;q=Equation+of+state+calculations+by+fast+computing+machines&amp;oq=Equation+of+state+calculations+by+fast+computing+machines&amp;gs_l=psy-ab.3..35i39k1j0i22i30k1l2.1983.1983.0.2488.3.2.0.0.0.0.91.91.1.2.0....0...1.2.64.psy-ab..1.2.180.6...89.Y99UmLWMZD0) was developed by physicist studying simulations of equation of state at the dawn of the computer age.
It is the first a a class of sampling algorithms referred to a [Monte Carlo Markov Chain](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo).
A couple of decades later the algorithm was generalized and given a firmer theoretical foundation becoming the [Metropolis Hastings Sampling Algorithm](https://www.google.com/search?client=safari&amp;rls=en&amp;ei=Xt-GW5GyLOWwtgX38az4Dg&amp;q=Monte+Carlo+Sampling+Methods+Using+Markov+Chains&amp;oq=Monte+Carlo+Sampling+Methods+Using+Markov+Chains&amp;gs_l=psy-ab.3..0j0i22i30k1l2.79402.79402.0.79877.1.1.0.0.0.0.95.95.1.1.0....0...1.2.64.psy-ab..0.1.95....0.99vsUPrnsUQ).
After a few more decades this work became widely used in simulating [Bayesian Posterior Distributions](https://en.wikipedia.org/wiki/Posterior_probability)
in Probabilistic Programming DSLs such as [`pymc`](https://en.wikipedia.org/wiki/PyMC3). This section provides an overview of the algorithm
to motivate details of the theory and examples discussed in following sections.

Let {% katex %}f(y){% endkatex %} denote the target distribution. The algorithm constructs a Markov Chain with
[equilibrium distribution]({{ site.baseurl }}{% link _posts/2018-08-16-continuous_state_markov_chain_equilibrium.md %}),
{% katex %}\pi_{E}(y){% endkatex %}, such that,

{% katex display %}
f(y) = \pi_{E}(y).
{% endkatex %}

The equilibrium [stochastic kernel]({{ site.baseurl }}{% link _posts/2018-08-16-continuous_state_markov_chain_equilibrium.md %}),
{% katex %}p(x,y){% endkatex %}, for the Markov Chain must satisfy,

{% katex display %}
\pi_{E}(y) = \int_{-\infty}^{\infty} p(x, y) \pi_{E}(x) dx\ \ \ \ \ (1).
{% endkatex %}

To generate samples for {% katex %}p(x, y){% endkatex %} samples from a proposal Markov Chain with stochastic kernel {% katex %}q(x, y){% endkatex %}
are produced. Let {% katex %}x{% endkatex %} denote the state of the {% katex %}p(x, y){% endkatex %} Markov Chain at the previous
time step, {% katex %}t-1{% endkatex %}, and {% katex %}y{% endkatex %} represent the yet to be determined state at time
{% katex %}t{% endkatex %}. Consider a proposal sample, {% katex %}y^{\ast}{% endkatex %}, generated by {% katex %}q(x, y){% endkatex %}.
Define an acceptance function, {% katex %}\alpha(x, y^{\ast}){% endkatex %}, that satisfies,

{% katex display %}
0\ \leq\ \alpha(x, y^{\ast})\ \leq 1\ \ \ \ \ (2),
{% endkatex %}

and an *acceptance* random variable, {% katex %}U{% endkatex %}, with distribution
{% katex %}\textbf{Uniform}(0,\ 1){% endkatex %}
independent of {% katex %}y^{\ast}{% endkatex %}. Now, if the following inequality is satisfied,

{% katex display %}
U\ \leq\ \alpha(x, y^{\ast}),
{% endkatex %}

*accept* the proposed sample, {% katex %}y=y^{\ast}{% endkatex %}, as a sample of {% katex %}p(x, y){% endkatex %}. If the inequality
is not satisfied then *reject* the sample by replicating the state from the previous time step, {% katex %}y=x{% endkatex %}.

It will be shown that,

{% katex display %}
\alpha(x, y) = \text{min}\left\{\frac{f(y)q(y,x)}{f(x)q(x,y)}, 1\right\}\ \ \ \ \ (3).
{% endkatex %}

The algorithm can be summarized by the following steps that are repeated for each sample.

1. Generate samples of {% katex %}y^{\ast}{% endkatex %} conditioned on {% katex %}x{% endkatex %}
and independently generate samples of {% katex %}U{% endkatex %}.
2. If {% katex %}U\ \leq\ \alpha(x, y^{\ast}){% endkatex %} then {% katex %}y = y^{\ast}{% endkatex %}.
3. If {% katex %}U\ &gt;\ \alpha(x, y^{\ast}){% endkatex %} then {% katex %}y = x{% endkatex %}.

## Theory

Metropolis Hastings Sampling is simple to implement but the theory that provides
validation of the algorithm is more complicated than required for both
[Rejection Sampling]({{ site.baseurl }}{% link _posts/2018-07-29-rejection_sampling.md %}) and
[Inverse CDF Sampling]({{ site.baseurl }}{% link _posts/2018-07-21-inverse_cdf_sampling.md %}).
Here the proof that the algorithm produces the desired result is accomplished in four steps.
The first will show that distributions and stochastic kernels that satisfy Time Reversal Symmetry,
also referred to as Detailed Balance, are equilibrium solutions that satisfy equation
{% katex %}(1).{% endkatex %} Next, the stochastic kernel resulting from the algorithm is derived
and followed by a proof that a distribution that satisfies Time Reversal Symmetry with the resulting
stochastic kernel is a solution to equation {% katex %}(1).{% endkatex %} Finally, the
expression for {% katex %}\alpha(x,y){% endkatex %} from equation {% katex %}(3){% endkatex %} will
be derived.

### Time Reversal Symmetry

Consider a stochastic kernel {% katex %}p(x,y){% endkatex %} and distribution {% katex %}\pi(y){% endkatex %}
where {% katex %}x{% endkatex %} is the state of the Markov Chain generated by the kernel at
{% katex %}t-1{% endkatex %} and {% katex %}y{% endkatex %} the
state at time {% katex %}t{% endkatex %}. If the chain has {% katex %}N{% endkatex %} steps
the expected number of transitions from {% katex %}x{% endkatex %} to
{% katex %}y{% endkatex %} will satisfy,

{% katex display %}
N_{y}=N \pi(y) p(x, y).
{% endkatex %}

It follows that the rate of transition from {% katex %}x{% endkatex %} to {% katex %}y{% endkatex %} is
given by {% katex %}\pi(y) p(x,y){% endkatex %}. The transition rate for the Markov Chain obtained by
reversing time, that is the chain transitions from {% katex %}y{% endkatex %} to {% katex %}x,{% endkatex %}
will be {% katex %}\pi(x) p(y, x){% endkatex %}.

Time Reversal Symmetry implies that the transition rate for the time reversed Markov Chain is the same as the
forward time chain,

{% katex display %}
\pi(y) p(x, y) = \pi(x) p(y,x)\ \ \ \ \ (3).
{% endkatex %}

If Time Reversal Symmetry is assumed it follows that,

{% katex display %}
\begin{aligned}
\int_{-\infty}^{\infty} p(x, y) \pi(x) dx &amp;= \int_{-\infty}^{\infty} p(y, x) \pi(y) dx \\
&amp;= \pi(y) \int_{-\infty}^{\infty} p(y, x) dx \\
&amp;= \pi (y),
\end{aligned}
{% endkatex %}

where the last step is a result of the definition of a stochastic kernel,
{% katex %}\int_{-\infty}^{\infty} p(y, x) dx = 1{% endkatex %}. Thus any distribution and kernel satisfying
equation {% katex %}(3){% endkatex %} is an equilibrium solution since it will also satisfy
equation {% katex %}(1){% endkatex %}

### Stochastic Kernel

In a [previous post]({{ site.baseurl }}{% link _posts/2018-08-16-continuous_state_markov_chain_equilibrium.md %})
it was shown that a stochastic kernel can be interpreted as probability density conditioned of the state
at the previous time step,

{% katex display %}
p(x,y) = f(y\mid x).
{% endkatex %}

It follows that the [Cumulative Probability Distribution (CDF)]({{ site.baseurl }}{% link _posts/2018-07-21-inverse_cdf_sampling.md %}) of obtaining a sample {% katex %}y{% endkatex %}
for a given {% katex %}x{% endkatex %} is given by,

{% katex display %}
\begin{aligned}
P\left[ Y\ \leq\ y\ \mid\ X=x \right] &amp;= \int_{-\infty}^{y} f(w\mid x) dw \\
&amp;= \int_{-\infty}^{y} p(x,w) dw.
\end{aligned}
{% endkatex %}

Let {% katex %}U{% endkatex %} represent the {% katex %}\textbf{Uniform}(0, 1){% endkatex %} acceptance
random variable. A proposal sample, {% katex %}y^{\ast}{% endkatex %} conditioned
on {% katex %}x{% endkatex %}, is generated by {% katex %}q(x,y){% endkatex %} independent of
{% katex %}U{% endkatex %} and accepted if,

{% katex display %}
U\ \leq\ \alpha(x, y^{\ast}),
{% endkatex %}

then {% katex %}y=y^{\ast}{% endkatex %}. The proposal is rejected if,

{% katex display %}
U\ &gt;\ \alpha(x, y^{\ast}),
{% endkatex %}

then {% katex %}y=x{% endkatex %}. Now, using the
[Law of Total Probability](https://en.wikipedia.org/wiki/Law_of_total_probability) to condition on
{% katex %}U{% endkatex %} the stochastic kernel CDF becomes,

{% katex display %}
\begin{aligned}
P\left[ Y\ \leq\ y\ \mid\ X=x \right]\ &amp;=\ P\left[Y\ \leq\ y\ \mid\ U\ \leq\ \alpha(x, y^{\ast}),\ X=x \right]\ P\left[U\ \leq\ \alpha(x, y^{\ast})\ \mid\ X=x \right] \\
&amp;\ + P\left[Y\ \leq\ y\ \mid\ U\ &gt;\ \alpha(x, y^{\ast}),\ X=x \right]\ P\left[U\ &gt;\ \alpha(x, y^{\ast})\ \mid\ X=x \right].
\end{aligned}\ \ \ \ \ (4).
{% endkatex %}

The first term is the probability that the proposed sample is accepted and the second term the
probability that it is rejected. Consider the first term where
{% katex %}U\ \leq\ \alpha(x, y^{\ast}){% endkatex %} and {% katex %}y=y^{\ast}{% endkatex %},

{% katex display %}
P\left[Y\ \leq\ y,\ U\ \leq\ \alpha(x, y^{\ast})\ \mid\ X=x \right]\ =\ P\left[Y\ \leq\ y\ \mid\ U\ \leq\ \alpha(x, y^{\ast}),\ X=x \right]\ P\left[U\ \leq\ \alpha(x, y^{\ast})\ \mid\ X=x \right]\ \ \ \ \ (5),
{% endkatex %}

which follows from the definition of
[Conditional Probability](https://en.wikipedia.org/wiki/Conditional_probability).

The algorithm assumes that {% katex %}U{% endkatex %} is independent of {% katex %}y^{\ast}{% endkatex %} conditioned on {% katex %}x{% endkatex %}. It follows that the joint density is
given by,

{% katex display %}
\begin{aligned}
h(y^{\ast}, u\mid x) &amp;= g(u)f(y^{\ast}\mid x) \\
&amp;= q(x, y^{\ast}),
\end{aligned}
{% endkatex %}

where the last step follows by noting that since {% katex %}U\ \sim\ \textbf{Uniform}(0,1),{% endkatex %} the density of {% katex %}U{% endkatex %} is given by {% katex %}g(u)=1{% endkatex %} and the density
of {% katex %}y^{\ast}{% endkatex %} conditioned on {% katex %}x{% endkatex %} is given by the
proposal stochastic kernel, {% katex %}f(y^{\ast}\mid x)=q(x, y^{\ast}).{% endkatex %} Using this
result to continue gives the acceptance probability term for the stochastic kernel CDF from
equation {% katex %}(5){% endkatex %},

{% katex display %}
\begin{aligned}
P\left[Y\ \leq\ y,\ U\ \leq\ \alpha(x, y^{\ast})\ \mid\ X=x \right] &amp;= \int_{-\infty}^{y}\int_{0}^{\alpha(x, y^{\ast})} h(y^{\ast}, u\mid x) du dy^{\ast} \\
&amp;= \int_{-\infty}^{y}\int_{0}^{\alpha(x, y^{\ast})} q(x, y^{\ast}) du dy^{\ast} \\
&amp; =  \int_{-\infty}^{y} \alpha(x, y^{\ast}) q(x, y^{\ast}) dy^{\ast}
\end{aligned}\ \ \ \ \ (6).
{% endkatex %}

Next, consider the second term in equation {% katex %}(4){% endkatex %}, which represents the case where
{% katex %}y^{\ast}{% endkatex %} is rejected as a sample of {% katex %}y{% endkatex %}.
Since {% katex %}y^{\ast}{% endkatex %} is rejected {% katex %}y=x{% endkatex %}.
It follows that any value of {% katex %}y^{\ast}{% endkatex %} is possible so
the integral over {% katex %}y^{\ast}{% endkatex %} needs to be over its entire range. Using the previous
result for the joint density {% katex %}h(y^{\ast}, u\mid x){% endkatex %}. gives

{% katex display %}
\begin{aligned}
P\left[Y\ = x,\ U\ &gt;\ \alpha(x, y^{\ast})\ \mid\ X=x \right] &amp;= \int_{-\infty}^{\infty}\int_{\alpha(x, y^{\ast})}^{1} h(y^{\ast}, u\mid x) du dy^{\ast} \\
&amp;= \int_{-\infty}^{\infty}\int_{\alpha(x, y^{\ast})}^{1} q(x, y^{\ast}) du dy^{\ast} \\
&amp;= \int_{-\infty}^{\infty}\left[ 1-\alpha(x, y^{\ast})\right] q(x, y^{\ast}) dy^{\ast} \\
&amp;= \int_{-\infty}^{\infty}\ q(x, y^{\ast}) dy^{\ast} - \int_{-\infty}^{\infty}\alpha(x, y^{\ast}) q(x, y^{\ast}) dy^{\ast} \\
&amp;= 1 - \int_{-\infty}^{\infty}\alpha(x, y^{\ast}) q(x, y^{\ast}) dy^{\ast}
\end{aligned}\ \ \ \ \ (7)
{% endkatex %}

since {% katex %}\int_{-\infty}^{\infty}\ q(x, y^{\ast}) dy^{\ast}=1{% endkatex %}. Simplify
things by defining the rejection probability density by,

{% katex display %}
f_{R}(x) = 1 - \int_{-\infty}^{\infty}\alpha(x, y) q(x, y) dy\ \ \ \ \ (8).
{% endkatex %}

Equation {% katex %}(7){% endkatex %} needs to be written as an integral over
{% katex %}y{% endkatex %} to continue with the evaluation of equation {% katex %}(4){% endkatex %}. This
is accomplished by use of the [Dirac Delta Function](https://en.wikipedia.org/wiki/Dirac_delta_function)
which is defined by,

{% katex display %}
\int_{-\infty}^{\infty} f(y^{\ast})\delta(y^{\ast}-x) dy^{\ast} = f(x).
{% endkatex %}

If use is made of equation {% katex %}(8){% endkatex %} and the Dirac Delta Function it follows that
equation {% katex %}(7){% endkatex %} becomes,

{% katex display %}
P\left[Y\ \leq\ y,\ U\ &gt;\ \alpha(x, y^{\ast})\ \mid\ X=x \right] = \int_{-\infty}^{y} f_{R}(y^{\ast})\delta(y^{\ast}-x) dy^{\ast}\ \ \ \ \ (9).
{% endkatex %}

The upper range of the limit was changed to conform to the limits of the CDF. This is acceptable
since if {% katex %}y\ &lt;\ x{% endkatex %} the probability of rejection is 0. The Metropolis Hastings
stochastic kernel can now by constructed by assembling the results obtained in
equations {% katex %}(6){% endkatex %} and {% katex %}(9){% endkatex %} and revisiting equation
{% katex %}(5){% endkatex %},

{% katex display %}
\begin{aligned}
\int_{-\infty}^{y} p(x,w) dw &amp; = P\left[ Y\ \leq\ y\ \mid\ X=x \right] \\
&amp;= P\left[Y\ \leq\ y,\ U\ \leq\ \alpha(x, y^{\ast})\ \mid\ X=x \right] + P\left[Y\ \leq\ y,\ U\ &gt;\ \alpha(x, y^{\ast})\ \mid\ X=x \right] \\
&amp;= \int_{-\infty}^{y} \alpha(x, y^{\ast}) q(x, y^{\ast}) dy^{\ast} + \int_{-\infty}^{y} f_{R}(y^{\ast})\delta(y^{\ast}-x) dy^{\ast} \\
&amp;= \int_{-\infty}^{y} \left[ \alpha(x, y^{\ast}) q(x, y^{\ast}) + f_{R}(y^{\ast})\delta(y^{\ast}-x)\right] dy^{\ast}
\end{aligned}
{% endkatex %}

Finally, the desired result is obtained by collecting the terms under a single integration variable,

{% katex display %}
\begin{gathered}
p(x,y) = \alpha(x, y) q(x, y) + f_{R}(y)\delta(y-x) \\
f_{R}(x) = 1 - \int_{-\infty}^{\infty}\alpha(x, y) q(x, y) dy
\end{gathered}\ \ \ \ \ (10)
{% endkatex %}

Verify that the kernel satisfies the stochastic property,

{% katex display %}
\begin{aligned}
\int_{-\infty}^{\infty} p(x,y) dy &amp;= \int_{-\infty}^{\infty}\left[ \alpha(x, y) q(x, y) + f_{R}(y)\delta(y-x)\right] dy \\
&amp;= \int_{-\infty}^{\infty}\alpha(x, y) q(x, y) dy - f_{R}(x) \\
&amp;= \int_{-\infty}^{\infty}\alpha(x, y) q(x, y) dy + 1 - \int_{-\infty}^{\infty}\alpha(x, y) q(x, y) dy \\
&amp;= 1
\end{aligned}
{% endkatex %}

which is the desired result.

### Equilibrium

It can now be shown that the Metropolis Hastings stochastic kernel from equation {% katex %}(10){% endkatex %}
is an equilibrium solution by evaluating the integral from equation {% katex %}(1){% endkatex %} that
defines equilibrium. Additionally, Time Reversal Symmetry must also be assumed,

{% katex display %}
\pi(x)\alpha(x,y)q(x,y) = \pi(y)\alpha(y,x)q(y,x)\ \ \ \ \ (11),
{% endkatex %}

where {% katex %}\alpha(x,y){% endkatex %} is the acceptance function from equation
{% katex %}(1){% endkatex %}, {% katex %}q(x,y){% endkatex %} is the stochastic kernel for the
proposal Markov Chain, {% katex %}\pi(y){% endkatex %} is the distribution, {% katex %}y{% endkatex %} is
the state of the target Markov Chain at time step {% katex %}t{% endkatex %} and {% katex %}x{% endkatex %}
the state at time {% katex %}t-1{% endkatex %}.

Now, starting with equation {% katex %}(1){% endkatex %},

{% katex display %}
\begin{aligned}
\int_{-\infty}^{\infty} p(x, y) \pi(x) dx &amp;= \int_{-\infty}^{\infty}\left[ \alpha(x, y) q(x, y) + f_{R}(y)\delta(y-x)\right] \pi(x) dx \\
&amp;= \int_{-\infty}^{\infty}\alpha(x, y) q(x, y) \pi(x) dx + f_{R}(y)\pi(y) \\
&amp;= \int_{-\infty}^{\infty}\alpha(x, y) q(x, y) \pi(x) dx + \left[1 - \int_{-\infty}^{\infty}\alpha(y, w) q(y, w) dw \right]\pi(y) \\
&amp;= \pi(y)+\int_{-\infty}^{\infty}\alpha(x, y) q(x, y) \pi(x) dx - \int_{-\infty}^{\infty}\pi(y)\alpha(y, w) q(y, w) dw \\
&amp;= \pi(y)+\int_{-\infty}^{\infty}\alpha(x, y) q(x, y) \pi(x) dx - \int_{-\infty}^{\infty}\pi(w)\alpha(w, y) q(w, y) dw \\
&amp;= \pi(y),
\end{aligned}
{% endkatex %}

where the last steps follow from substituting equation {% katex %}(11){% endkatex %} into the last term
leading to the desired result.

### Derivation of {% katex %}\alpha(x,y){% endkatex %}

It has been shown that the Metropolis Hastings algorithm generates a Markov Chain with an equilibrium
distribution equal to the target distribution. This has been accomplished by only requiring that
the acceptance function, {% katex %}\alpha(x,y){% endkatex %}, satisfy Time Reversal Symmetry
as specified by equation {% katex %}(11){% endkatex %} without giving and explicit form. Here
an expression for {% katex %}\alpha(x,y){% endkatex %} is derived with the aim of driving arbitrary
proposal Markov Chains toward states satisfying Time Reversal Symmetry.

For an arbitrary proposal stochastic kernel, {% katex %}q(x,y){% endkatex %}, Time Reversal Symmetry
will not be satisfied, so either {% katex %}\pi(x)q(x,y)\ &gt;\ \pi(y)q(y,x){% endkatex %} or
{% katex %}\pi(x)q(x,y)\ &lt;\ \pi(y)q(y,x){% endkatex %} will be true. Assume the first condition is valid.
If this is the case transitions from {% katex %}x{% endkatex %} to {% katex %}y{% endkatex %} occur more
frequently than transitions from {% katex %}y{% endkatex %} to {% katex %}x{% endkatex %}. To correct for
the imbalance the number of transitions from {% katex %}x{% endkatex %} to {% katex %}y{% endkatex %} needs
to be decreased and the number of transition from {% katex %}y{% endkatex %} to {% katex %}x{% endkatex %}
increased. This can be accomplished by setting {% katex %}\alpha(y,x)=1{% endkatex %} in equation
{% katex %}(11){% endkatex %} to obtain,

{% katex display %}
\pi(x)\alpha(x,y)q(x,y) = \pi(y)q(y,x).
{% endkatex %}

Solving this equation for {% katex %}\alpha(x,y){% endkatex %} gives,

{% katex display %}
\alpha(x,y) = \frac{\pi(y)q(y,x)}{\pi(x)q(x,y)}.
{% endkatex %}

Similarly if the second condition, {% katex %}\pi(x)q(x,y)\ &lt;\ \pi(y)q(y,x){% endkatex %}, is satisfied
by the proposal stochastic kernel the number of transitions from {% katex %}x{% endkatex %} to
{% katex %}y{% endkatex %} needs to be increased and the transitions from {% katex %}y{% endkatex %} to
{% katex %}x{% endkatex %} decreased. Setting {% katex %}\alpha(x,y)=1{% endkatex %} in equation
{% katex %}(11){% endkatex %} produces the desired result,

{% katex display %}
\pi(x)q(x,y) = \pi(y)\alpha(y,x)q(y,x).
{% endkatex %}

Solving for {% katex %}\alpha(y,x){% endkatex %} gives,

{% katex display %}
\alpha(y,x) = \frac{\pi(x)q(x,y)}{\pi(y)q(y,x)},
{% endkatex %}

which is the time reversed version of the first result. Equation {% katex %}(3){% endkatex %} follows
when the constraint, {% katex %}0\ \leq\ \alpha(x, y^{\ast})\ \leq 1,{% endkatex %} is considered,

{% katex display %}
\alpha(x, y) = \text{min}\left\{\frac{f(y)q(y,x)}{f(x)q(x,y)}, 1\right\}.
{% endkatex %}

## Example

Here an example implementation of the Metropolis Hastings Sampling algorithm using a
[{% katex %}\textbf{Weibull}{% endkatex %}](https://en.wikipedia.org/wiki/Weibull_distribution)
target distribution and
[{% katex %}\textbf{Normal}{% endkatex %}](https://en.wikipedia.org/wiki/Normal_distribution)
proposal distribution is discussed. The {% katex %}\textbf{Weibull}{% endkatex %} distribution PDF is defined by,

{% katex display %}
f_X(x; k, \lambda) =
\begin{cases}
\frac{k}{\lambda}\left(\frac{x}{\lambda} \right)^{k-1} e^{-\left(x/\lambda\right)^k} &amp; x\ \geq\ 0 \\
0 &amp; x &lt; 0
\end{cases} \ \ \ \ \ (12),
{% endkatex %}

where {% katex %}k\ &gt;\ 0{% endkatex %} is the shape parameter and {%katex %}\lambda\ &gt;\ 0{% endkatex %} the scale parameter. The first and second moments are,

{% katex display %}
\begin{aligned}
\mu &amp; = \lambda\Gamma\left(1+\frac{1}{k}\right) \\
\sigma^2 &amp; = \lambda^2\left[\Gamma\left(1+\frac{2}{k}\right)-\left(\Gamma\left(1+\frac{1}{k}\right)\right)^2\right]
\end{aligned} \ \ \ \ \ (13),
{% endkatex %}

where {% katex %}\Gamma(x){% endkatex %} is the [Gamma function](https://en.wikipedia.org/wiki/Gamma_function). The following plot illustrates the variation in the {% katex %}\textbf{Weibull}{% endkatex %} distribution
for a fixed value of the scale parameter of {% katex %}\lambda=1{% endkatex %} as the shape parameter,
{% katex %}k{% endkatex %}, is varied.
The following sections will assume that {% katex %}\lambda=1{% endkatex %} and {% katex %}k=5{% endkatex %}.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/weibull_distribution_parameters.png&quot;&gt;

The Normal distribution is defined by the PDF,

{% katex display %}
f_X(x; \mu, \sigma^2) =\frac{1}{\sqrt{2\pi\sigma^2}}e^{(x-\mu)^2/2\sigma^2}\ \ \ \ \ (14),
{% endkatex %}

where {% katex %}\mu{% endkatex %} is the location parameter and first moment and
{% katex %}\sigma^2{% endkatex %} is the scale parameter and second moment. The following plot illustrates
variation in the PDF as the scale and location parameter are varied.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_distribution_parameters.png&quot;&gt;

### Proposal Distribution Stochastic Kernel

The Metropolis Hastings Sampling algorithm requires a stochastic kernel based on the proposal distribution.
A {% katex %}\textbf{Normal}{% endkatex %} stochastic kernel can be derived from the difference equation,

{% katex display %}
X_{t} = X_{t-1} + \varepsilon_{t},
{% endkatex %}

where {% katex %}t=0,\ 1,\ 2,\ldots{% endkatex %} and the {% katex %}\varepsilon_{t}{% endkatex %} are identically distributed independent {% katex %}\textbf{Normal}{% endkatex %}
random variables with zero mean and variance, {% katex %}\sigma^2{% endkatex %}.
Let {% katex %}y=X_{t}{% endkatex %} and {% katex %}x=X_{t-1}{% endkatex %} then the equation above becomes,

{% katex display %}
y-x=\varepsilon_{t}.
{% endkatex %}

Substitution into equation {% katex %}(14){% endkatex %} gives the stochastic kernel,

{% katex display %}
q(x,y) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-(y-x)^2/2\sigma^2}\ \ \ \ \ (15),
{% endkatex %}

The form of {% katex %}q(x,y){% endkatex %} is a {% katex %}\textbf{Normal}{% endkatex %} distribution with
mean {% katex %}\mu=x{% endkatex %}. This has eliminated {% katex %}\mu{% endkatex %} as a free parameter.
The only arbitrary parameter is the standard deviation, {% katex %}\sigma{% endkatex %}. In
the implementation {% katex %}\sigma{% endkatex %} will be referred to as the `stepsize`. The plot below
shows how {% katex %}q(x,y){% endkatex %} varies with each step in a simulation. The first five steps
are shown for an initial condition {% katex %}X_{0}=0{% endkatex %} and `stepsize=1.0`.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_examples.png&quot;&gt;

In the plot it is seen that the distribution is recentered at each step about the the previous value.
This behavior is a consequence of the assuming a {% katex %}\textbf{Normal}{% endkatex %} proposal distribution.
Using another form for a proposal distribution could use a different parameterization.

A [Rejection Sampling]({{ site.baseurl }}{% link _posts/2018-07-29-rejection_sampling.md %}) implementation
using the same proposal and target distributions has both {% katex %}\mu{% endkatex %} and
{% katex %}\sigma{% endkatex %} as arbitrary parameters. Modeling the sampling process as a Markov Chain
has eliminated one parameter.

### Implementation

Metropolis Hastings Sampling is simple to implement. This section will describe an implementation
in Python using libraries available in `numpy`. Below a sampler for {% katex %}q(x,y){% endkatex %}
using the `numpy` `normal` random number generator is shown.

```python
import numpy

def qsample(x, stepsize):
    return numpy.random.normal(x, stepsize)
```

`qsample(x, stepsize)` takes two arguments as input. The first is `x`, the previous state, and
the second the `stepsize`. `x` is used as the `loc` parameter and `stepsize` the `scale` parameter
in the call to the `numpy` `normal` random number generator.

Simulations of time series using `qsample(x, stepsize)` can be performed using the code below.

```python
stepsize = 1.0
x0 = 0.0
nsamples = 500
x = numpy.zero(nsamples)

x[0] = x0
for j in range(1, nsamples):
    x[j] = qsample(x[j-1], stepsize)
```

The following plot shows time series generated by three separate runs of the code listed above.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_time_series.png&quot;&gt;

The Python implementation of the algorithm summarized in the  **Algorithm** section is shown below,

```python
def metropolis_hastings(f, q, qsample, stepsize, nsample, x0):
    x = x0
    samples = numpy.zeros(nsample)
    for i in range(nsample):
        u = numpy.random.rand()
        y_star = qsample(x, stepsize)
        fy_star = f(y_star)
        fx = p(x)
        α = (fy_star*q(y_star, x, stepsize)) / (fx*q(x, y_star, stepsize))
        if u &lt; α:
            x = y_star
        samples[i] = x
    return samples
```

`metropolis_hastings(f, q, qsample, stepsize, nsample, x0)` takes five arguments as input that are
described in the table below.

| Argument | Description |
| :-----: | :---- |
| `f` | The target distribution which is assumed to support an interface taking a the previous state, `x`, as a floating point argument. In this example equation {% katex %}(12){% endkatex %} is used.|
| `q` | The proposal stochastic kernel which is assumed to support an interface taking the previous state, `x`, and the `stepsize` both as floating point arguments. In this example equation {% katex %}(15){% endkatex %} is used.|
| `qsample` | A random number generator based on the proposal stochastic kernel, {% katex %}q(x,y).{% endkatex %} It is assumed to support an interface taking the previous state, `x`, and the `stepsize` both as floating point arguments. The implementation used in this example is the function `qsample(x, stepsize)` previously discussed.|
| `stepsize` | The scale parameter used by the proposal distribution.|
| `nsample` | The number of samples desired.|
| `x0` | The initial target sample value.|

The execution of `metropolis_hastings(f, q, qsample, stepsize, nsample, x0)` begins by allocation of storage for
the result and initialization of the Markov Chain. A loop is then executed `nsample` times
where each iteration generates the next sample. Within the loop the acceptance random variable
with distribution {% katex %}\textbf{Uniform}(0,\ 1){% endkatex %} is generated using the `numpy` random number
generator. Next, a proposal sample is generated using `qsample(x, stepsize)` followed by evaluation
of the acceptance function {% katex %}\alpha(x,y){% endkatex %}. Finally, the acceptance criteria is
evaluated leading the sample being rejected or accepted.

## Simulations

Here the results of simulations performed using,

```python
 metropolis_hastings(f, q, qsample, stepsize, nsample, x0),
 ```

from the previous section are discussed. The simulations assume the
{% katex %}\textbf{Weibull}{% endkatex %} target distribution
from equation {% katex %}(12){% endkatex %} with {% katex %}\lambda=1{% endkatex %} and
{% katex %}k=5{% endkatex %} and the {% katex %}\textbf{Normal}{% endkatex %} stochastic kernel from
equation {% katex %}(14){% endkatex %}. First, simulations that scan 4 orders of magnitude of `stepsize`
with `x0` fixed are compared with the goal of determining the value leading to the best performance.
Next, simulations are performed with `stepsize` fixed that scan values of `x0` to determine the impact
of initial condition on performance. Finally, a method for removing autocorrelation from generated samples using Thinning is discussed.

The criteria for evaluating simulations include the time for
convergence of the first and seconds moments computed from samples to the target
distribution moments, the fit of the sampled distribution to the target PDF, the percentage of
accepted proposal samples and the timescale for the decay of time series autocorrelation.
It will be shown that `stepsize` is the only relevant parameter. The choice for `x0` will be seen
to have an impact that vanishes given sufficient time. Thus, the model has a single parameter of significance.

### Performance

The plot below shows the percentage of proposal samples accepted as a function of `stepsize` for
simulations with `stepsize` ranging from {% katex %}10^{-3}{% endkatex %} to {% katex %}10^{1}{% endkatex %}.
For all simulations `x0=1.0`. The simulation believed to be the best performing accepted {% katex %}82\%{% endkatex %}
of the proposed samples and had a stepsize of {% katex %}0.12{% endkatex %}. The two other simulations discussed
in this section as representative of small and large values of `stepsize` had acceptance
percentages of {% katex %}99\%{% endkatex %} and {% katex %}19\%{% endkatex %} for `stepsize` values of
{% katex %}0.01{% endkatex %} and {% katex %}1.33{% endkatex %} respectively. Each of this simulations is indicated in the plot below.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_acceptance.png&quot;&gt;

On examination of the plot it is seen that for `stepsize` smaller than
{% katex %}0.12{% endkatex %}, the simulations to the left of the orange symbol, the accepted percentage of
proposal samples very quickly approach {% katex %}100\%{% endkatex %} while for `stepsize` larger than
{% katex %}0.12{% endkatex %}, the simulations to the right of the orange symbol, the accepted
percentage approaches {% katex %}0\%{% endkatex %} as a power law.

To get a sense of why this happens the `stepsize` is compared to the standard deviation
of the target distribution computed from equation {% katex %}(13){% endkatex %}, using the assumed values for
{% katex %}\lambda{% endkatex %} and {% katex %}k{% endkatex %}, gives {% katex %}0.21{% endkatex %}.
This value is the same order of magnitude of the best performing `stepsize` determined from simulations.
Comparing the `stepsize` to the target standard deviation in the large and small limits
provides an interpretation of the results. For small `stepsize` relative to the target standard
deviation the proposal variance is much smaller then the target variance. Because of this the steps
taken by the proposal Markov Chain are small leading
to a exploration of the target distribution that never goes far from the initial value. The samples
produced will have the proposal distribution since nearly all proposals are accepted.
This is seen in the first of the following
plots where time series examples for different `stepsize` values for the last {% katex %}500{% endkatex %} steps
for a {% katex %}51000{% endkatex %} sample simulation are shown. The small variance seen in the first
plot is a consequence of the small `stepsize` leading to very small deviations from the initial value `x0=1`. In the
opposite limit where the `stepsize` becomes large relative to the target standard deviation the steps taken by the proposal
Markov Chain are so large that they are frequently rejected since low probability target events are oversampled. This effect is seen in
last time series plot shown below. There long runs where the series has a constant value are clearly visible. The
best value of `stepsize` relative to the target standard deviation occurs when they are about the same size. The middle plot
below has the optimal `stepsize` of {% katex %}0.12{% endkatex %} and accepted {% katex %}82\%{% endkatex %} of the proposed
samples. It clearly has a more authentic look than the other two simulations which are at extreme values of the
percentage accepted.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_time_series_stepsize_comparison.png&quot;&gt;

A measure of simulation performance is the rate of convergence of distribution moments computed from
samples to the
target distribution momements. The next two plots show convergence of the cumulative sample mean,
{% katex %}\mu{% endkatex %}, and standard deviation, {% katex %}\sigma{% endkatex %}, to the target
distribution values computed from
equation {% katex %}(13){% endkatex %} for three values of `stepsize` that compare
simulations at both the
small and large extremes with the optimal `stepsize` of {% katex %}0.12{% endkatex %}.
For both {% katex %}\mu{% endkatex %}
and {% katex %}\sigma{% endkatex %} the small `stepsize` example is clearly the worst performing. After
{% katex %}10^5{% endkatex %} time steps there is no indication of convergence. There is no significant difference  between the
other two simulations. Both are showing convergence after {% katex %}O(10^4){% endkatex %} samples.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_sigma_convergence_stepsize_comparison.png&quot;&gt;

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_mean_convergence_stepsize_comparison.png&quot;&gt;

A consequence of using a Markov Chain to generate samples is that autocorrelation is built into the model.
This is considered an undesirable artifact since in general independent and identically distributed samples
are desired. It follows that there is a preference for rapid decorrelation of samples. The following plot
shows the autocorrelation coefficient for the three values of `stepsize` previously discussed.
The autocorrelation coefficient of a time series, {% katex %}f{% endkatex %}, provides a measure of
*similarity* or *dependence* of the series past and future and is defined by,

{% katex display %}
\gamma_{\tau} = \frac{1}{\sigma_{f}^2}\sum_{n=0}^{t} \left(f_{n} - \mu_f \right) \left(f_{n+\tau} - \mu_f\right),
{% endkatex %}

where {% katex %}\mu_{f}{% endkatex %} and {% katex %}\sigma_{f}{% endkatex %} are the time series mean and
standard deviation respectively. Calculation of autocorrelation was discussed in a
[previous post]({{ site.baseurl }}{% link _posts/2018-08-25-discrete_cross_correlation_theorem.md %}).
The small `stepsize` simulation has a very slowly decaying autocorrelation. For time lags of up to 100
steps it has decayed by only a few precent. This behavior is expected since for small
`stepsize` the resulting samples are from the proposal Markov Chain, with stochastic
kernel shown in equation {% katex %}(15){% endkatex %}, which has an autocorrelation coefficient independent
of {% katex %}\tau{% endkatex %} given by {% katex %}\gamma_{\tau}=1{% endkatex %}.
The other simulations have a similar decorrelation rate of {% katex %}O(10){% endkatex %} time steps,
though for the larger `stepsize` the decorrelation rate is slightly faster.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_autocorrelation_convergence_stepsize_comparison.png&quot;&gt;

The following three plots compare histograms computed from simulations of {% katex %}10^5{% endkatex %} samples with the target
{% katex %}\textbf{Weibull}{% endkatex %} distribution from equation {% katex %}(12){% endkatex %} for the same `stepsize`
values used in the previous comparisons. The first plot shows the small `stepsize` simulation with a very high acceptance rate.
For this case the simulated histogram is not close to reproducing the target distribution. The last plot is the large `stepsize` simulation
with a very large rejection rate. When compared with optimal `stepsize` of {% katex %}0.12{% endkatex %} simulation shown in the middle plot
the larger `stepsize` simulation is not as smooth but is acceptable. The degraded performance of larger `stepsize` simulation
will be a consequence of rejection of many more proposal samples leading to long stretches of repeated values. For the
optimal `stepsize` simulation almost {% katex %}10{% endkatex %} times more samples are available
in the histogram calculation.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_sampled_pdf-99.png&quot;&gt;

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_sampled_pdf-82.png&quot;&gt;

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_sampled_pdf-19.png&quot;&gt;

In summary a collection of simulations using the Metropolis Hastings Sampling algorithm to sample a target
{% katex %}\textbf{Weibull}{% endkatex %} distribution using a {% katex %}\textbf{Normal}{% endkatex %}
proposal distribution have been performed that scan the `stepsize` parameter for a fixed initial value
of `x0=1.0` in an effort to determine the best performing `stepsize`. Best performing was determined by considering
the total percentage of accepted samples, the *quality* of the generated time series, the convergence of first
and second moments to the known target values, the decorrelation timescale and fit of sample histograms to
the target distribution. The best performing `stepsize` was found to have a value of
{% katex %}0.12{% endkatex %} which is near the standard deviation of the target distribution.
For values of `stepsize` smaller than the best
performing `stepsize` the performance was inferior on all counts. The number of accepted
proposals was high,
the time series look like the proposal distribution, convergence of moments is slow, samples
remain correlated
over long time scales and the distributions computed from samples do not converge to the target distribution.
When the same comparison is made to simulations with a larger `stepsize` the results were less conclusive.
Larger values of `stepsize` accept fewer proposal samples. This causes degradation of the time series since there
are many long runs of repeated values. In comparisons of convergence of distribution moments and autocorrelation
there was no significant differences but calculation of the distribution using histograms on sample data were not
as acceptable since an order of magnitude less data was used in the calculation because of the high rejection percentage.

### Burn In

In the previous section simulations were compared that scanned `stepsize` with `x0` fixed. Here
simulations with `stepsize` fixed that scan `x0` are discussed. The further `x0` is from the
target distribution mean the further displaced the initial state is from equilibrium so the
expectation is that a longer time is required to reach equilibrium. If
some knowledge of the target mean is available it should be used to minimize this relaxation period.
The time required to reach equilibrium is referred to as *burn in*. Typically the
burn in period of the simulation is considered and artifact and discarded with the aim of
improving the final result. The expectation then is that the simulation is generating *natural*
fluctuations about equilibrium.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_burnin-mean-convergence.png&quot;&gt;

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_burnin-sigma-convergence.png&quot;&gt;

The two plots above compare cumulative first and second moment calculations on simulated samples with
the target {% katex %}\textbf{Weibull}{% endkatex %} distribution values calculated from equation
{% katex %}(13){% endkatex %} using {% katex %}\lambda = 1{% endkatex %} and {% katex %}k=5{% endkatex %}. The obtained
mean and standard deviation are {% katex %}0.92{% endkatex %} and {% katex %}0.21{% endkatex %} respectively.
In the plots time to reach equilibrium in seen to increase with increasing displacement of `x0` from
{% katex %}0.92{% endkatex %}. For the simulation at the most extreme value of `x0` the time to reach equilibrium
is a factor of {% katex %}10{% endkatex %} longer than the simulation that reached equilibrium first.
For standard deviation the effect is even larger increasing the relaxation time by nearly a factor of
{% katex %}10^2{% endkatex %} when compared to the fastest relaxation time seen. There is also a very
large spike in the standard deviation that increases with displacement of `x0` from the target mean.

The following plot of the autocorrelation coefficient shows that time for sampled time series to
decorrelate is not impacted by the initial value of `x0`.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_burnin-autocorrelation.png&quot;&gt;

The next plot shows a comparison of the histogram computed from the worst performing simulation
with `x0=3.5` with the target distribution. The over representation of large low probability
samples induced by the large displacement of the initial condition is
apparent in the long right tail.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_sampled_pdf_burnin-x-3-5.png&quot;&gt;

In the next series of plots a *burn in* period of {% katex %}10^4{% endkatex %} time steps is assumed
and the data is excluded from calculations. This corresponds to removing
{% katex %}20\%{% endkatex %} of the samples. The magnitude of the adjustment
to equilibrium is significantly reduced. Within {% katex %}10^3{% endkatex %} time steps all
simulations for both moments are near their equilibrium values with no significant
difference in the convergence rate. The clear increase in the time of convergence to equilibrium
with displacement of `x0` from the equilibrium value seen when all samples are included has been eliminated.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_burnin-removed-mean-convergence.png&quot;&gt;

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_burnin_removed-sigma-convergence.png&quot;&gt;

The final plot compares the sample histogram with burn in removed for the simulation with
`x0=3.5` to the target distribution. It is much improved from the plot in which burn in was retained.
In fact it is comparable with the same plot obtained for a simulation where `x0=1` above.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_sampled_pdf_burnin-removed-x-3-5.png&quot;&gt;

### Thinning

It is desirable that sampling algorithms not introduce correlations between samples since
random number generators for a given distribution are expected to produce independent and identically distributed. Since Metropolis Hastings Sampling models generated
samples as a Markov Chain, autocorrelation is expected because the proposal stochastic kernel
depends on the previously generated sample. Thinning is a method for reducing autocorrelation
in sequence of generated samples. It is a simple algorithm that can be understood by considering
a time series {% katex %}\{x_{t}\}{% endkatex %} samples of length
{% katex %}N{% endkatex %}. Thinning discards samples that do not satisfy
{% katex %}t\ \mod\ {\eta}=0{% endkatex %}, where {% katex %}\eta{% endkatex %} is referred to as
the thinning interval. Discarding all but equally spaced samples increases the time
between the retained samples which can reduce autocorrelation.

The impact of Thinning on the appearance of the time series is illustrated below.
The first plot is from the original time series and the others illustrate increasing the
thinning interval. The first point in each plot is the same and the plot range is adjusted so that all
have {% katex %}500{% endkatex %} samples. A tendency of series values to infrequently change
from increasing to decreasing as time increases is an indication of autocorrelation. Comparison
of the original series with the thinned series illustrates this. The plot with
{% katex %}\eta=1{% endkatex %} may have runs of {% katex %}O(10){% endkatex %} samples
with a persistent increasing or decreasing trend which is consistent with decorrelation
time of {% katex %}O(10){% endkatex %} previously demonstrated. For increasing
{% katex %}\eta{% endkatex %} the length of increasing or decreasing trends clearly
decreases.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_thinning-time-series.png&quot;&gt;

The following plot confirms this intuition. The simulation samples are generated
using Metropolis Hastings with a {% katex %}\textbf{Weibull}{% endkatex %} target
distribution and {% katex %}\textbf{Normal}{% endkatex %} proposal distribution with `x0=1`
and the previously determined best performing `stepsize=0.12`. The burn in period samples
have also been discarded. A value of {% katex %}\eta=1{% endkatex %} corresponds
to not discarding any samples. It is seen that the decorrelation time scale decreases rapidly
with most of the reduction occurring by {% katex %}\eta=4.{% endkatex %}

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_thinning-thined-autocorrelation.png&quot;&gt;

Thinning has no impact on the rate of convergence of first and second moments computed from
samples to the target distribution values. This is shown in the following two plots which have
convergence rates of {% katex %}O(10^3){% endkatex %} samples as seen in the previous section
when only the burn in samples were discarded.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_thinning-mean-convergence.png&quot;&gt;

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_thinning-sigms-convergence.png&quot;&gt;

The following two plots compare histograms computed from samples with the target distribution for
different values of the thinning interval. The first plot shows the original series and the second
the result from thinned samples. The fit of the thinned plot is degraded but this will be due to the
smaller number on samples. The original series consists of {% katex %}4\times 10^4{% endkatex %}
samples and the thinned series {% katex %}6.6\times 10^3{% endkatex %}. It follows that if fairly
aggressive thinning is performed simulations may need to be run {% katex %}O(10){% endkatex %}
longer to obtain a sufficient set of samples.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_sampled_pdf_thinning-1.png&quot;&gt;

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_sampled_pdf_thinning-6.png&quot;&gt;

The following plot shows the results of a simulation {% katex %}5\times10^5{% endkatex %} samples
that is comparable with the result obtained without thinning.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/metropolis_hastings_sampling/normal_proposal_sampled_pdf_thinning-large-run-6.png&quot;&gt;

## Conclusions

The Metropolis Hastings Sampling algorithm provides a general method for generating samples for a
known target distribution using an available proposal sampler. The algorithm is similar to
[Rejection Sampling]({{ site.baseurl }}{% link _posts/2018-07-29-rejection_sampling.md %}) but instead of discarding rejected proposal samples Metropolis Hastings Sampling replicates the previous sample.
It also has a more complicated acceptance function that assumes the generated samples are a Markov Chain.
Metropolis Hastings Sampling is simple to implement but the theory describing how it works is more
sophisticated than that encountered in both
[Inverse CDF Sampling]({{ site.baseurl }}{% link _posts/2018-07-21-inverse_cdf_sampling.md %})
and [Rejection Sampling]({{ site.baseurl }}{% link _posts/2018-07-29-rejection_sampling.md %}).

The theoretical discussion began by deriving the stochastic kernel following from the assumptions
introduced by the rejection algorithm, equation {% katex %}(10){% endkatex %}.
Next, it was shown that if Time Reversal Symmetry were assumed for the stochastic kernel and target distribution,
equation {% katex %}(11){% endkatex %}, then the target distribution is the equilibrium distribution of the Markov Chain created by the stochastic kernel. Finally, the acceptance function,
equation {% katex %}(3){% endkatex %}, was derived using Time Reversal Symmetry.

A Python implementation of a Metropolis Hastings Sampler was presented and followed by discussion of an
example using a {% katex %}\textbf{Weibull}{% endkatex %} distribution as target and a
{% katex %}\textbf{Normal}{% endkatex %} distribution as proposal.
A parameterization of the proposal stochastic kernel using `setpsize` as the standard deviation
of the proposal distribution was described. The results of a series of simulations that varied `stepsize` for a fixed initial state, `x0`, over several orders of magnitude were presented.
It was shown that
the best performing simulations have `stepsize` that is about the same as the standard deviation
of the proposal distribution. This was followed by simulations that scanned `x0` for the
`stepsize` determined as best. It was shown that the best performing simulations have `x0` near
the mean of the target distribution but that if the first {% katex %}10^4{% endkatex %} samples
of the simulation were discarded `x0` can differ significantly from the target mean with no impact.
Autocorrelation of samples is a consequence of using a Markov Chain to model samples and
considered an undesirable artifact since independent identically distributed samples are desired.
Autocorrelation can be removed by Thinning the samples. It was shown that thinning intervals
of about {% katex %}\eta=5{% endkatex %} can produce samples with a very short decorrelation time
at the expense of requiring generation of more samples.

The best performing simulations using Metropolis Hastings Sampling have an acceptance rate of
about {% katex %}80\%{% endkatex %} and converge to target values in about {% katex %}O(10^3){% endkatex %} time steps. This is the same performance obtained using
[Rejection Sampling]({{ site.baseurl }}{% link _posts/2018-07-29-rejection_sampling.md %})
with a {% katex %}\textbf{Normal}{% endkatex %} proposal distribution.
The advantage offered by Metropolis Hastings Sampling is that it has a single arbitrary parameter.
Rejection sampling has two arbitrary parameters that can significantly impact performance for small changes. It follows that Metropolis Hastings Sampling can be considered more robust.</content><author><name>Troy Stribling</name></author><summary type="html">Metropolis Hastings Sampling is a method for obtaining samples for a known target probability distribution using samples from some other proposal distribution. It is similar to Rejection Sampling in providing a criteria for acceptance of a proposal sample as a target sample but instead of discarding the samples that do not meet the acceptance criteria the sample from the previous time step is replicated. Another difference is that Metropolis Hastings samples are modeled as a Markov Chain where the target distribution is the Markov Chain Equilibrium Distribution. As a consequence the previous sample is used as part of the acceptance criteria when generating the next sample. It will be seen this has the advantage of permitting adjustment of some proposal distribution parameters as each sample is generated, which in effect eliminates parameter inputs. This is is an improvement over Rejection Sampling, where it was previously shown that slight variations in proposal distribution parameters can significantly impact performance. A downside of the Markov Chain representation is that autocorrelation can develop in the samples which is not the case in Rejection Sampling.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/posts/metropolis_hastings_sampling/normal_proposal_acceptance.png" /></entry><entry><title type="html">Discrete Cross Correlation Theorem</title><link href="http://localhost:4000/2018/08/25/discrete_cross_correlation_theorem.html" rel="alternate" type="text/html" title="Discrete Cross Correlation Theorem" /><published>2018-08-25T00:00:00-07:00</published><updated>2018-08-25T00:00:00-07:00</updated><id>http://localhost:4000/2018/08/25/discrete_cross_correlation_theorem</id><content type="html" xml:base="http://localhost:4000/2018/08/25/discrete_cross_correlation_theorem.html">The [Cross Correlation Theorem](https://en.wikipedia.org/wiki/Cross-correlation) is similar to the more
widely known [Convolution Theorem](https://en.wikipedia.org/wiki/Convolution_theorem). The cross correlation
of two discrete finite time series {% katex %}\{f_0,\ f_1,\ f_2,\ldots\,\ f_{N-1}\}{% endkatex %} and
{% katex %}\{g_0,\ g_1,\ g_2,\ldots\,\ g_{N-1}\}{% endkatex %} is defined by,

{% katex display %}
\psi_t = \sum_{n=0}^{N-1} f_{n} g_{n+t}\ \ \ \ \ (1),
{% endkatex %}

where {% katex %}t{% endkatex %} is called the *time lag*. Cross correlation provides a measure of the similitude
of two time series when shifted by the time lag. A direct calculation of the cross correlation using the
equation above requires {% katex %}O(N^2){% endkatex %} operations. The Cross Correlation Theorem
provides a method for calculating cross correlation in {% katex %}O(NlogN){% endkatex %}
operations by use of the
[Fast Fourier Transform](https://en.wikipedia.org/wiki/Fast_Fourier_transform). Here the theoretical
background required to understand cross correlation calculations using the Cross Correlation Theorem is discussed.
Example calculations are performed and different implementations using the FFT libraries in `numpy` compared.
The important special case of the cross correlation called [Autocorrelation](https://en.wikipedia.org/wiki/Autocorrelation) is addressed in the final section.

&lt;!--more--&gt;

## Cross Correlation

Cross Correlation can be understood by considering the [Covariance](https://en.wikipedia.org/wiki/Covariance) of
two random variables, {% katex %}X{% endkatex %} and {% katex %}Y{% endkatex %}. Covariance is the
[Expectation](https://en.wikipedia.org/wiki/Expected_value) of the product of the deviations of the random variables
from their respective means,

{% katex display %}
\begin{aligned}
Cov(X,Y) &amp;= E\left[(X-E[X])(Y-E[Y])\right] \\
&amp;= E[XY] - E[X]E[Y].
\end{aligned}\ \ \ \ \ (2)
{% endkatex %}

Note that {% katex %}Cov(X,Y)=Cov(Y,X){% endkatex %} and if {% katex %}X{% endkatex %} and
{% katex %}Y{% endkatex %} are
[Independent Random Variables](https://en.wikipedia.org/wiki/Independence_(probability_theory))
{% katex %}E[XY]=E[X]E[Y]\ \implies\ Cov(X,Y)=0{% endkatex %}.
If {% katex %}X=Y{% endkatex %} the Covariance reduces to the [Variance](https://en.wikipedia.org/wiki/Variance),

{% katex display %}
\begin{aligned}
Var(X) &amp;= E\left[(X-E[X])^2\right] \\
&amp;= E[X^2] - \left(E[X]\right)^2.
\end{aligned}
{% endkatex %}

These two results are combined in the definition of the
[Correlation Coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient),

{% katex display %}
\rho_{XY} = \frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}.
{% endkatex %}

The correlation coefficient has a geometric interpretation leading to the conclusion that
{% katex %}-1\ \leq \rho_{XY}\ \leq 1{% endkatex %}. At the extreme values
{% katex %}X{% endkatex %} and {% katex %}Y{% endkatex %} are either the same or differ by a
multiple of {% katex %}-1{% endkatex %}. At the midpoint value, {% katex %}\rho_{XY}=0{% endkatex %},
{% katex %}X{% endkatex %} and {% katex %}Y{% endkatex %} are independent random variables. If follows that
{% katex %}\rho_{XY}{% endkatex %} provides a measure of possible *dependence* or *similarity* of two random variables.

Consider the first term in equation {% katex %}(2){% endkatex %} when a time series of samples
of {% katex %}X{% endkatex %} and {% katex %}Y{% endkatex %} of equal length are available,

{% katex display %}
\begin{aligned}
E[XY]&amp; \approx \frac{1}{N^2}\sum_{n=0}^{N-1}x_n y_n \\
&amp;\propto\ \psi_{0},
\end{aligned}
{% endkatex %}

if {% katex %}N{% endkatex %} is sufficiently large. Generalizing this result to arbitrary time shifts leads to
equation {% katex %}(1){% endkatex %}.

An important special case of the cross correlation is the autocorrelation which is defined a the cross
correlation of a time series with itself,

{% katex display %}
r_t = \sum_{n=0}^{N-1} x_{n} x_{n+t}\ \ \ \ \ (3).
{% endkatex %}

Building on the interpretation of cross correlation the autocorrelation is viewed as a measure of *dependence*
or *similarity* of the past and future of a time series. For a time lag of {% katex %}t=0{% endkatex %},

{% katex display %}
r_0\ \propto\ E\left[X^2\right].
{% endkatex %}

## Discrete Fourier Transform

This section will discuss properties of the Discrete Fourier Transform that are used in following sections.
The [Discrete Fourier Transform](https://en.wikipedia.org/wiki/Discrete_Fourier_transform) for a discrete periodic
time series of length {% katex %}N{% endkatex %}, {% katex %}\{f_0,\ f_1,\ f_2,\ldots,\ f_{N-1}\}{% endkatex %},
is defined by,

{% katex display %}
\begin{gathered}
f_{n} = \frac{1}{N}\sum_{k=0}^{N-1}F_{k}e^{2\pi i (k/N)n} \\
F_{k} = \sum_{n=0}^{N-1}f_{n}e^{-2\pi i (n/N)k},
\end{gathered}\ \ \ \ \ (4)
{% endkatex %}

where the expression for {% katex %}f_{n}{% endkatex %} is referred to the inverse transform and the one for
{% katex %}F_{k}{% endkatex %} the forward transform.

### Linearity

Both the forward and inverse transforms are [Linear Operators](http://mathworld.wolfram.com/LinearOperator.html).
An operator, {% katex %}\mathfrak{F}{% endkatex %}, is linear if the operation on a sum is equal the sum of the operations,

{% katex display %}
\mathfrak{F}(a+b) = \mathfrak{F}(a)+\mathfrak{F}(b)\ \ \ \ \ (5)
{% endkatex %}

To show this for the forward transform consider {% katex %}h_{n}=f_{n}+g_{n}{% endkatex %}, then,

{% katex display %}
\begin{aligned}
H_{k} &amp;= \sum_{n=0}^{N-1}h_{n}e^{-2\pi i (n/N)k} \\
&amp;= \sum_{n=0}^{N-1}\left(f_{n}+g_{n}\right)e^{-2\pi i (n/N)k} \\
&amp;= \sum_{n=0}^{N-1}f_{n} e^{-2\pi i (n/N)k} + \sum_{n=0}^{N-1} g_{n}e^{-2\pi i (n/N)k} \\
&amp;= F_{k} + G_{k}.
\end{aligned}
{% endkatex %}

Similarly it can be shown that the inverse transform is linear.

### Periodicity

Periodicity of the forward transform implies that,
{% katex display %}
F_{k+mN}=F_{k}\ \ \ \ \ (6),
{% endkatex %}
where {% katex %}m=\{\ldots,-2,\ -1,\ 0,\ 1,\ 2,\ldots\}{% endkatex %}.
To show that this is true first consider the case
{% katex %}m=1{% endkatex %},

{% katex display %}
\begin{aligned}
F_{k+N} &amp;= \sum_{n=0}^{N} f_{n}e^{-2\pi i (n/N)(k+N)} \\
&amp;= \sum_{n=0}^{N} f_{n} e^{-2\pi i(n/N)k}e^{-2\pi i n} \\
&amp;= \sum_{n=0}^{N} f_{n} e^{-2\pi i(n/N)k} \\
&amp;= F_{k},
\end{aligned}
{% endkatex %}

where the second step follows from, {% katex %}e^{2\pi i n} = 1,\ \forall\ n{% endkatex %}.

For an arbitrary value of {% katex %}m{% endkatex %},
{% katex display %}
\begin{aligned}
F_{k+mN} &amp;= \sum_{n=0}^{N} f_{n}e^{-2\pi i (n/N)(k+mN)} \\
&amp;= \sum_{n=0}^{N} f_{n} e^{-2\pi i(n/N)k}e^{-2\pi i nm} \\
&amp;= \sum_{n=0}^{N} f_{n} e^{-2\pi i(n/N)k} \\
&amp;= F_{k},
\end{aligned}
{% endkatex %}

since, {% katex %}e^{2\pi i mn} = 1,\ \forall\ m,\ n{% endkatex %}.

### Consequence of Real {% katex %}f_{n}{% endkatex %}

If {% katex %}f_{n}{% endkatex %} is real then {% katex %}f_{n}=f_{n}^{\ast}{% endkatex %}, where
{% katex %}\ast{% endkatex %} denotes the [Complex Conjugate](https://en.wikipedia.org/wiki/Complex_conjugate).
It follows that,

{% katex display %}
\begin{aligned}
f_{n} &amp;= f_{n}^{\ast} \\
&amp;= \left\{ \frac{1}{N}\sum_{k=0}^{N-1}F_{k}e^{2\pi i (k/N)n} \right\}^{\ast} \\
&amp;= \frac{1}{N}\sum_{k=0}^{N-1}F_{k}^{\ast}e^{-2\pi i (k/N)n}
\end{aligned}\ \ \ \ \ (7)
{% endkatex %}

Another interesting and related result is,

{% katex display %}
F_{-k} = F_{k}^{\ast}\ \ \ \ \ (8).
{% endkatex %}

which follows from,

{% katex display %}
\begin{aligned}
F_{-k} &amp;= \sum_{n=0}^{N-1} f_{n}e^{2\pi i (n/N)k} \\
&amp;= \sum_{n=0}^{N-1} f_{n}^{\ast}e^{2\pi i (n/N)k} \\
&amp;= \left\{ \sum_{n=0}^{N-1} f_{n}e^{-2\pi i (n/N)k}\right\}^{\ast} \\
&amp;=F_{k}^{\ast}.
\end{aligned}
{% endkatex %}

## Orthogonality of Fourier Basis

The Discrete Fourier Basis is the collection of functions,

{% katex display %}
\left\{e^{2\pi i(k/N)n}\right\},
{% endkatex %}

 where {% katex %}n = 0,\ 1,\ 2,\ldots,N-1{% endkatex %}. It forms an [Orthogonal Basis](https://en.wikipedia.org/wiki/Orthogonal_basis) since,

{% katex display %}
\frac{1}{N} \sum_{n=0}^{N-1} e^{2\pi \left[ (m-k)/N\right] n}\ =\ \delta_{mk} =
\begin{cases}
1 &amp; \text{if}\ m\ =\ k \\
0 &amp; \text{if}\ m\ \ne\  k
\end{cases}\ \ \ \ \ (9),
{% endkatex %}

where {% katex %}\delta_{mk}{% endkatex %} is the [Kronecker Delta](https://en.wikipedia.org/wiki/Kronecker_delta).
This result can be proven for {% katex %}m\ \ne\ k{% endkatex %} by noting that the sum in
equation {% katex %}(9){% endkatex %} is a [Geometric Series](https://en.wikipedia.org/wiki/Geometric_series),

{% katex display %}
\frac{1}{N} \sum_{n=0}^{N-1} e^{2\pi i \left[(m-k)/N \right] n} = \frac{1}{N} \frac{1-e^{2\pi i (m-k)}}{1-e^{2\pi i (m-k)/N}}.
{% endkatex %}

Since {% katex %}2\pi i(m-k){% endkatex %} is
always a multiple of {% katex %}2\pi{% endkatex %} it follows that the numerator is zero,

{% katex display %}
1-e^{2\pi i (m-k)} = 1-1 = 0.
{% endkatex %}

The denominator is zero only if {% katex %}m-k=lN{% endkatex %} where {% katex %}l{% endkatex %} is
an integer. This cannot happen since {% katex %}-(N-1)\ \leq m-k\ \leq N-1{% endkatex %}, so,

{% katex display %}
\sum_{n=0}^{N-1} e^{2\pi \left[ (m-k)/N\right] n}\ =\ 0
{% endkatex %}

If {% katex %}m=k{% endkatex %} then,

{% katex display %}
\sum_{n=0}^{N-1} e^{2\pi i \left[(m-k)/N \right] n} = \sum_{n=0}^{N-1} 1 = N,
{% endkatex %}

this proves that equation {% katex %}(9){% endkatex %}.

## The Cross Correlation Theorem

The Cross Correlation Theorem is a relationship between the Fourier Transform of the cross correlation,
{% katex %}\psi_{t}{% endkatex %} defined by equation {% katex %}(1){% endkatex %} and the
Fourier Transforms of the two time series used in the cross correlation calculation,

{% katex display %}
\Psi_{k} = F_{k}^{\ast}G_{k}\ \ \ \ \ (10),
{% endkatex %}

where,

{% katex display %}
\begin{aligned}
\Psi_{k} &amp;= \sum_{n=0}^{N-1}\psi_{n}e^{-2\pi i (n/N)k} \\
F_{k}^{\ast} &amp;= \sum_{n=0}^{N-1}f_{n}^{\ast}e^{2\pi i (n/N)k} \\
G_{k} &amp;= \sum_{n=0}^{N-1}g_{n}e^{-2\pi i (n/N)k}.
\end{aligned}
{% endkatex %}

To derive equation {% katex %}(10){% endkatex %} consider the Inverse Fourier Transform of the time
series {% katex %}f_{n}{% endkatex %} and {% katex %}g_{n+t}{% endkatex %},

{% katex display %}
\begin{gathered}
f_{n} = \frac{1}{N}\sum_{k=0}^{N-1}F_{k}^{\ast}e^{-2\pi i (k/N)n} \\
g_{n+t} = \frac{1}{N}\sum_{k=0}^{N-1}G_{k}e^{2\pi i (k/N)(n+t)},
\end{gathered}
{% endkatex %}

Substituting these expressions into equation {% katex %}(1){% endkatex %} gives,

{% katex display %}
\begin{aligned}
\psi_t &amp;= \sum_{n=0}^{N-1} f_{n} g_{n+t} \\
&amp;= \sum_{n=0}^{N-1} \left\{   \frac{1}{N}\sum_{k=0}^{N-1}F_{k}^{\ast}e^{-2\pi i (k/N)n} \right\} \left\{ \frac{1}{N}\sum_{m=0}^{N-1}G_{m}e^{2\pi i (m/N)(n+t)} \right\} \\
&amp;= \frac{1}{N}\sum_{k=0}^{N-1}\sum_{m=0}^{N-1} F_{k}^{\ast}G_{m} e^{2\pi i (t/N)m} \frac{1}{N} \sum_{n=0}^{N-1} e^{2\pi i \left[(m-k)/N \right] n} \\
&amp;= \frac{1}{N}\sum_{k=0}^{N-1}\sum_{m=0}^{N-1} F_{k}^{\ast}G_{m} e^{2\pi i (t/N)m} \delta_{mk} \\
&amp;= \frac{1}{N}\sum_{k=0}^{N-1} F_{k}^{\ast}G_{k} e^{2\pi i (t/N)k},
\end{aligned}
{% endkatex %}

where the second step follows from equation {% katex %}(9){% endkatex %}. Equation {% katex %}(10){% endkatex %} follows by taking the Fourier Transform of the previous result,

{% katex display %}
\begin{aligned}
\Psi_{k} &amp;= \sum_{t=0}^{N-1}\psi_{t}e^{-2\pi i (t/N)k} \\
&amp;= \sum_{t=0}^{N-1} \left\{ \frac{1}{N}\sum_{k=0}^{N-1} F_{k}^{\ast}G_{k} e^{2\pi i (t/N)m} \right\}e^{-2\pi i (t/N)k} \\
&amp;= \sum_{m=0}^{N-1} F_{m}^{\ast}G_{m} \frac{1}{N} \sum_{t=0}^{N-1} e^{2\pi i \left[(m-k)/N)\right]t} \\
&amp;= \sum_{m=0}^{N-1} F_{m}^{\ast}G_{m} \delta_{mk} \\
&amp;= F_{k}^{\ast}G_{k},
\end{aligned}
{% endkatex %}

proving the Cross Correlation Theorem defined by equation {% katex %}(10){% endkatex %}.

## Discrete Fourier Transform Example

This section will work through an example calculation of a discrete Fourier Transform that can be worked
out by hand. The manual calculations will be compared with calculations performed using the FFT library
from `numpy`.

The Discrete Fourier Transform of a time series, represented by the column vector {% katex %}f{% endkatex %},
into a column vector of Fourier coefficients, {% katex %}\overline{f}{% endkatex %}, can be represented by the linear
equation,

{% katex display %}
\overline{f} = Tf,
{% endkatex %}

where {% katex %}T{% endkatex %} is the transform matrix computed from the Fourier basis functions.
Each element of the matrix is the value of the basis function used in the calculation.
It is assumed that the time series contains only {% katex %}4{% endkatex %} points so that
{% katex %}T{% endkatex %} will be a {% katex %}4\times 4{% endkatex %} matrix. The transform
matrix only depends on the number of elements in the time series vector and is given by,

{% katex display %}
T=
\begin{pmatrix}
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; e^{-i\pi/2} &amp; e^{-i\pi} &amp; e^{-i3\pi/2} \\
1 &amp; e^{-i\pi} &amp; e^{-i2\pi} &amp; e^{-i3\pi} \\
1 &amp; e^{-i3\pi/2} &amp; e^{-i3\pi} &amp; e^{-i9\pi/2}
\end{pmatrix} =
\begin{pmatrix}
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; -i &amp; -1 &amp; i \\
1 &amp; -1 &amp; 1 &amp; -1 \\
1 &amp; i &amp; -1 &amp; -i
\end{pmatrix} \ \ \ \ \ (11)
{% endkatex %}

Assume an example time series of,

{% katex display %}
f =
\begin{pmatrix}
8 \\
4 \\
8 \\
0
\end{pmatrix}.
{% endkatex %}

It follows that,

{% katex display %}
\begin{aligned}
\begin{pmatrix}
\overline{f_1} \\
\overline{f_2} \\
\overline{f_3} \\
\overline{f_4}
\end{pmatrix}
&amp;=
\begin{pmatrix}
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; -i &amp; -1 &amp; i \\
1 &amp; -1 &amp; 1 &amp; -1 \\
1 &amp; i &amp; -1 &amp; -i
\end{pmatrix}
\begin{pmatrix}
8 \\
4 \\
8 \\
0
\end{pmatrix} \\
&amp;=
\begin{pmatrix}
20 \\
-4i \\
12 \\
4i
\end{pmatrix}
\end{aligned}\ \ \ \ \ (12)
{% endkatex %}

The Python code listing below uses the FFT implementation from `numpy` to confirm the calculation of
equation {% katex %}(12){% endkatex %}. It first defines the time series example data
{% katex %}f{% endkatex %}. The Fourier Transform is then used to compute
{% katex %}\overline{f}{% endkatex %}.

```python
In [1]: import numpy
In [2]: f = numpy.array([8, 4, 8, 0])
In [3]: numpy.fft.fft(f)
Out[3]: array([20.+0.j,  0.-4.j, 12.+0.j,  0.+4.j])
```
## Cross Correlation Theorem Example

This section will work through an example calculation of cross correlation using the Cross Correlation Theorem
with the goal of verifying an implementation of the algorithm in Python. Here use will be made of the
time series vector {% katex %}f{% endkatex %} and the transform matrix {% katex %}T{% endkatex %}
discussed in the previous section. An additional time series vector also needs to be considered, let,

{% katex display %}
g =
\begin{pmatrix}
6 \\
3 \\
9 \\
3
\end{pmatrix}.
{% endkatex %}

First, consider a direct calculation of the cross correlation,
{% katex %}\psi_t = \sum_{n=0}^{N-1} f_{n} g_{n+t}{% endkatex %}. The following python function
`cross_correlate_sum(x, y)` implements the required summation.

```python
In [1]: import numpy
In [2]: def cross_correlate_sum(x, y):
   ...:     n = len(x)
   ...:     correlation = numpy.zeros(len(x))
   ...:     for t in range(n):
   ...:         for k in range(0, n - t):
   ...:             correlation[t] += x[k] * y[k + t]
   ...:     return correlation
   ...:

In [3]: f = numpy.array([8, 4, 8, 0])
In [4]: g = numpy.array([6, 3, 9, 3])
In [5]: cross_correlate_sum(f, g)
Out[5]: array([132.,  84.,  84.,  24.])
```

`cross_correlate_sum(x, y)` takes two vectors, `x` and `y`, as arguments. It assumes that `x` and `y` are equal length and after allocating storage for the result performs the double summation required to compute the cross
correlation for all possible time lags, returning the result. It is also seen that
{% katex %}O(N^2){% endkatex %} operations are required to perform the calculation, where
{% katex %}N{% endkatex %} is the length of the input vectors.

Verification of following results requires a manual calculation. A method of organizing the calculation to facilitate  
this is shown in table below. The table rows are constructed from the elements of
{% katex %}f_{n}{% endkatex %} and the time lagged
elements of {% katex %}g_{n+t}{% endkatex %} for each value {% katex %}t{% endkatex %}.
The column is indexed by the element number
{% katex %}n{% endkatex %}. The time lag shift performed on the vector {% katex %}g_{n+t}{% endkatex %} results
in the translation of the components to the left that increases for each row as the time lag increases. Since the number of elements in
{% katex %}f{% endkatex %} and {% katex %}g{% endkatex %} is finite the time lag shift will lead to some
elements not participating in {% katex %}\psi_{t}{% endkatex %} for some time lag values. If there is no element
in the table at a position the value of {% katex %}f{% endkatex %} or {% katex %}g{% endkatex %} at that position
is assumed to be {% katex %}0{% endkatex %}.

| {% katex %}n{% endkatex %}      |     |     |     |  0  |  1  |  2  |  3 |
| :---: | :---:  | :---:  | :---: | :---:  | :---:  | :---: | :---: |
| {% katex %}f_{n}{% endkatex %}  |     |     |     |  8  |  4  |  8  |  0  |
| {% katex %}g_{n}{% endkatex %}  |     |     |     |  6  |  3  |  9  |  3  |
| {% katex %}g_{n+1}{% endkatex %}|     |     |  6  |  3  |  9  |  3  |     |
| {% katex %}g_{n+2}{% endkatex %}|     |  6  |  3  |  9  |  3  |     |     |
| {% katex %}g_{n+3}{% endkatex %}|  6  |  3  |  9  |  3  |     |     |     |

The cross correlation, {% katex %}\psi_t{% endkatex %}, for a value of the time lag,
{% katex %}t{% endkatex %}, is computed for each {% katex %}n{% endkatex %} by multiplication
of {% katex %}f_{n}{% endkatex %} and {% katex %}g_{n+t}{% endkatex %} and summing the results.
The outcome of this calculation is shown as the column vector
{% katex %}\psi{% endkatex %} below where each row corresponds to a different time lag value.

{% katex display %}
\psi =
\begin{pmatrix}
8\cdot 6 + 4\cdot 3 + 8\cdot 9 + 0\cdot 3 \\
8\cdot 3 + 4\cdot 9 + 8\cdot 3 \\
8\cdot 9 + 4\cdot 3 \\
8\cdot 3
\end{pmatrix}
=
\begin{pmatrix}
132 \\
84 \\
84 \\
24
\end{pmatrix}\ \ \ \ \ \ (13)
{% endkatex %}

The result is the same as determined by `cross_correlate_sum(x,y)`.

Now that an expectation of a result is established it can be compared with the
a calculation using using the Cross Correlation Theorem from equation {% katex %}(10){% endkatex %}
where {% katex %}f{% endkatex %} and {% katex %}g{% endkatex %} are represented by Discrete Fourier
Series. It was previously shown that the Fourier representation is periodic, see
equation {% katex %}(6){% endkatex %}. It follows that the time lag shifts of
{% katex %}g_{n+t}{% endkatex %} will by cyclic as shown in the calculation table below.

| {% katex %}n{% endkatex %}      |  0  |  1  |  2  |  3  |
| :---: | :---:  | :---:  | :---: | :---: |
| {% katex %}f_{n}{% endkatex %}  |  8  |  4  |  8  |  0  |
| {% katex %}g_{n}{% endkatex %}  |  6  |  3  |  9  |  3  |
| {% katex %}g_{n+1}{% endkatex %}|  3  |  9  |  3  |  6  |
| {% katex %}g_{n+2}{% endkatex %}|  9  |  3  |  6  |  3  |
| {% katex %}g_{n+3}{% endkatex %}|  3  |  6  |  3  |  9  |

Performing the calculation following the steps previously described has the following outcome,

{% katex display %}
\psi =
\begin{pmatrix}
8\cdot 6 + 4\cdot 3 + 8\cdot 9 + 0\cdot 3 \\
8\cdot 3 + 4\cdot 9 + 8\cdot 3 + 0\cdot 6 \\
8\cdot 9 + 4\cdot 3 + 8\cdot 6 + 0\cdot 3 \\
8\cdot 3 + 4\cdot 6 + 8\cdot 3 + 0\cdot 9
\end{pmatrix}
=
\begin{pmatrix}
132 \\
84 \\
132 \\
72
\end{pmatrix}.
{% endkatex %}

This is different from what was obtained from a direct evaluation of the cross correlation sum. Even though
the result is different the calculation could be correct since periodicity of {% katex %}f{% endkatex %}
and {% katex %}g{% endkatex %} was not assumed when the sum was evaluated. Below a calculation
using the Cross Correlation Theorem implemented in Python is shown.

```python
In [1]: import numpy
In [2]: f = numpy.array([8, 4, 8, 0])
In [3]: g = numpy.array([6, 3, 9, 3])
In [4]: f_bar = numpy.fft.fft(f)
In [5]: g_bar = numpy.fft.fft(g)
In [6]: numpy.fft.ifft(f_bar * g_bar)
Out[6]: array([132.+0.j,  72.+0.j, 132.+0.j,  84.+0.j])
```

In the calculation {% katex %}f{% endkatex %} and {% katex %}g{% endkatex %} are defined and their Fourier Transforms
are computed. The Cross Correlation Theorem is then used to compute the Fourier Transform of the cross correlation, which is then inverted. The result obtained is the same as obtained in the
manual calculation verifying the results. Since the calculations seem to be correct the problem must be that
periodicity of the Fourier representations {% katex %}f{% endkatex %} and {% katex %}g{% endkatex %} was
not handled properly. This analysis *artifact* is called [aliasing](https://en.wikipedia.org/wiki/Aliasing).
The following example attempts to correct for this problem.

The cross correlation calculation table for periodic {% katex %}f{% endkatex %} and
{% katex %}g{% endkatex %} can be made to resemble the table for the nonperiodic case by
padding the end of the vectors with {% katex %}N-1{% endkatex %} zeros, where {% katex %}N{% endkatex %} is
the vector length, creating a new periodic vector of length {% katex %}2N-1{% endkatex %}. This
new construction is shown below.

| {% katex %}n{% endkatex %}      |     |     |     |  0  |  1  |  2  |  3  |  4  |  5  |  6  |
| :---: | :---:  | :---:  | :---: | :---:  | :---:  | :---: | :---: | :---: | :---: | :---: | :---: |
| {% katex %}f_{n}{% endkatex %}  |     |     |     |  8  |  4  |  8  |  0  |     |     |     |
| {% katex %}g_{n}{% endkatex %}  |     |     |     |  6  |  3  |  9  |  3  |  0  |  0  |  0  |
| {% katex %}g_{n+1}{% endkatex %}|     |     |  6  |  3  |  9  |  3  |  0  |  0  |  0  |  6  |
| {% katex %}g_{n+2}{% endkatex %}|     |  6  |  3  |  9  |  3  |  0  |  0  |  0  |  6  |  3  |
| {% katex %}g_{n+3}{% endkatex %}|  6  |  3  |  9  |  3  |  0  |  0  |  0  |  6  |  3  |  9  |
| {% katex %}g_{n+4}{% endkatex %}|  3  |  9  |  3  |  0  |  0  |  0  |  6  |  3  |  9  |  3  |
| {% katex %}g_{n+5}{% endkatex %}|  9  |  3  |  0  |  0  |  0  |  6  |  3  |  9  |  3  |  0  |
| {% katex %}g_{n+6}{% endkatex %}|  3  |  0  |  0  |  0  |  6  |  3  |  9  |  3  |  0  |  0  |

It follows that,

{% katex display %}
\psi =
\begin{pmatrix}
8\cdot 6 + 4\cdot 3 + 8\cdot 9 + 3\cdot 0 \\
8\cdot 3 + 4\cdot 9 + 8\cdot 3 + 0\cdot 0 \\
8\cdot 9 + 4\cdot 3 + 8\cdot 0 + 0\cdot 0 \\
8\cdot 3 + 4\cdot 0 + 8\cdot 0 + 0\cdot 0 \\
8\cdot 0 + 4\cdot 0 + 8\cdot 0 + 0\cdot 3 \\
8\cdot 0 + 4\cdot 0 + 8\cdot 6 + 0\cdot 3 \\
8\cdot 0 + 4\cdot 6 + 8\cdot 3 + 0\cdot 9
\end{pmatrix}
=
\begin{pmatrix}
132 \\
84 \\
84 \\
24 \\
0 \\
48 \\
48
\end{pmatrix}
{% endkatex %}

The first {% katex %}N{% endkatex %} elements of this result are the same as obtained calculating the sum
directly. The same result is achieved by discarding the last {% katex %}N-1{% endkatex %} elements.
Verification is shown below where the previous example is extended by padding the tail of both
{% katex %}f{% endkatex %} and {% katex %}g{% endkatex %} with three zeros.

```python
In [1]: import numpy
In [2]: f = numpy.array([8, 4, 8, 0])
In [3]: g = numpy.array([6, 3, 9, 3])
In [4]: f_bar = numpy.fft.fft(numpy.concatenate((f, numpy.zeros(len(f)-1))))
In [5]: g_bar = numpy.fft.fft(numpy.concatenate((g, numpy.zeros(len(g)-1))))
In [6]: numpy.fft.ifft(numpy.conj(f_bar) * g_bar)
Out[7]:
array([1.3200000e+02+0.j, 8.4000000e+01+0.j, 8.4000000e+01+0.j,
       2.4000000e+01+0.j, 4.0602442e-15+0.j, 4.8000000e+01+0.j,
       4.8000000e+01+0.j])
```
The following function, `cross_correlate(x, y)`, generalizes the calculation to vectors of arbitrary but equal lengths.

```python
def cross_correlate(x, y):
    n = len(x)
    x_padded = numpy.concatenate((x, numpy.zeros(n-1)))
    y_padded = numpy.concatenate((y, numpy.zeros(n-1)))
    x_fft = numpy.fft.fft(x_padded)
    y_fft = numpy.fft.fft(y_padded)
    h_fft = numpy.conj(x_fft) * y_fft
    cc = numpy.fft.ifft(h_fft)
    return cc[0:n]
```

## Autocorrelation

The autocorrelation, defined by equation {% katex %}(3){% endkatex %}, is the special case of the
cross correlation of a time series with itself. It provides a measure of the *dependence* or
*similarity* of its past and future. The version of the Cross Correlation Theorem for autocorrelation is
given by,

{% katex display %}
R_{k} = F^{\ast}_{k}F_{k} = {\mid F_{k} \mid}^{2}\ \ \ \ \ (14).
{% endkatex %}

{% katex %}R_{k}{% endkatex %} is the *weight* of each of the coefficients in the Fourier Series
representation of the time series and is known as the [Power Spectrum](https://en.wikipedia.org/wiki/Spectral_density).

When discussing the autocorrelation of a time series, {% katex %}f{% endkatex %}, the autocorrelation coefficient is
useful,

{% katex display %}
\gamma_{\tau} = \frac{1}{\sigma_{f}^2}\sum_{n=0}^{t} \left(f_{n} - \mu_f \right) \left(f_{n+\tau} - \mu_f\right)\ \ \ \ \ (15),
{% endkatex %}

where {% katex %}\mu_{f}{% endkatex %} and {% katex %}\sigma_{f}{% endkatex %} are the time series mean and
standard deviation respectively. Below a Python implementation calculating the autocorrelation coefficient
is given.

```python
def autocorrelate(x):
    n = len(x)
    x_shifted = x - x.mean()
    x_padded = numpy.concatenate((x_shifted, numpy.zeros(n-1)))
    x_fft = numpy.fft.fft(x_padded)
    r_fft = numpy.conj(x_fft) * x_fft
    ac = numpy.fft.ifft(r_fft)
    return ac[0:n]/ac[0]
```

`autocorrelate(x)` takes a single argument, `x`, that is the time series used in the calculation.
The function first shifts
`x` by its mean, then adds padding to remove aliasing and computes its FFT. Equation {% katex %}(14){% endkatex %} is
next used to compute the Discrete Fourier Transform of the autocorrelation which is inverted. The final result is
normalized by the zero lag autocorrelation which equals {% katex %}\sigma_f^2{% endkatex %}.

### AR(1) Equilibrium Autocorrelation

The equilibrium properties of the AR(1) random process are discussed in some detail in
[Continuous State Markov Chain Equilibrium]({{ site.baseurl }}{% link _posts/2018-08-16-continuous_state_markov_chain_equilibrium.md %}).
AR(1) is defined by the difference equation,

{% katex display %}
X_{t} = \alpha X_{t-1} + \varepsilon_{t}\ \ \ \ \ (16),
{% endkatex %}

where {% katex %}t=0,\ 1,\ 2,\ldots{% endkatex %} and the {% katex %}\varepsilon_{t}{% endkatex %} are identically
distributed independent {% katex %}\textbf{Normal}(0,\ \sigma^2){% endkatex %} random variables.

The
equilibrium mean and standard deviation, {% katex %}\mu_E{% endkatex %} and {% katex %}\sigma_E{% endkatex %} are given by,

{% katex display %}
\begin{gathered}
\mu_{E} = 0 \\
\sigma_{E} = \frac{\sigma^2}{1 - \alpha^2}.
\end{gathered}\ \ \ \ \ (17)
{% endkatex %}

The equilibrium autocorrelation with time lag {% katex %}\tau{% endkatex %} is defined by,

{% katex display %}
r_{\tau}^{E} = \lim_{t\to\infty} E\left[X_t X_{t+\tau} \right]
{% endkatex %}

If equation {% katex %}(16){% endkatex %} is used to evaluate a few steps beyond an arbitrary time {% katex %}t{% endkatex %}
it is seen that,

{% katex display %}
\begin{aligned}
X_{t+1} &amp;= \alpha X_t + \varepsilon_{t+1} \\
X_{t+2} &amp;= \alpha X_{t+1} + \varepsilon_{t+2} \\
X_{t+3} &amp;= \alpha X_{t+2} + \varepsilon_{t+3}.
\end{aligned}
{% endkatex %}

Substituting the equation for {% katex %}t+1{% endkatex %} into the equation for {% katex %}t+2{% endkatex %} and that
result into the equation for {% katex %}t+3{% endkatex %} gives,

{% katex display %}
X_{t+3} = \alpha^{3} X_t + \sum_{n=1}^{3}\alpha^{n-1} \varepsilon_{t+n}.
{% endkatex %}

If this procedure is continued for {% katex %}\tau{% endkatex %} steps the following is obtained,

{% katex display %}
X_{t+\tau} = \alpha^{\tau} X_t + \sum_{n=1}^{\tau}\alpha^{n-1} \varepsilon_{t+n}.
{% endkatex %}

It follows that the autocorrelation is given by,

{% katex display %}
\begin{aligned}
r_{\tau} &amp;= E\left[X_t X_{t+\tau} \right] \\
&amp;=E\left[ X_{t}\left( \alpha^{\tau} X_t + \sum_{n=1}^{\tau}\alpha^{n-1} \varepsilon_{t+n} \right) \right] \\
&amp;= E\left[ \alpha^{\tau} X_t^2 + \sum_{n=1}^{\tau}\alpha^{n-1} X_t \varepsilon_{t+n}\right] \\
&amp;= \alpha^{\tau} E\left[X_t^2\right] + \sum_{n=1}^{\tau}\alpha^{n-1} E\left[ X_t \varepsilon_{t+n}\right].
\end{aligned}
{% endkatex %}

To go further the summation in the last step needs to be evaluated. In a
[previous post]({{ site.baseurl }}{% link _posts/2018-08-16-continuous_state_markov_chain_equilibrium.md %}) it was
shown that,

{% katex display %}
X_t = \alpha^t X_{0} + \sum_{i=1}^t \alpha^{t-i} \varepsilon_{i}.
{% endkatex %}

Using this result the summation term becomes,

{% katex display %}
\begin{aligned}
E\left[ X_t \varepsilon_{t+n}\right] &amp;= E\left[ \alpha^t X_{0}\varepsilon_{t+n} + \sum_{i=1}^t \alpha^{t-i} \varepsilon_{i}\varepsilon_{t+n} \right] \\
&amp;= \alpha^{t} X_0 E\left[ \varepsilon_{t+n} \right] + \sum_{i=1}^{t} \alpha^{t-i} E\left[ \varepsilon_{i} \varepsilon_{t+n} \right] \\
&amp;= 0,
\end{aligned}
{% endkatex %}

since the {% katex %}\varepsilon_{t}{% endkatex %} are independent and identically distributed random variables. It follows that,

{% katex display %}
\begin{aligned}
r_{\tau} &amp;= E\left[X_t X_{t+\tau} \right] \\
&amp;= \alpha^{\tau} E\left[X_t^2\right]
\end{aligned}
{% endkatex %}

Evaluation of the equilibrium limit gives,

{% katex display %}
\begin{aligned}
r_{\tau}^{E} &amp;= \lim_{t\to\infty} E\left[X_t X_{t+\tau} \right] \\
&amp;= \lim_{t\to\infty} \alpha^{\tau} E\left[X_t^2\right] \\
&amp;= \alpha^{\tau} \sigma_{E}^{2}.
\end{aligned}
{% endkatex %}

The last step follows from {% katex %}(17){% endkatex %} by assuming that
{% katex %}\mid\alpha\mid\ &lt; 1{% endkatex %} so that {% katex %}\mu_{E}{% endkatex %} and
{% katex %}\sigma_{E}{% endkatex %}
are finite. A simple form of the autocorrelation coefficient in the equilibrium limit
follows from equation {% katex %}(15){% endkatex %},

{% katex display %}
\begin{aligned}
\gamma_{\tau}^{E} &amp;= \frac{r_{\tau}}{\sigma^2_E} \\
&amp;= \alpha^{\tau}
\end{aligned}\ \ \ \ \ (18).
{% endkatex %}

{% katex %}\gamma_{\tau}^{E}{% endkatex %}
remains finite for increasing {% katex %}\tau{% endkatex %} only for {% katex %}\mid\alpha\mid\ \leq\ 1{% endkatex %}.

### AR(1) Simulations

In this section the results obtained for AR(1) equilibrium autocorrelation in the previous section will be compared with
simulations. Below an implementation in Python of an AR(1) simulator based on the difference equation representation from
equation {% katex %}(16){% endkatex %} is listed.

```python
def ar_1_series(α, σ, x0=0.0, nsamples=100):
    samples = numpy.zeros(nsamples)
    ε = numpy.random.normal(0.0, σ, nsamples)
    samples[0] = x0
    for i in range(1, nsamples):
        samples[i] = α * samples[i-1] + ε[i]
    return samples
```

The function `ar_1_series(α, σ, x0, nsamples)` takes four arguments: `α` and `σ` from equation {% katex %}(16){% endkatex %},
the initial value of {% katex %}x{% endkatex %}, `x0`, and the number of desired samples, `nsamples`. It begins by allocating storage
for the sample output followed by generation of `nsamples` values of {% katex %}\varepsilon \sim \textbf{Normal}(0,\ \sigma^2){% endkatex %}
with the requested standard deviation, {% katex %}\sigma{% endkatex %}.
The samples are then created using the AR(1 ) difference equation, equation {% katex %}(5){% endkatex %}.

The plots below show examples of simulated time series with {% katex %}\sigma=1{% endkatex %} and values of
{% katex %}\alpha{% endkatex %} satisfying {% katex %}\alpha\ &lt;\ 1{% endkatex %}.
It is seen that for smaller {% katex %}\alpha{% endkatex %} values the series more frequently change direction
and have smaller variance. This is expected from equation {% katex %}(17){% endkatex %}.

&lt;div style=&quot;text-align:center;&quot;&gt;
  &lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/discrete_cross_correlation_theorem/ar1_alpha_sample_comparison.png&quot;&gt;
&lt;/div&gt;

The next series of plots compare the autocorrelation coefficient from equation {% katex %}(18){% endkatex %}, obtained in
the equilibrium limit, with an autocorrelation coefficient calculation using the previously discussed `autocorrelate(x)` function on
the generated sample data. Recall that `autocorrelate(x)` performs a calculation using the Cross Correlation Theorem.
Equation {% katex %}(18){% endkatex %} does a good job of capturing the time scale for the series to become uncorrelated.

&lt;div style=&quot;text-align:center;&quot;&gt;
  &lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/discrete_cross_correlation_theorem/ar1_alpha_equilibrium_autocorrelation_comparison.png&quot;&gt;
&lt;/div&gt;

## Conclusions

The Discrete Cross Correlation Theorem provides a more efficient method of calculating time series
correlations than directly evaluating the sums. For a time series of length N it decreases the cost
of the calculation from {% katex %}O(N^2){% endkatex %} to {% katex %}O(NlogN){% endkatex %} by
use of the Fast Fourier Transform.
An interpretation of the cross correlation as the time lagged covariance of two random variables was presented
and followed by a discussion of the properties of Discrete Fourier Transforms needed to prove the
Cross Correlation Theorem. After building sufficient tools the theorem was derived by application of the
Discrete Fourier Transform to equation {% katex %}(1){% endkatex %}, which defines cross correlation.
An example manual calculation of a Discrete Fourier Transform was performed and compared with a calculation
using the FFT library form `numpy`. Next, manual calculations of cross correlation using a tabular method
to represent the summations were presented and followed by a calculation using the Discrete
Cross Correlation Theorem which illustrated the problem of aliasing. The next example calculation eliminated
aliasing and recovered a result equal to the direct calculation of the summations.
A *dealiased* implementation using `numpy` FFT libraries was then presented. Finally,
the Discrete Cross Correlation Theorem for the special case of the autocorrelation was
discussed and a `numpy` FFT implementation was provided and followed by an example calculation using the AR(1)
random process. In conclusion the autocorrelation coefficient in the equilibrium limit for AR(1) was evaluated
and shown to be finite only for values of the AR(1) parameter that satisfy
{% katex %}\mid\alpha\mid\ &lt; \ 1{% endkatex %}. This result is compared to direct simulations and shown to
provide a good estimate of the decorrelation time of the process.</content><author><name>Troy Stribling</name></author><summary type="html">The Cross Correlation Theorem is similar to the more widely known Convolution Theorem. The cross correlation of two discrete finite time series {f0, f1, f2,… fN−1}\{f_0,\ f_1,\ f_2,\ldots\,\ f_{N-1}\}{f0​, f1​, f2​,… fN−1​} and {g0, g1, g2,… gN−1}\{g_0,\ g_1,\ g_2,\ldots\,\ g_{N-1}\}{g0​, g1​, g2​,… gN−1​} is defined by, ψt=∑n=0N−1fngn+t     (1), \psi_t = \sum_{n=0}^{N-1} f_{n} g_{n+t}\ \ \ \ \ (1), ψt​=n=0∑N−1​fn​gn+t​     (1), where ttt is called the time lag. Cross correlation provides a measure of the similitude of two time series when shifted by the time lag. A direct calculation of the cross correlation using the equation above requires O(N2)O(N^2)O(N2) operations. The Cross Correlation Theorem provides a method for calculating cross correlation in O(NlogN)O(NlogN)O(NlogN) operations by use of the Fast Fourier Transform. Here the theoretical background required to understand cross correlation calculations using the Cross Correlation Theorem is discussed. Example calculations are performed and different implementations using the FFT libraries in numpy compared. The important special case of the cross correlation called Autocorrelation is addressed in the final section.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/posts/discrete_cross_correlation_theorem/ar1_alpha_equilibrium_autocorrelation_comparison.png" /></entry><entry><title type="html">Continuous State Markov Chain Equilibrium</title><link href="http://localhost:4000/2018/08/16/continuous_state_markov_chain_equilibrium.html" rel="alternate" type="text/html" title="Continuous State Markov Chain Equilibrium" /><published>2018-08-16T00:00:00-07:00</published><updated>2018-08-16T00:00:00-07:00</updated><id>http://localhost:4000/2018/08/16/continuous_state_markov_chain_equilibrium</id><content type="html" xml:base="http://localhost:4000/2018/08/16/continuous_state_markov_chain_equilibrium.html">A [Markov Chain](https://en.wikipedia.org/wiki/Markov_chain) is a sequence of states
where transitions between states occur ordered in time with
the probability of transition depending only on the previous state. Here the
states will be assumed a continuous unbounded set and time a discrete unbounded set. If the
set of states is given by, {% katex %}x\in\mathbb{R}{% endkatex %}, the probability that the process
will be in state {% katex %}x{% endkatex %} at time {% katex %}t{% endkatex %}, denoted by
{% katex %}\pi_t (y){% endkatex %}, is referred to as the distribution. Markov Chain equilibrium is
defined by {% katex %}\lim_{t\to\infty}\pi_t (y)\ &lt;\ \infty{% endkatex %}, that is, as time advances
{% katex %}\pi_t (y){% endkatex %} becomes independent of time. Here a solution
for this limit is discussed and illustrated with examples.

&lt;!--more--&gt;

## Model

The Markov Chain is constructed from the set of states {% katex %}\{x\}{% endkatex %},
ordered in time, where {% katex %}x\in\mathbb{R}{% endkatex %}.
The process starts at time {% katex %}t=0{% endkatex %} with state {% katex %}X_0=x{% endkatex %}.
At the next step, {% katex %}t=1{% endkatex %}, the process will assume a state
{% katex %}X_1=y{% endkatex %}, {% katex %}y\in\{x\}{% endkatex %},
with probability {% katex %}P(X_1=y|X_0=x){% endkatex %}
since it will depend on the state at {% katex %}t=0{% endkatex %} by the definition of a Markov Process.
At the next time step {% katex %}t=2{% endkatex %} the process state will be
{% katex %}X_2=z, \text{where}\ z\in\{x\}{% endkatex %} with probability,
{% katex display %}
P(X_2=z|X_0=x, X_1=y) = P(X_2=z|X_1=y),
{% endkatex %}
since by definition the probability of state transition depends only upon the state at the previous time step.
For an arbitrary time the transition from a state {% katex %}X_{t}=x{% endkatex %} to a state
{% katex %}X_{t+1}=y{% endkatex %} will occur with probability, {% katex %}P(X_{t+1}=y|X_t=x){% endkatex %}
that is independent of {% katex %}t{% endkatex %}.
The [Transition Kernel](https://en.wikipedia.org/wiki/Markov_kernel),
defined by,

{% katex display %}
p(x,y) = P(X_{t+1}=y|X_t=x),
{% endkatex %}

plays the same role as the transition matrix plays in the theory of
[Discrete State Markov Chains]({{ site.baseurl }}{% link _posts/2018-08-08-discrete_state_markov_chain_equilibrium.md %}). In general {% katex %}p(x,y){% endkatex %} cannot always be represented by a probability density function, but
here it is assumed that it has a density function representation.
This leads to the interpretation that for a known value of {% katex %}x{% endkatex %} {% katex %}p(x, y){% endkatex %} can be interpreted as a conditional probability density for a transition to state {% katex %}y{% endkatex %} given that the process is in state {% katex %}x{% endkatex %}, namely,

{% katex display %}
p(x, y) = f(y|x)
{% endkatex %}

Consequently, {% katex %}p(x,y){% endkatex %} is a family of conditional probability distributions each
representing conditioning on a possible state of the chain at time step {% katex %}t{% endkatex %}.
Since {% katex %}p(x, y){% endkatex %} is a conditional probability density for each value of
{% katex %}x{% endkatex %} it follows that,

{% katex display %}
\begin{gathered}
\int^{\infty}_{-\infty} p(x, y) dy = 1\ \forall\ x \\
p(x,y)\ \geq 0\ \forall\ x,\ y
\end{gathered}\ \ \ \ \ (1).
{% endkatex %}

The transition kernel for a single step in the Markov Process is defined by {% katex %}p(x,y){% endkatex %}. The
transition kernel across two time steps is computed as follows. Begin by denoting the process state at time
{% katex %}t{% endkatex %} by {% katex %}X_t=x{% endkatex %}, the state at {% katex %}t+1{% endkatex %} by
{% katex %}X_{t+1}=y{% endkatex %} and the state at {% katex %}t+2{% endkatex %} by
{% katex %}X_{t+2}=z{% endkatex %}. Then the probability of transitioning to a state
{% katex %}X_{t+3}=z{% endkatex %} from {% katex %}X_{t}=x{% endkatex %} in two steps,
{% katex %}p^2(x, z){% endkatex %}, is given by,
{% katex display %}
\begin{aligned}
f(z|x) &amp;= \int_{-\infty}^{\infty} f(z|x, y)f(y|x) dy \\
&amp;= \int_{-\infty}^{\infty} f(z|y)f(y|x) dy \\
&amp;= \int_{-\infty}^{\infty} p(y,z)p(x,y) dy \\
&amp;= \int_{-\infty}^{\infty} p(x,y)p(y,z) dy
\end{aligned}
{% endkatex %}

where use was made of the [Law of Total Probability](https://en.wikipedia.org/wiki/Law_of_total_probability), in the
first step and second step used the Markov Chain property {% katex %}f(z|x, y)=f(z|y){% endkatex %}.
Now, the result obtained for the two step transition kernel is the continuous version of
matrix multiplication of the single step transitions probabilities.
A operator inspired by matrix multiplication would be helpful. Make the definition,
{% katex display %}
P^2(x,z) = \int_{-\infty}^{\infty} p(x, y)p(y, z) dy.
{% endkatex %}

Using this operator, with {% katex %}X_{t+3}=w{% endkatex %}, the three step transition kernel is given by,
{% katex display %}
\begin{aligned}
f(w|x) &amp;= \int_{-\infty}^{\infty} f(w|x,z)f(z|x) dz \\
&amp;= \int_{-\infty}^{\infty} f(w|z) \left[ \int_{-\infty}^{\infty} f(z|y)f(y|x) dy \right] dz \\
&amp;= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(w|z)f(z|y)f(y|x) dy dz \\
&amp;= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} p(z,w)p(y,z)p(x,y) dy dz \\
&amp;= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} p(x,y)p(y,z)p(z,w) dy dz \\
&amp;= P^3(x,w),
\end{aligned}
{% endkatex %}

where the second step substitutes the two step transition kernel and the remaining steps perform the decomposition to the single step transition kernel, {% katex %}p(x,y){% endkatex %}. Use of
[Mathematical Induction](https://en.wikipedia.org/wiki/Mathematical_induction) is used to show that the transition
kernel between two states in an arbitrary number of steps, {% katex %}t{% endkatex %}, is given by,

{% katex display %}
P^t(x,y) = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}\cdots\int_{-\infty}^{\infty} p(x,z_1)p(z_1,z_2)\ldots p(z_{t-1},y) dz_1 dz_2\ldots dz_{t-1}.
{% endkatex %}

The distribution of Markov Chain states {% katex %}\pi (x){% endkatex %} is defined by,

{% katex display %}
\begin{gathered}
\int_{-\infty}^{\infty} \pi (x) dx = 1 \\
\pi (x) \geq 0\ \forall\ x
\end{gathered}
{% endkatex %}

To determine the equilibrium distribution, {% katex %}\pi_E (x){% endkatex %}, the time
variability of {% katex %}\pi_t (x){% endkatex %} must be determined. Begin by considering an arbitrary
distribution at {% katex %}t=0{% endkatex %}, {% katex %}\pi_0 (x){% endkatex %}. The distribution
after the first step will be,

{% katex display %}
\pi_1 (y) = \int_{-\infty}^{\infty} p(x, y)\pi_0 (x) dx.
{% endkatex %}

The distribution after two steps is,

{% katex display %}
\begin{aligned}
\pi_2 (y) &amp;= \int_{-\infty}^{\infty} p(x, y)\pi_1 (x) dx \\
&amp;= \int_{-\infty}^{\infty} p(x, y)\left[ \int_{-\infty}^{\infty} p(z, x)\pi_0 (z) dz \right] dx \\
&amp;= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} p(z,x) p(x,y) \pi_0 (z) dx dz
\end{aligned}
{% endkatex %}

The pattern becomes more apparent after the third step,

{% katex display %}
\begin{aligned}
\pi_3 (y) &amp;= \int_{-\infty}^{\infty} p(x, y)\pi_2 (x) dx \\
&amp;= \int_{-\infty}^{\infty} p(x, y)\left[ \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} p(w,x) p(z,w)\pi_0 (z) dz dw \right] dx \\
&amp;= \int_{-\infty}^{\infty}\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} p(x,y) p(w,x) p(z,w)\pi_0 (z) dz dw dx \\
&amp;= \int_{-\infty}^{\infty}\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} p(z,w) p(w,x) p(x,y) \pi_0 (z) dw dx dz.
\end{aligned}
{% endkatex %}

This looks similar to the previous result obtained for the time dependence of the transition kernel. Making use
of the operator {% katex %}P{% endkatex %} gives,

{% katex display %}
\begin{aligned}
\pi_1 (y) &amp;= P\pi_0(y) = \int_{-\infty}^{\infty} p(x, y)\pi_0 (x) dx \\
\pi_2 (y) &amp;= P^2\pi_0(y) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} p(z,x) p(x,y) \pi_0 (z) dx dz \\
\pi_3 (y) &amp;= P^3\pi_0(y) = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} p(z,w) p(w,x) p(x,y) \pi_0 (z) dw dx dz.
\end{aligned}
{% endkatex %}

Mathematical Induction can be used to prove the distribution at an arbitrary time {% katex %}t{% endkatex %}
is given by,

{% katex display %}
\pi_t (y) = P^t\pi_0(y)\ \ \ \ \ (2)
{% endkatex %}

## Equilibrium Distribution

The equilibrium distribution is defined as the invariant solution to equation {% katex %}(2){% endkatex %}
for arbitrary {% katex %}t{% endkatex %}, namely,

{% katex display %}
\pi_E (y) = P^t\pi_E(y)\ \ \ \ \ (3).
{% endkatex %}

Consider,
{% katex display %}
\pi_E (y) = P\pi_E(y)\ \ \ \ \ (4),
{% endkatex %}

substitution into equation {% katex %}(3){% endkatex %} gives,

{% katex display %}
\begin{aligned}
\pi_E (y) &amp;= P^t\pi_E(y) \\
&amp;= P^{t-1}(P\pi_E)(y) \\
&amp;= P^{t-1}\pi_E(y) \\
&amp;\vdots \\
&amp;= P\pi_E(y) \\
&amp;= \pi_E(y).
\end{aligned}
{% endkatex %}

Thus equation {% katex %}(4){% endkatex %} defines the time invariant solution to equation
{% katex %}(3){% endkatex %}.

To go further a particular form for the transition kernel must be specified. Unlike the
[discrete state model]({{ site.baseurl }}{% link _posts/2018-08-08-discrete_state_markov_chain_equilibrium.md %})
a general solution cannot be obtained since convergence of the limit {% katex %}t\to\infty{% endkatex %} will
depend on the assumed transition kernel. The following section will describe a solution to equation
{% katex %}(4){% endkatex %} arising from a simple stochastic processes.

## Example

To evaluate the equilibrium distribution a form for the transition kernel must be assumed. Here the
[AR(1)](https://en.wikipedia.org/wiki/Autoregressive_model) stochastic process is considered.
AR(1) is a simple first order autoregressive model providing an example of a continuous state Markov Chain.
In following sections its equilibrium distribution is determined and the results of simulations are discussed.

AR(1) is defined by the difference equation,

{% katex display %}
X_{t} = \alpha X_{t-1} + \varepsilon_{t}\ \ \ \ \ (5),
{% endkatex %}

where {% katex %}t=0,\ 1,\ 2,\ldots{% endkatex %} and the {% katex %}\varepsilon_{t}{% endkatex %} are identically
distributed independent {% katex %}\textbf{Normal}{% endkatex %}
random variables with zero mean and variance, {% katex %}\sigma^2{% endkatex %}. The {% katex %}t{% endkatex %}
subscript on {% katex %}\varepsilon{% endkatex %} indicates that it is generated at time step
{% katex %}t{% endkatex %}.
The transition kernel for AR(1) can be derived from equation {% katex %}(5){% endkatex %} by using,
{% katex %}\varepsilon_{t} \sim \textbf{Normal}(0,\ \sigma^2){% endkatex %} and letting
{% katex %}x=x_{t-1}{% endkatex %} and {% katex %}y=x_{t}{% endkatex %} so that
{% katex %}\varepsilon_{t} = y - \alpha x{% endkatex %}. The result is,

{% katex display %}
p(x,y) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-(y-\alpha x)^2/2\sigma^2}\ \ \ \ \ \ (6)
{% endkatex %}

Now, consider a few steps,

{% katex display %}
\begin{aligned}
X_1 &amp;= \alpha X_0 + \varepsilon_1 \\
X_2 &amp;= \alpha X_1 + \varepsilon_2 \\
X_3 &amp;= \alpha X_2 + \varepsilon_3,
\end{aligned}
{% endkatex %}

substituting the first equation into the second equation and that result into the third equation gives,

{% katex display %}
X_3 = \alpha^3 X_0 + \alpha^2\varepsilon_1 + \alpha\varepsilon_2 + \varepsilon_3
{% endkatex %}

If this process is continued for {% katex %}t{% endkatex %} steps the following result is
obtained,

{% katex display %}
X_t = \alpha^t X_0 + \sum_{i=1}^{t} \alpha^{t-i} \varepsilon_{i}\ \ \ \ \ (7).
{% endkatex %}

### Equilibrium Solution

In this section equation {% katex %}(7){% endkatex %} is used to evaluate the the mean and variance of
the AR(1) process in the equilibrium limit {% katex %}t\to\infty{% endkatex %}. The mean and variance
obtained are then used to construct {% katex %}\pi_E(x){% endkatex %} that is shown to be a solution
to equation {% katex %}(4){% endkatex %}.

The equilibrium mean is given by,

{% katex display %}
  \mu_{E} = \lim_{t\to\infty} E(X_t).
{% endkatex %}

From equation {% katex %}(7){% endkatex %} it is seen that,

{% katex display %}
\begin{aligned}
E(X_t) &amp;= E\left[ \alpha^t X_0 + \sum_{i=1}^{t} \alpha^{t-i} \varepsilon_{i} \right] \\
&amp;= \alpha^t x_0 + \sum_{i=1}^t E(\varepsilon_i) \\
&amp;= \alpha^t x_0,
\end{aligned}
{% endkatex %}

where the last step follows from {% katex %}E(\varepsilon_i)=0{% endkatex %}. Now,

{% katex display %}
\begin{aligned}
\mu_E &amp;= \lim_{t\to\infty} E(X_t) \\
&amp;= \lim_{t\to\infty} \alpha^t X_0,
\end{aligned}
{% endkatex %}

this limit exists for {% katex %}\mid\alpha\mid\ \leq\ 1{% endkatex %},

{% katex display %}
\mu_E =
\begin{cases}
X_0 &amp; \mid\alpha\mid=1 \\
0 &amp; \mid\alpha\mid\ \leq\ 1
\end{cases}\ \ \ \ \ (8).
{% endkatex %}

The equilibrium variance is given by,

{% katex display %}
\sigma^2_E = \lim_{t\to\infty} E(X^2_t) - \left[E(X_t)\right]^2.
{% endkatex %}

To evaluate this expression and equation for {% katex %}X^2_t{% endkatex %} is needed. From equation
{% katex %}(7){% endkatex %} it follows that,

{% katex display %}
\begin{aligned}
X_t^2 &amp;= \left[ \alpha^t X_0 + \sum_{i=1}^{t} \alpha^{t-i} \varepsilon_i \right]^2 \\
&amp;= \alpha^{2t}X_0^2 + 2\alpha^t X_0\sum_{i=1}^t \alpha^{t-1} \varepsilon_i + \sum_{i=1}^t \sum_{j=1}^t \alpha^{t-i}\alpha^{t-j}\varepsilon_i \varepsilon_j.
\end{aligned}
{% endkatex %}

It follows that,

{% katex display %}
\begin{aligned}
E(X_t^2) &amp;= E\left[\alpha^{2t}X_0^2 + 2\alpha^t X_0\sum_{i=1}^t \alpha^{t-1} \varepsilon_i + \sum_{i=1}^t \sum_{j=1}^t \alpha^{t-i}\alpha^{t-j}\varepsilon_i \varepsilon_j \right] \\
&amp;= \alpha^{2t} X_0^2 +  2\alpha^t X_0\sum_{i=1}^t \alpha^{t-1} E(\varepsilon_i) + \sum_{i=1}^t \sum_{j=1}^t \alpha^{t-i}\alpha^{t-j}E(\varepsilon_i \varepsilon_j) \\
&amp;= \alpha^{2t} X_0^2 + \sum_{i=1}^t \sum_{j=1}^t \alpha^{t-i}\alpha^{t-j}E(\varepsilon_i \varepsilon_j),
\end{aligned}
{% endkatex %}

where the last step follows from {% katex %}E(\varepsilon_i)=0{% endkatex %}. Since the
{% katex %}\varepsilon_t{% endkatex %} are independent,

{% katex display %}
E(\varepsilon_i \varepsilon_j) = \sigma^2 \delta_{ij},
{% endkatex %}

where {% katex %}\delta_{ij}{% endkatex %} is the [Kronecker Delta](https://en.wikipedia.org/wiki/Kronecker_delta),
{% katex display %}
\delta_{ij} =
\begin{cases}
0 &amp; i \neq j \\
1 &amp; i=j
\end{cases}.
{% endkatex %}

Using these results gives,

{% katex display %}
\begin{aligned}
E(X_t^2) &amp;= \alpha^{2t} X_0^2 + \sigma^2\sum_{i=1}^t \sum_{j=1}^t \alpha^{2t-i-j}\delta_{ij} \\
&amp;= \alpha^{2t} X_0^2 + \sigma^2\sum_{i=1}^t \alpha^{2(t-i)} \\
&amp;= \alpha^{2t} X_0^2 + \sigma^2\sum_{i=1}^t \left(\alpha^2\right)^{t-i} \\
&amp;= \alpha^{2t} X_0^2 + \frac{\sigma^2\left[1 - (\alpha^2)^{t-1}\right]}{1 - \alpha^2},
\end{aligned}
{% endkatex %}

The last step follows from summation of a geometric series,

{% katex display %}
\begin{aligned}
\sum_{i=1}^{t} (\alpha^2)^{t-1} &amp;= \sum_{k=0}^{t-1}(\alpha^2)^k \\
&amp;= \frac{1-(\alpha^2)^{t-1}}{1-\alpha^2}.
\end{aligned}
{% endkatex %}

In the limit {% katex %}t\to\infty {% endkatex %} {% katex %}E(X_t^2){% endkatex %} only converges for {% katex %}\mid\alpha\mid\ &lt;\ 1{% endkatex %}. If {% katex %}\alpha=1{% endkatex %} the denominator of the second term in
of {% katex %}E(X_t^2){% endkatex %} is {% katex %}0{% endkatex %} {% katex %}E(X_t^2){% endkatex %} is
undefined. {% katex %}\sigma^2_E{% endkatex %}
is evaluated assuming {% katex %}\mid\alpha\mid\ &lt;\ 1{% endkatex %} if this is the case
{% katex %}(8){% endkatex %} gives {% katex %}\mu_E=0{% endkatex %}, so,

{% katex display %}
\begin{aligned}
\sigma^2_E &amp;= \lim_{t\to\infty} E(X_t^2) - \left(\mu_E\right)^2 \\
&amp;= \lim_{t\to\infty} \alpha^{2t}X_0^2 + \frac{\sigma^2\left[1 - (\alpha^2)^{t-1}\right]}{1 - \alpha^2} \\
&amp;= \frac{\sigma^2}{1 - \alpha^2}.
\end{aligned}\ \ \ \ \ (9)
{% endkatex %}

The equilibrium distribution, {% katex %}\pi_E{% endkatex %}, is found by substituting the results
from equation {% katex %}(8){% endkatex %} and {% katex %}(9){% endkatex %} into a
{% katex %}\textbf{Normal}(\mu_E,\ \sigma^2_E){% endkatex %} distribution to obtain,

{% katex display %}
\pi_E(y) = \frac{1}{\sqrt{2\pi\sigma_E^2}}e^{-y^2/2\sigma_E^2}\ \ \ \ \ (10)
{% endkatex %}

It can be shown that equation {% katex %}(10){% endkatex %} is the equilibrium distribution by verifying that it is a solution to
equation {% katex %}(4){% endkatex %}. Inserting equations {% katex %}(6){% endkatex %} and
{% katex %}(10){% endkatex %} into equation {% katex %}(4){% endkatex %} yields,

{% katex display %}
\begin{aligned}
P\pi_E(y) &amp;= \int_{-\infty}^{\infty} p(x, y) \pi_E(x) dx \\
&amp;= \int_{-\infty}^{\infty} \left[\frac{1}{\sqrt{2\pi\sigma^2}} e^{(y-\alpha x)^2/2\sigma^2}\right]\left[\frac{1}{\sqrt{2\pi\sigma_E^2}}e^{-y^2/2\sigma_E^2}\right] dx \\
&amp;= \frac{1}{\sqrt{2\pi\sigma^2}}\frac{1}{\sqrt{2\pi\sigma_E^2}} \int_{-\infty}^{\infty} e^{-\frac{1}{2}\left[(y-\alpha x)^2/\sigma^2+x^2/\sigma_E^2 \right]} dx \\
&amp;= \frac{1}{\sqrt{2\pi\sigma^2}}\frac{1}{\sqrt{2\pi\sigma_E^2}} \int_{-\infty}^{\infty} e^{-\frac{1}{2}\left[y^2/\sigma_E^2+(x-\alpha y)^2/\sigma^2 \right]} dx \\
&amp;= \frac{1}{\sqrt{2\pi\sigma_E^2}} e^{-y^2/2\sigma_E^2}\frac{1}{\sqrt{2\pi\sigma^2}}\int_{-\infty}^{\infty} e^{-(x-\alpha y)^2/2\sigma^2} dx \\
&amp;= \frac{1}{\sqrt{2\pi\sigma_E^2}} e^{-y^2/2\sigma_E^2} \\
&amp;= \pi_E(y)
\end{aligned}
{% endkatex %}

### Simulation

An AR(1) simulator can be implemented using either the difference equation definition, equation
{% katex %}(5){% endkatex %} or the transition kernel, equation {% katex %}(6){% endkatex %}.
The result produced by either are statistically identical, An example implementation in Python using
equation {% katex %}(5){% endkatex %} is shown below.

```python
def ar_1_difference_series(α, σ, x0, nsample=100):
    samples = numpy.zeros(nsample)
    ε = numpy.random.normal(0.0, σ, nsample)
    samples[0] = x0
    for i in range(1, nsample):
        samples[i] = α * samples[i-1] + ε[i]
    return samples
```

The function `ar_1_difference_series(α, σ, x0, nsamples)` takes four arguments: `α` and `σ`, the initial value
of {% katex %}x{% endkatex %}, `x0` and the number of desired samples `nsample`. It begins by allocating storage
for the sample output followed by generation of `nsample` values of {% katex %}\varepsilon_\sim \textbf{Normal}(0,\ \sigma^2){% endkatex %} with the requested standard deviation, {% katex %}\sigma{% endkatex %}. The samples are then created using the AR(1 ) difference equation, equation {% katex %}(5){% endkatex %}.
A second implementation using the transition kernel, equation {% katex %}(6){% endkatex %} is shown below.

```python
def ar1_kernel_series(α, σ, x0, nsample=100):
    samples = numpy.zeros(nsample)
    samples[0] = x0
    for i in range(1, nsample):
        samples[i] = numpy.random.normal(α * samples[i-1], σ)
    return samples
```

The function `ar1_kernel_series(α, σ, x0, nsamples)` also  takes four arguments: `α` and `σ`
from equation {% katex %}(6){% endkatex %},
the initial value of {% katex %}x{% endkatex %}, `x0` and the number of desired samples, `nsample`.
It begins by allocating storage for the sample output and then generates samples using the transition kernel
with distribution {% katex %}\textbf{Normal}(α * samples[i-1],\ \sigma^2){% endkatex %}.

The plots below show examples of time series generated
using `ar_1_difference_series` with {% katex %}\sigma=1{% endkatex %} and values of {% katex %}\alpha{% endkatex %}
satisfying {% katex %}\alpha\ &lt;\ 1{% endkatex %}. It is seen that for smaller {% katex %}\alpha{% endkatex %} values of
the series more frequently change direction and have smaller variance. This is expected from
equation {% katex %}(9){% endkatex %}, where {% katex %}\sigma_E=1/1-\alpha^2{% endkatex %}.

&lt;div style=&quot;text-align:center;&quot;&gt;
  &lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/continuous_state_markov_chain_equilibrium/ar1_alpha_sample_comparison.png&quot;&gt;
&lt;/div&gt;

If {% katex %}\alpha{% endkatex %} is just slightly larger than {% katex %}1{% endkatex %} the time series
can increase rapidly as illustrated in the plot below.

&lt;div style=&quot;text-align:center;&quot;&gt;
  &lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/continuous_state_markov_chain_equilibrium/ar1_alpha_larger_than_1.png&quot;&gt;
&lt;/div&gt;

For {% katex %}\alpha\ &lt;\ 1{% endkatex %} {% katex %}\sigma_E{% endkatex %} is bounded and the generated
samples are constrained about the equilibrium mean value, {% katex %}\mu_E=0{% endkatex %}, but for
{% katex %}\alpha\ \geq\ 1{% endkatex %} {% katex %}\sigma_E{% endkatex %} is unbounded
and the samples very quickly develop very large deviations from {% katex %}\mu_E{% endkatex %}.

### Convergence to Equilibrium

For sufficiently large times samples generated by the AR(1) process will approach the equilibrium values
for {% katex %}\alpha\ &lt;\ 1{% endkatex %}. In the plots following the cumulative values of both the
mean and standard deviation computed from simulations, using `ar_1_difference_series` with
{% katex %}\sigma=1{% endkatex %}, are compared with the equilibrium vales {% katex %}\mu_E{% endkatex %}
and {% katex %}\sigma_E{% endkatex %} from equations {% katex %}(8){% endkatex %} and
{% katex %}(9){% endkatex %} respectively. The first plot illustrates the convergence {% katex %}\mu{% endkatex %}
to {% katex %}\mu_E{% endkatex %} for six different simulations with varying initial states,
{% katex %}X_0{% endkatex %}, and {% katex %}\alpha{% endkatex %}. The rate of convergence is seen to
decrease as {% katex %}\alpha{% endkatex %} increases. For smaller {% katex %}\alpha{% endkatex %} the simulation
{% katex %}\mu{% endkatex %} is close to {% katex %}\mu_E{% endkatex %} within {% katex %}10^2{% endkatex %}
samples and indistinguishable from {% katex %}\mu_E{% endkatex %} by {% katex %}10^3{% endkatex %}. For larger
values of {% katex %}\alpha{% endkatex %} the convergence is mush slower. After {% katex %}10^5{% endkatex %}
samples there are still noticeable oscillations of the sampled {% katex %}\mu{% endkatex %} about
{% katex %}\mu_E{% endkatex %}.

&lt;div style=&quot;text-align:center;&quot;&gt;
  &lt;img class=&quot;post-image&quot;  src=&quot;/assets/posts/continuous_state_markov_chain_equilibrium/mean_convergence.png&quot;&gt;
&lt;/div&gt;

Since {% katex %}\sigma_E{% endkatex %} varies with {% katex %}\alpha{% endkatex %} for clarity only simulations
with varying {% katex %}\alpha{% endkatex %} are shown. The rate of convergence {% katex %}\sigma{% endkatex %} to
{% katex %}\sigma_E{% endkatex %} is slightly slower than the rate seem for {% katex %}\mu{% endkatex %}. For
smaller {% katex %}\alpha{% endkatex %} simulation {% katex %}\sigma{% endkatex %} computations are
indistinguishable form {% katex %}\sigma_E{% endkatex %} by {% katex %}10^3{% endkatex %} samples. For larger
{% katex %}\alpha{% endkatex %} after {% katex %}10^4{% endkatex %} sample deviations about the
{% katex %}\sigma_E{% endkatex %} are still visible.

&lt;div style=&quot;text-align:center;&quot;&gt;
  &lt;img class=&quot;post-image&quot;  src=&quot;/assets/posts/continuous_state_markov_chain_equilibrium/sigma_convergence.png&quot;&gt;
&lt;/div&gt;

The plot below favorably compares the histogram produced from results of a simulation of {% katex %}10^6{% endkatex %}
samples and the equilibrium distribution, {% katex %}\pi_E(y){% endkatex %}, from equation {% katex %}(10){% endkatex %}.

&lt;div style=&quot;text-align:center;&quot;&gt;
  &lt;img class=&quot;post-image&quot;  src=&quot;/assets/posts/continuous_state_markov_chain_equilibrium/equilibrium_pdf_comparison_samples.png&quot;&gt;
&lt;/div&gt;

A more efficient method of estimating {% katex %}\pi_E(y){% endkatex %} is obtained from equation
{% katex %}(4){% endkatex %} by noting that for sufficiently large number of samples equation
{% katex %}(4){% endkatex %} can be approximated by the expectation of the transition kernel, namely,

{% katex display %}
\begin{aligned}
\pi_E(y) &amp;= P\pi_E(y) \\
&amp;= \int_{-\infty}^{\infty} p(x, y) \pi_E(x) dx \\
&amp;\approx \frac{1}{N} \sum_{i=0}^{N-1} p(x_i, y).
\end{aligned}\ \ \ \ \ (11)
{% endkatex %}

A Python implementation of the solution to equation {% katex %}(11){% endkatex %} for the average transition kernel
is listed below where two functions are defined.

```python
def ar_1_kernel(α, σ, x, y):
    p = numpy.zeros(len(y))
    for i in range(0, len(y)):
        ε  = ((y[i] -  α * x)**2) / (2.0 * σ**2)
        p[i] = numpy.exp(-ε) / numpy.sqrt(2 * numpy.pi * σ**2)
    return p

def ar_1_equilibrium_distributions(α, σ, x0, y, nsample=100):
    py = [ar_1_kernel(α, σ, x, y) for x in ar_1_difference_series(α, σ, x0, nsample)]
    pavg = [py[0]]
    for i in range(1, len(py)):
        pavg.append((py[i] + i * pavg[i-1]) / (i + 1))
    return pavg
```

The first function `ar_1_kernel(α, σ, x, y)` computes the transition kernel for a range of values and takes four arguments as
input: `α` and `σ` from equation {% katex %}(5){% endkatex %} and the value of `x` and an array of `y` values where
the transition kernel is evaluated. The second function `ar_1_equilibrium_distributions(α, σ, x0, y, nsample)` has five arguments as input:  
`α` and `σ`, the initial value of {% katex %}x{% endkatex %}, `x0`, the array of `y` values used to evaluate the transition kernel and
the number of desired samples `nsample`. `ar_1_equilibrium_distributions` begins by calling `ar_1_difference_series` to generate
`nsample` samples of `x`. These values and the needed inputs are then passed to `ar_1_kernel` providing `nsample` evaluations of
the transition kernel. The cumulative average of the transition kernel is then evaluated and returned.

In practice this method gives reasonable results for as few as {% katex %}10^2{% endkatex %} samples. This is illustrated
in the following plot where the transition kernel mean value computed with just {% katex %}50{% endkatex %} samples
using `ar_1_equilibrium_distributions` is compared {% katex %}\pi_E(y){% endkatex %} from equation
{% katex %}(10){% endkatex %}.

&lt;div style=&quot;text-align:center;&quot;&gt;
  &lt;img class=&quot;post-image&quot;  src=&quot;/assets/posts/continuous_state_markov_chain_equilibrium/equilibrium_pdf_comparison.png&quot;&gt;
&lt;/div&gt;

The following plot shows intermediate values the calculation in the range of {% katex %}1{% endkatex %} to
{% katex %}50{% endkatex %} samples. This illustrates the changes in the estimated equilibrium distribution
as the calculation progresses. By {% katex %}500{% endkatex %} samples a distribution near the equilibrium distribution
is obtained.

&lt;div style=&quot;text-align:center;&quot;&gt;
  &lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/continuous_state_markov_chain_equilibrium/ar1_relaxation_to_equilibrium_2.png&quot;&gt;
&lt;/div&gt;

## Conclusions

Markov Chain equilibrium for continuous state processes provides a general theory of the time evolution
of stochastic kernels and distributions. Unlike the case for the [discrete state model]({{ site.baseurl }}{% link _posts/2018-08-08-discrete_state_markov_chain_equilibrium.md %}) general solutions cannot be obtained
since evaluation of the obtained equations depends of the form of the stochastic kernel. Kernels will
exist which do not have equilibrium solutions. A continuous state process that has an equilibrium
distribution that can be analytically evaluated is AR(1). The stochastic kernel for AR(1) is derived
from its difference equation representation and the first and second moments are evaluated in
the equilibrium limit, {% katex %}{t\to\infty}{% endkatex %}. It is shown that finite values exists only
for values of the AR(1) parameter that satisfy {% katex %}\mid\alpha\mid\ &lt; \ 1{% endkatex %}.
A distribution is then constructed using these moments and shown to be the equilibrium distribution.
Simulations are performed using the difference equation
representation of the process and compared with the equilibrium calculations. The rate of convergence
of simulations to the equilibrium is shown to depend on {% katex %}\alpha{% endkatex %}. For values
not near {% katex %}1{% endkatex %} convergence of the mean occurs with {% katex %}O(10^3){% endkatex %}
time steps and convergence of the standard deviation with {% katex %}O(10^4){% endkatex %} time steps.
For values of {% katex %}\alpha{% endkatex %} closer to {% katex %}1{% endkatex %} convergence has
not occurred by {% katex %}10^4{% endkatex %} time steps.</content><author><name>Troy Stribling</name></author><summary type="html">A Markov Chain is a sequence of states where transitions between states occur ordered in time with the probability of transition depending only on the previous state. Here the states will be assumed a continuous unbounded set and time a discrete unbounded set. If the set of states is given by, x∈Rx\in\mathbb{R}x∈R, the probability that the process will be in state xxx at time ttt, denoted by πt(y)\pi_t (y)πt​(y), is referred to as the distribution. Markov Chain equilibrium is defined by limt→∞πt(y) &amp;lt; ∞\lim_{t\to\infty}\pi_t (y)\ &amp;lt;\ \inftylimt→∞​πt​(y) &amp;lt; ∞, that is, as time advances πt(y)\pi_t (y)πt​(y) becomes independent of time. Here a solution for this limit is discussed and illustrated with examples.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/posts/continuous_state_markov_chain_equilibrium/ar1_relaxation_to_equilibrium_2.png" /></entry><entry><title type="html">Discrete State Markov Chain Equilibrium</title><link href="http://localhost:4000/2018/08/08/discrete_state_markov_chain_equilibrium.html" rel="alternate" type="text/html" title="Discrete State Markov Chain Equilibrium" /><published>2018-08-08T00:00:00-07:00</published><updated>2018-08-08T00:00:00-07:00</updated><id>http://localhost:4000/2018/08/08/discrete_state_markov_chain_equilibrium</id><content type="html" xml:base="http://localhost:4000/2018/08/08/discrete_state_markov_chain_equilibrium.html">A [Markov Chain](https://en.wikipedia.org/wiki/Markov_chain) is a sequence of states
where transitions between states occur ordered in time with
the probability of transition depending only on the previous state. Here the
states will be assumed a discrete finite set and time a discrete unbounded set. If the
set of states is given by {% katex %}\{x_1,\ x_2,\ldots,\ x_N\}{% endkatex %} the probability
that the process will be in state {% katex %}x_i{% endkatex %} at time {% katex %}t{% endkatex %}
is denoted by {% katex %}P(X_t=x_i){% endkatex %}, referred to as the distribution.
Markov Chain equilibrium is defined by {% katex %}\lim_{t\to\infty}P(X_t=x_i)\ &lt;\ \infty{% endkatex %},
that is, as time advances  
{% katex %}P(X_t=x_i){% endkatex %} becomes independent of time. Here a solution
for this limit is discussed and illustrated with examples.

&lt;!--more--&gt;

## Model

The Markov Chain model is constructed from the set of states
{% katex %}\{x_1,\ x_2,\ldots,\ x_N\}{% endkatex %} ordered in time.
The process starts at time {% katex %}t=0{% endkatex %} with state {% katex %}X_0=x_i{% endkatex %}.
At the next step, {% katex %}t=1{% endkatex %}, the process will assume a state
{% katex %}X_1=x_j{% endkatex %} with probability {% katex %}P(X_1=x_j|X_0=x_i){% endkatex %} since
it will depend on the previous state {% katex %}x_0{% endkatex %} as defined for a Markov Process.
At the next time step {% katex %}t=2{% endkatex %} the process state will be
{% katex %}X_2=x_k{% endkatex %} with probability,
{% katex display %}
P(X_2=x_k|X_0=x_i, X_1=x_j)=P(X_2=x_k|X_1=x_j),
{% endkatex %}
since by definition the probability of state transition depends only upon the state at the previous time step.
For an arbitrary time the transition from a state {% katex %}X_{t}=x_j{% endkatex %} to a state
{% katex %}X_{t+1}=x_j{% endkatex %} will occur with probability, {% katex %}P(X_{t+1}=x_j|X_t=x_i){% endkatex %}
that is independent of {% katex %}t{% endkatex %}.
Transition probabilities have the form of a matrix,

{% katex display %}
P_{ij} = P(X_{t+1}=x_j|X_t=x_i).
{% endkatex %}

{% katex %}P{% endkatex %} will be an {% katex %}N\times N{% endkatex %} matrix
where {% katex %}N{% endkatex %} is determined by the number of possible states. Each
row represents the Markov Chain transition probability from that state at
time {% katex %}t{% endkatex %} and the columns the values at {% katex %}t+1{% endkatex %}.
It follows that,
{% katex display %}
\begin{gathered}
\sum_{j=1}^{N}P_{ij} = 1\\
P_{ij}\ \geq\ 0
\end{gathered} \ \ \ \ \ (1).
{% endkatex %}

Equation {% katex %}(1){% endkatex %} is the definition of a [Stochastic Matrix](https://en.wikipedia.org/wiki/Stochastic_matrix).

The transition probability for a single step in the Markov Process is defined by {% katex %}P{% endkatex %}.
The transition probability across two time steps can be obtained with use of the
[Law of Total Probability](https://en.wikipedia.org/wiki/Law_of_total_probability),
{% katex display %}
\begin{aligned}
P(X_{t+2}=x_j|X_t=x_i) &amp;= \sum_{k=1}^{N} P(X_{t+2}=x_j | X_{t}=x_i, X_{t+1}=x_k)P(X_{t+1}=x_k | X_{t}=x_i) \\
&amp;= \sum_{k=1}^{N} P(X_{t+2}=x_j | X_{t+1}=x_k)P(X_{t+1}=x_k | X_{t}=x_i) \\
&amp;= \sum_{k=1}^{N} P_{kj}P_{ik} \\
&amp;= \sum_{k=1}^{N} P_{ik}P_{kj} \\
&amp;= {(P^2)}_{ij},
\end{aligned}
{% endkatex %}

where the last step follows from the definition of matrix multiplication. It is straight forward but
tedious to use [Mathematical Induction](https://en.wikipedia.org/wiki/Mathematical_induction) to extend the previous result to the case of an arbitrary time difference, {% katex %}\tau{% endkatex %},
{% katex display %}
P(X_{t+\tau}=x_j|X_t=x_i) = {(P^{\tau})}_{ij}\ \ \ \ \ (2).
{% endkatex %}

It should be noted that since {% katex %}{(P^{\tau})}_{ij}{% endkatex %} is a transition probability it must
satisfy,

{% katex display %}
\begin{gathered}
\sum_{j=1}^{N} {(P^{\tau})}_{ij}\ =\ 1 \\
{(P^{\tau})}_{ij}\ \geq\ 0
\end{gathered} \ \ \ \ \ (3).
{% endkatex %}

To determine the equilibrium solution of the distribution of states,
{% katex %}\{x_1,\ x_2,\ldots,\ x_N\}{% endkatex %}, the distribution time variability must be determined.
Begin by considering an arbitrary distribution at {% katex %}t=0{% endkatex %}, which can be written as a
column vector,
{% katex display %}
\pi =
\begin{pmatrix}
\pi_1 \\
\pi_2 \\
\vdots \\
\pi_N
\end{pmatrix} =
\begin{pmatrix}
P(X_0=x_1) \\
P(X_0=x_2) \\
\vdots \\
P(X_0=x_N)
\end{pmatrix},
{% endkatex %}

since it is a probability distribution {% katex %}\pi_i{% endkatex %} must satisfy,
{% katex display %}
\begin{gathered}
\sum_{i=1}^{N} \pi_i\ =\ 1\\
\pi_i\ \geq \ 0
\end{gathered} \ \ \ \ \ (4).
{% endkatex %}

The distribution after the first step is given by,
{% katex display %}
\begin{aligned}
P(X_1=x_j) &amp;= \sum_{i=1}^{N} P(X_1=x_j|X_0=x_i)P(X_0=x_i) \\
&amp;= \sum_{i=1}^{N} P_{ij}\pi_{i} \\
&amp;= \sum_{i=1}^{N} \pi_{i}P_{ij} \\
&amp;= {(\pi^{T}P)}_{j},
\end{aligned}
{% endkatex %}

where {% katex %}\pi^T{% endkatex %} is the transpose of {% katex %}\pi{% endkatex %}. Similarly, the distribution after the second step is,
{% katex display %}
\begin{aligned}
P(X_2=x_j) &amp;= \sum_{i=1}^{N} P(X_2=x_j|X_1=x_i)P(X_1=x_i) \\
&amp;= \sum_{i=1}^{N} P_{ij}{(\pi^{T}P)}_{i} \\
&amp;= \sum_{i=1}^{N} P_{ij}\sum_{k=1}^{N} \pi_{k}P_{ki} \\
&amp;= \sum_{k=1}^{N} \pi_{k} \sum_{i=1}^{N} P_{ij}P_{ki} \\
&amp;= \sum_{k=1}^{N} \pi_{k} \sum_{i=1}^{N} P_{ki}P_{ij} \\
&amp;= \sum_{k=1}^{N} \pi_{k} {(P^2)}_{kj} \\
&amp;= {(\pi^{T}P^2)}_{j},
\end{aligned}
{% endkatex %}

A pattern is clearly developing. Mathematical Induction can be used to prove the distribution
at an arbitrary time {% katex %}t{% endkatex %} is given by,
{% katex display %}
P(X_t=x_j) = {(\pi^{T}P^t)}_{j}
{% endkatex %}

or as a column vector,

{% katex display %}
\pi_{t}^{T} = \pi^{T}P^t\ \ \ \ \ (5).
{% endkatex %}

Where {% katex %}\pi{% endkatex %} and {% katex %}\pi_t{% endkatex %} are the initial distribution
and the distribution after {% katex %}t{% endkatex %} steps respectively.

## Equilibrium Transition Matrix

The probability of transitioning between two states {% katex %}x_i{% endkatex %} and
{% katex %}x_j{% endkatex %} in {% katex %}t{% endkatex %} time steps was previously shown to be
stochastic matrix {% katex %}P^t{% endkatex %} constrained by equation {% katex %}(3){% endkatex %}.
The equilibrium transition matrix is defined by,
{% katex display %}
P^{E} = \lim_{t\to\infty}P^{t}.
{% endkatex %}
This limit can be determined using
[Matrix Diagonalization](https://en.wikipedia.org/wiki/Diagonalizable_matrix).
The following sections will use diagonalization to construct a form of
{% katex %}P^{t}{% endkatex %} that will easily allow evaluation equilibrium limit.

### Eigenvectors and Eigenvalues of the Transition Matrix

Matrix Diagonalization requires evaluation of eigenvalues and eigenvectors, which are defined
by the solutions to the equation,
{% katex display %}
Pv = \lambda v\ \ \ \ \ (6),
{% endkatex %}
where {% katex %}v{% endkatex %} is the eigenvector and {% katex %}\lambda{% endkatex %} eigenvalue.
From equation {% katex %}(6){% endkatex %} it follows,
{% katex display %}
\begin{aligned}
P^{t}v &amp;= P^{t-1}(Pv)\\
&amp;=P^{t-1}\lambda v\\
&amp;=P^{t-2}(Pv)\lambda\\
&amp;=P^{t-2}\lambda^{2}v \\
&amp;\vdots\\
&amp;=(Pv)\lambda^{t-1}\\
&amp;=\lambda^{t}v.
\end{aligned}
{% endkatex %}

Since {% katex %}P^t{% endkatex %} is a stochastic matrix it satisfies equation {% katex %}(3){% endkatex %}.
As a result of these constraints the limit {% katex %}t\to\infty{% endkatex %} requires,
{% katex display %}
\lim_{t\to\infty}P^{t}=\lim_{t\to\infty}\lambda^{t}v\ \leq\ \infty.
{% endkatex %}

It follows that {% katex %}\lambda\ \leq\ 1 {% endkatex %}. Next,
it will be shown that {% katex %}\lambda_1=1{% endkatex %} and that a column vector of
{% katex %}1's{% endkatex %} with {% katex %}N{% endkatex %} rows,
{% katex display %}
V_1 =
\begin{pmatrix}
1 \\
1 \\
\vdots \\
1
\end{pmatrix}\ \ \ \ \ (7),
{% endkatex %}
are eigenvalue and eigenvector solutions of equation {% katex %}(6){% endkatex %},
{% katex display %}
\begin{pmatrix}
P_{11} &amp; P_{12} &amp; \cdots &amp; P_{1N} \\
P_{21} &amp; P_{22} &amp; \cdots &amp; P_{2N} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
P_{N1} &amp; P_{N2} &amp; \cdots &amp; P_{NN}
\end{pmatrix}
\begin{pmatrix}
1 \\
1 \\
\vdots \\
1
\end{pmatrix}
=
\begin{pmatrix}
\sum_{j=1}^{N}P_{1j} \\
\sum_{j=1}^{N}P_{2j} \\
\vdots \\
\sum_{j=1}^{N}P_{Nj}
\end{pmatrix}
=
\begin{pmatrix}
1 \\
1 \\
\vdots \\
1
\end{pmatrix}
=\lambda_1 V_1,
{% endkatex %}

where use was made of the stochastic matrix condition from equation {% katex %}(1){% endkatex %}, namely,
{% katex %}\sum_{j=1}^{N}P_{ij}=1{% endkatex %}.

To go further a result from the [Perron-Frobenius Theorem](https://en.wikipedia.org/wiki/Perron–Frobenius_theorem) is needed.
This theorem states that a stochastic matrix will have a largest eigenvalue with multiplicity 1. Here all eigenvalues will satisfy
{% katex %}\lambda_1=1 \ &gt;\ \mid{\lambda_i}\mid,\ \forall\ 1\ &lt;\ i\ \leq\ N{% endkatex %}.

Denote the eigenvector {% katex %}V_j{% endkatex %} by the column vector,
{% katex display %}
V_j =
\begin{pmatrix}
v_{1j} \\
v_{2j} \\
\vdots \\
v_{Nj}
\end{pmatrix},
{% endkatex %}

and let {% katex %}V{% endkatex %} be the matrix with columns that are the eigenvectors of
{% katex %}P{% endkatex %} with {% katex %}V_1{% endkatex %} from equation
{% katex %}(7){% endkatex %} in the first column,
{% katex display %}
V=
\begin{pmatrix}
1 &amp; v_{12} &amp; \cdots &amp; v_{1N} \\
1 &amp; v_{22} &amp; \cdots &amp; v_{2N} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; v_{N2} &amp; \cdots &amp; v_{NN}
\end{pmatrix}.
{% endkatex %}

Assume that {% katex %}V{% endkatex %} is invertible and denote the inverse by,

{% katex display %}
V^{-1}=
\begin{pmatrix}
v^{-1}_{11} &amp; v^{-1}_{12} &amp; \cdots &amp; v^{-1}_{1N} \\
v^{-1}_{21} &amp; v^{-1}_{22} &amp; \cdots &amp; v^{-1}_{2N} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
v^{-1}_{N1} &amp; v^{-1}_{N2} &amp; \cdots &amp; v^{-1}_{NN}
\end{pmatrix}\ \ \ \ \ (8).
{% endkatex %}

If the identity matrix is represented by {% katex %}I{% endkatex %} then {% katex %}VV^{-1} = I{% endkatex %}.
Let {% katex %}\Lambda{% endkatex %} be a diagonal matrix constructed from the eigenvalues of
{% katex %}P{% endkatex %} using {% katex %}\lambda_1=1{% endkatex %},

{% katex display %}
\Lambda =
\begin{pmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \lambda_2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \lambda_N
\end{pmatrix}.
{% endkatex %}

Sufficient information about the eigenvalues and eigenvectors has been obtained to prove some very
general results for Markov Chains.
The following section will work through the equilibrium limit using the using these results
to construct a diagonalized representation of the matrix.

### Diagonalization of Transition Matrix

Using the results obtained in the previous section the diagonalized
form of the transition matrix is given by,

{% katex display %}
P = V\Lambda V^{-1},
{% endkatex %}

Using this representation of {% katex %}P{% endkatex %} an expression for {% katex %}P^t{% endkatex %}
is obtained,
{% katex display %}
\begin{aligned}
P^{t} &amp;= P^{t-1}V\Lambda V^{-1} \\
&amp;= P^{t-2}V\Lambda V^{-1}V\Lambda V^{-1} \\
&amp;= P^{t-2}V\Lambda^2 V^{-1}\\
&amp;\vdots \\
&amp;= PV\Lambda^{t-1} V^{-1} \\
&amp;= V\Lambda^{t}V^{-1}
\end{aligned}
{% endkatex %}

Evaluation of {% katex %}\Lambda^{t}{% endkatex %} is straight forward,

{% katex display %}
\Lambda^t =
\begin{pmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \lambda_2^t &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \lambda_N^t
\end{pmatrix}.
{% endkatex %}

Since {% katex %}\mid{\lambda_i}\mid\ &lt;\ 1,\ \forall\ 1\ &lt;\ i\ \leq\ N{% endkatex %} in the limit
{% katex %}t\to\infty{% endkatex %} it is seen that,
{% katex display %}
\Lambda^{E} =
\lim_{t\to\infty} \Lambda^t =
\lim_{t\to\infty}
\begin{pmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \lambda_2^t &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \lambda_N^t
\end{pmatrix}
=
\begin{pmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 0 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; 0
\end{pmatrix},
{% endkatex %}

so,
{% katex display %}
P^{E} = \lim_{t\to\infty} P^{t} = \lim_{t\to\infty} V\Lambda^{t} V^{-1} = V\Lambda^{E}V^{-1}.
{% endkatex %}

Evaluation of the first two terms on the righthand side gives,

{% katex display %}
V\Lambda^{E} =
\begin{pmatrix}
1 &amp; v_{12} &amp; \cdots &amp; v_{1N} \\
1 &amp; v_{22} &amp; \cdots &amp; v_{2N} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; v_{N2} &amp; \cdots &amp; v_{NN}
\end{pmatrix}
\begin{pmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 0 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; 0
\end{pmatrix}
=
\begin{pmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
1 &amp; 0 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; 0 &amp; \cdots &amp; 0
\end{pmatrix}.
{% endkatex %}

It follows that,
{% katex display %}
V\Lambda^{E} V^{-1} =
\begin{pmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
1 &amp; 0 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; 0 &amp; \cdots &amp; 0
\end{pmatrix}
\begin{pmatrix}
v^{-1}_{11} &amp; v^{-1}_{12} &amp; \cdots &amp; v^{-1}_{1N} \\
v^{-1}_{21} &amp; v^{-1}_{22} &amp; \cdots &amp; v^{-1}_{2N} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
v^{-1}_{N1} &amp; v^{-1}_{N2} &amp; \cdots &amp; v^{-1}_{NN}
\end{pmatrix}
=
\begin{pmatrix}
v^{-1}_{11} &amp; v^{-1}_{12} &amp; \cdots &amp; v^{-1}_{1N} \\
v^{-1}_{11} &amp; v^{-1}_{12} &amp; \cdots &amp; v^{-1}_{1N} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
v^{-1}_{11} &amp; v^{-1}_{12} &amp; \cdots &amp; v^{-1}_{1N}
\end{pmatrix}.
{% endkatex %}

Finally, the equilibrium transition matrix is given by,
{% katex display %}
P^{E} = V\Lambda^{E} V^{-1} =
\begin{pmatrix}
v^{-1}_{11} &amp; v^{-1}_{12} &amp; \cdots &amp; v^{-1}_{1N} \\
v^{-1}_{11} &amp; v^{-1}_{12} &amp; \cdots &amp; v^{-1}_{1N} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
v^{-1}_{11} &amp; v^{-1}_{12} &amp; \cdots &amp; v^{-1}_{1N}
\end{pmatrix}\ \ \ \ \ (9).
{% endkatex %}

The rows of {% katex %}P^{E}{% endkatex %} are identical and given by the
first row of the inverse of the matrix of eigenvectors, {% katex %}V^{-1}{% endkatex %},
from equation {% katex %}(8){% endkatex %}. This row is a consequence of the location of the
{% katex %}\lambda=1{% endkatex %} eigenvalue and eigenvector in {% katex %}\Lambda{% endkatex %} and {% katex %}V{% endkatex %} respectively.
Since {% katex %}P^{E}{% endkatex %} is a transition matrix,

{% katex display %}
\begin{gathered}
\sum_{j=1}^{N} v_{ij}^{-1}\ =\ 1\\
v_{ij}^{-1}\ \geq \ 0.
\end{gathered}
{% endkatex %}

## Equilibrium Distribution

The equilibrium distribution is defined by a solution to equation {% katex %}(5){% endkatex %}
that is independent of time.

{% katex display %}
\pi^{T} = \pi^{T}P^t\ \ \ \ \ (10).
{% endkatex %}

Consider a distribution {% katex %}\pi_{E}{% endkatex %} that satisfies,
{% katex display %}
\pi_{E}^{T} = \pi_{E}^{T}P\ \ \ \ \ (11).
{% endkatex %}

It is easy to show that {% katex %}\pi_{E}{% endkatex %} is an equilibrium solution
by substituting it into equation {% katex %}(10){% endkatex %}.
{% katex display %}
\begin{aligned}
\pi_{E}^{T} &amp;= \pi_{E}^{T}P^t \\
&amp;= (\pi_{E}^{T}P)P^{t-1} \\
&amp;= \pi_{E}^{T}P^{t-1} \\
&amp;= \pi_{E}^{T}P^{t-2} \\
&amp;\vdots \\
&amp;= \pi_{E}^{T}P \\
&amp;= \pi_{E}^{T}.
\end{aligned}
{% endkatex %}

### Relationship Between Equilibrium Distribution and Transition Matrix

To determine the relationship between {% katex %}\pi_E{% endkatex %} and {% katex %}P^{E}{% endkatex %},
begin by considering an arbitrary initial distribution states
with {% katex %}N{% endkatex %} elements,
{% katex display %}
\pi =
\begin{pmatrix}
\pi_{1} \\
\pi_{2} \\
\vdots \\
\pi_{N}
\end{pmatrix},
{% endkatex %}

where,

{% katex display %}
\begin{gathered}
\sum_{j=1}^{N}\pi_{j} = 1\\
\pi_{j}\ \geq\ 0
\end{gathered}.
{% endkatex %}

The distribution when the Markov Chain has had sufficient time to reach equilibrium will be given by,
{% katex display %}
\begin{aligned}
\pi^{T}P^{E} &amp;=
\begin{pmatrix}
\pi_{1} &amp; \pi_{2} &amp; \cdots &amp; \pi_{N}
\end{pmatrix}
\begin{pmatrix}
v^{-1}_{11} &amp; v^{-1}_{12} &amp; \cdots &amp; v^{-1}_{1N} \\
v^{-1}_{11} &amp; v^{-1}_{12} &amp; \cdots &amp; v^{-1}_{1N} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
v^{-1}_{11} &amp; v^{-1}_{12} &amp; \cdots &amp; v^{-1}_{1N}
\end{pmatrix} \\
&amp;=
\begin{pmatrix}
v^{-1}_{11}\sum_{j=1}^{N} \pi_{j} &amp;
v^{-1}_{12}\sum_{j=1}^{N} \pi_{j} &amp;
\cdots &amp;
v^{-1}_{1N}\sum_{j=1}^{N} \pi_{j}
\end{pmatrix},
\end{aligned}
{% endkatex %}

since, {% katex %}\sum_{j=1}^{N} \pi_{j} = 1{% endkatex %},

{% katex display %}
\pi^{T}P^{E} =
\begin{pmatrix}
v^{-1}_{11} &amp; v^{-1}_{12} &amp; \cdots &amp; v^{-1}_{1N}
\end{pmatrix}.
{% endkatex %}

Thus any initial distribution {% katex %}\pi{% endkatex %} will after
sufficient time approach the distribution above. It follows that it will be the solution
of equation {% katex %}(11){% endkatex %} which defines the equilibrium distribution,

{% katex display %}
\pi_E =
\begin{pmatrix}
v^{-1}_{11} \\
v^{-1}_{12} \\
\vdots \\
v^{-1}_{1N}
\end{pmatrix}.
{% endkatex %}

### Solution of Equilibrium Equation

An equation for the equilibrium distribution, {% katex %}\pi_{E}{% endkatex %}, can
be obtained from equation {% katex %}(11){% endkatex %},
{% katex display %}
\pi^{T}_E\left(P - I\right) = 0\ \ \ \ \ (12),
{% endkatex %}
where {% katex %}I{% endkatex %} is the identity matrix. Equation {% katex %}(12){% endkatex %} alone
is insufficient to obtain a unique solution since the system of linear equations it defines is
[Linearly Dependent](https://en.wikipedia.org/wiki/Linear_independence). In a linearly dependent
system of equations some equations are the result of linear operations on the others.
It is straight forward to show that one of the equations defined by {% katex %}(12){% endkatex %} can
be eliminated by summing the other equations and multiplying by {% katex %}-1{% endkatex %}.
If the equations were
linearly independent the only solution would be the trivial zero solution,
{% katex %}{\left( \pi^{T}_E \right)}_{i}\ =\ 0,\ \forall\ i{% endkatex %}. A unique solution to
{% katex %}(12){% endkatex %} is obtained by including the normalization constraint,
{% katex display %}
\sum_{j=1}^{N} {\left( \pi_{E}^{T} \right)}_{j} = 1.
{% endkatex %}
The resulting system of equations to be solved is given by,
{% katex display %}
\pi_{E}^{T}
\begin{pmatrix}
{P_{11} - 1} &amp; P_{12} &amp; \cdots &amp; P_{1N} &amp; 1 \\
P_{21} &amp; {P_{22} -1} &amp; \cdots &amp; P_{2N} &amp; 1 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots\\
P_{N1} &amp; P_{N2} &amp; \cdots &amp; {P_{NN} - 1} &amp; 1 \\
\end{pmatrix}
=
\begin{pmatrix}
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{pmatrix}\ \ \ \ \ (13).
{% endkatex %}

## Example

Consider the Markov Chain defined by the transition matrix,
{% katex display %}
P =
\begin{pmatrix}
0.0 &amp; 0.9 &amp; 0.1 &amp; 0.0 \\
0.8 &amp; 0.1 &amp; 0.0 &amp; 0.1 \\
0.0 &amp; 0.5 &amp; 0.3 &amp; 0.2 \\
0.1 &amp; 0.0 &amp; 0.0 &amp; 0.9
\end{pmatrix}\ \ \ \ \ (14).
{% endkatex %}
The state transition diagram below provides a graphical representation of {% katex %}P{% endkatex %}.
&lt;div style=&quot;text-align:center;&quot;&gt;
  &lt;img class=&quot;post-image&quot;  src=&quot;/assets/posts/discrete_state_markov_chain_equilibrium/transition_diagram.png&quot;&gt;
&lt;/div&gt;

### Convergence to Equilibrium

Relaxation of both the transition matrix and distribution to their equilibrium values
is easily demonstrated with the few lines of Python executed within `ipython`.

```shell
In [1]: import numpy
In [2]: t = [[0.0, 0.9, 0.1, 0.0],
   ...:      [0.8, 0.1, 0.0, 0.1],
   ...:      [0.0, 0.5, 0.3, 0.2],
   ...:      [0.1, 0.0, 0.0, 0.9]]
In [3]: p = numpy.matrix(t)
In [4]: p**100
Out[4]:
matrix([[0.27876106, 0.30088496, 0.03982301, 0.38053097],
        [0.27876106, 0.30088496, 0.03982301, 0.38053097],
        [0.27876106, 0.30088496, 0.03982301, 0.38053097],
        [0.27876106, 0.30088495, 0.03982301, 0.38053098]])
```

Here the transition matrix from the initial state to states {% katex %}100{% endkatex %} time steps
in the future is computed using equation {% katex %}(2){% endkatex %}. The result obtained
has identical rows as obtained in equation {% katex %}(9){% endkatex %}.
{% katex display %}
P^{100} =
\begin{pmatrix}
0.27876106 &amp; 0.30088496 &amp; 0.03982301 &amp; 0.38053097 \\
0.27876106 &amp; 0.30088496 &amp; 0.03982301 &amp; 0.38053097 \\
0.27876106 &amp; 0.30088496 &amp; 0.03982301 &amp; 0.38053097 \\
0.27876106 &amp; 0.30088495 &amp; 0.03982301 &amp; 0.38053098
\end{pmatrix}\ \ \ \ \ (15).
{% endkatex %}

For an initial distribution {% katex %}\pi{% endkatex %} the distribution after {% katex %}100{% endkatex %}
time steps is evaluated using,

```shell
In [5]: c = [[0.1],
   ...:      [0.5],
   ...:      [0.35],
   ...:      [0.05]]
In [6]: π = numpy.matrix(c)
In [8]: π.T*p**100
Out[8]: matrix([[0.27876106, 0.30088496, 0.03982301, 0.38053097]])
```

Here an initial distribution is constructed that satisfies
{% katex %}\sum_{i=0}^3 \pi_i = 1{% endkatex %}. Then equation {% katex %}(5){% endkatex %} is used
to compute the distribution after {% katex %}100{% endkatex %} time steps.
The result is that expected from the previous analysis.
In the equilibrium limit the distribution is the repeated row of the equilibrium transition matrix,
namely,

{% katex display %}
\pi_{100} =
\begin{pmatrix}
0.27876106 \\
0.30088496 \\
0.03982301 \\
0.38053097
\end{pmatrix}\ \ \ \ \ (16).
{% endkatex %}

The plot below illustrates the convergence of the distribution from the previous example.
In the plot the components of {% katex %}\pi_t{% endkatex %} from equation {% katex %}(5){% endkatex %}
are plotted for each time step. The convergence to the limiting value occurs rapidly. Within only
{% katex %}20{% endkatex %} steps {% katex %}\pi_t{% endkatex %} has reached limiting distribution.

&lt;div style=&quot;text-align:center;&quot;&gt;
  &lt;img class=&quot;post-image&quot;  src=&quot;/assets/posts/discrete_state_markov_chain_equilibrium/distribution_relaxation_1.png&quot;&gt;
&lt;/div&gt;

### Equilibrium Transition Matrix

In this section the equilibrium limit of the transition matrix is determined for the example Markov Chain
shown in equation {% katex %}(14){% endkatex %}.
It was previously shown that this limit is given by equation {% katex %}(9){% endkatex %}. To evaluate
this equation the example transition matrix must be diagonalized.
First, the transition matrix eigenvalues and eigenvectors are computed using the `numpy` linear
algebra library.

```shell
In [9]: λ, v = numpy.linalg.eig(p)
In [10]: λ
Out[10]: array([-0.77413013,  0.24223905,  1.        ,  0.83189108])
In [11]: v
Out[11]:
matrix([[-0.70411894,  0.02102317,  0.5       , -0.4978592 ],
        [ 0.63959501,  0.11599428,  0.5       , -0.44431454],
        [-0.30555819, -0.99302222,  0.5       , -0.14281543],
        [ 0.04205879, -0.00319617,  0.5       ,  0.73097508]])
```

It is seen that {% katex %}\lambda\ =\ 1{% endkatex %} is indeed an eigenvalue,
as previously proven and that other eigenvalues have magnitudes less than {% katex %}1{% endkatex %}.
This is in agreement with Perron-Frobenius Theorem. The `numpy` linear algebra library normalizes the
eigenvectors and uses the same order for eigenvalues and eigenvector columns. The eigenvector
corresponding to {% katex %}\lambda\ =\ 1{% endkatex %} is in the third column and has all components equal.
Eigenvectors are only known to an arbitrary scalar, so the vector of {% katex %}1's{% endkatex %} used
in the previous analysis can be obtained by multiplying the third column by {% katex %}2{% endkatex %}.
After obtaining the eigenvalues and eigenvectors equation {% katex %}(9){% endkatex %} is evaluated
{% katex %}100{% endkatex %} after time steps and compared with the equilibrium limit.

```shell
In [12]: Λ = numpy.diag(λ)
In [13]: V = numpy.matrix(v)
In [14]: Vinv = numpy.linalg.inv(V)
In [15]: Λ_t = Λ**100
In [16]: Λ_t
Out[16]:
array([[7.61022278e-12, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 2.65714622e-62, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.01542303e-08]])
In [17]: V * Λ_t * Vinv
Out[17]:
matrix([[0.27876106, 0.30088496, 0.03982301, 0.38053097],
        [0.27876106, 0.30088496, 0.03982301, 0.38053097],
        [0.27876106, 0.30088496, 0.03982301, 0.38053097],
        [0.27876106, 0.30088495, 0.03982301, 0.38053098]])
```

First, the diagonal matrix of eigenvalues, {% katex %}\Lambda{% endkatex %}, is created maintaining
the order of {% katex %}\lambda{% endkatex %}. Next, the matrix {% katex %}V{% endkatex %} is constructed
with eigenvectors as columns while also maintaining the order of vectors in {% katex %}v{% endkatex %}.
The inverse of {% katex %}V{% endkatex %} is then computed. {% katex %}\Lambda^{t}{% endkatex %} can now be
computed for {% katex %}100{% endkatex %} time steps. The result is in agreement with the past effort where
the limit {% katex %}t\to\infty{% endkatex %} was evaluated giving a matrix that contained a
{% katex %}1{% endkatex %} in the {% katex %}(1,1){% endkatex %} component corresponding to the position
of the {% katex %}\lambda=1{% endkatex %} component and zeros for all others.
Here the eigenvectors are ordered differently but the only nonzero component has the
{% katex %}\lambda=1{% endkatex %} eigenvalue. Finally, equation {% katex %}(9){% endkatex %} is evaluated and
all rows are identical and equal to {% katex %}\pi_t{% endkatex %} evaluated at
{% katex %}t=100{% endkatex %}, in agreement with the equilibrium limit determined previously and calculations
performed in the last section shown in equations {% katex %}(15){% endkatex %} and {% katex %}(16){% endkatex %}.

### Equilibrium Distribution

The equilibrium distribution will now be calculated using the system of linear
equations defined by equation {% katex %}(9){% endkatex %}. Below the resulting system of equations
for the example distribution in equation {% katex %}(14){% endkatex %} is shown.

{% katex display %}
\pi_{E}^{T}
\begin{pmatrix}
-1.0 &amp; 0.9 &amp; 0.1 &amp; 0.0 &amp; 1.0 \\
0.8 &amp; -0.9 &amp; 0.0 &amp; 0.1 &amp; 1.0 \\
0.0 &amp; 0.5 &amp; -0.7 &amp; 0.2 &amp; 1.0 \\
0.1 &amp; 0.0 &amp; 0.0 &amp; -0.1 &amp; 1.0
\end{pmatrix}
=
\begin{pmatrix}
0.0 &amp; 0.0 &amp; 0.0 &amp; 0.0 &amp; 1.0
\end{pmatrix}
{% endkatex %}

This system of equations is solved using the least squares method provided by the `numpy` linear
algebra library, which requires the use of the transpose of the above equation.
The first line below computes it using equation {% katex %}(14){% endkatex %}.

```shell
In [18]: E = numpy.concatenate((p.T - numpy.eye(4), [numpy.ones(4)]))
In [19]: E
Out[19]:
matrix([[-1. ,  0.8,  0. ,  0.1],
        [ 0.9, -0.9,  0.5,  0. ],
        [ 0.1,  0. , -0.7,  0. ],
        [ 0. ,  0.1,  0.2, -0.1],
        [ 1. ,  1. ,  1. ,  1. ]])
In [20]: πe, _, _, _ = numpy.linalg.lstsq(E, numpy.array([0.0, 0.0, 0.0, 0.0, 1.0]), rcond=None)

In [21]: πe
Out[21]: array([0.27876106, 0.30088496, 0.03982301, 0.38053097])

```

Next, the equilibrium distribution is evaluated using the least squares method. The result obtained is
consistent with previous results shown in equation {% katex %}(16){% endkatex %}.

### Simulation

This section will use a direct simulation of equation {% katex %}(14){% endkatex %} to calculate the
equilibrium distribution and compare the result to those previously obtained. Below a Python
implementation of the calculation is shown.

```python
import numpy

def sample_chain(t, x0, nsample):
    xt = numpy.zeros(nsample, dtype=int)
    xt[0] = x0
    up = numpy.random.rand(nsample)
    cdf = [numpy.cumsum(t[i]) for i in range(4)]
    for t in range(nsample - 1):
        xt[t] = numpy.flatnonzero(cdf[xt[t-1]] &gt;= up[t])[0]
    return xt

# Simulation parameters
π_nsamples = 1000
nsamples = 10000
c = [[0.25],
     [0.25],
     [0.25],
     [0.25]]

# Generate π_nsamples initial state samples
π = numpy.matrix(c)
π_cdf = numpy.cumsum(c)
π_samples = [numpy.flatnonzero(π_cdf &gt;= u)[0] for u in numpy.random.rand(π_nsamples)]

# Run sample_chain for nsamples for each of the initial state samples
chain_samples = numpy.array([])
for x0 in π_samples:
  chain_samples = numpy.append(chain_samples, sample_chain(t, x0, nsamples))
```

The function `sample_chain` performs the simulation and uses
[Inverse CDF Sampling]({{ site.baseurl }}{% link _posts/2018-07-21-inverse_cdf_sampling.md %}) on the
discrete distribution obtained from the transition matrix defined by equation {% katex %}(14){% endkatex %}.
The transition matrix determines state at step {% katex %}t+1{% endkatex %} from the state at step
{% katex %}t{% endkatex %}. The following code uses `sample_chain` to generate and ensemble of
simulations with the initial state also sampled from an assumed initial distribution.
First, simulation parameters are defined and the initial distribution is assumed to be uniform.
Second, `π_nsamples` of the initial state are generated using Inverse CDF sampling with the
initial distribution. Finally, simulations of length `nsamples` are performed for each initial state.
The ensemble of samples are collected in the variable `chain_samples` and plotted below. A comparison
is made with the two other calculations performed. The first is {% katex %}\pi_t{% endkatex %} for
{% katex %}t=100{% endkatex %} shown in equation {% katex %}(16){% endkatex %} and the second
the solution to equation {% katex %}(9){% endkatex %}. The different
calculations are indistinguishable.

&lt;div style=&quot;text-align:center;&quot;&gt;
  &lt;img  class=&quot;post-image&quot; src=&quot;/assets/posts/discrete_state_markov_chain_equilibrium/distribution_comparison.png&quot;&gt;
&lt;/div&gt;

## Conclusions

Markov Chain equilibrium for discrete state processes is a general theory of the time evolution
of transition probabilities and state distributions. It has been shown that equilibrium
is a consequence of assuming the transition matrix and distribution vector are both stochastic.
Expressions were derived for the time evolution of any transition matrix and distribution and
the equilibrium solutions were then obtained analytically by evaluating the limit
{% katex %}t\to\infty{% endkatex %}. A calculation was performed using the obtained
equations for the equilibrium solutions and the `numpy` linear algebra libraries
using an example transition matrix. These results were compared to ensemble simulations.
The time to relax from an arbitrary state to the equilibrium distributions was shown to occur
within {% katex %}O(10){% endkatex %} time steps.</content><author><name>Troy Stribling</name></author><summary type="html">A Markov Chain is a sequence of states where transitions between states occur ordered in time with the probability of transition depending only on the previous state. Here the states will be assumed a discrete finite set and time a discrete unbounded set. If the set of states is given by {x1, x2,…, xN}\{x_1,\ x_2,\ldots,\ x_N\}{x1​, x2​,…, xN​} the probability that the process will be in state xix_ixi​ at time ttt is denoted by P(Xt=xi)P(X_t=x_i)P(Xt​=xi​), referred to as the distribution. Markov Chain equilibrium is defined by limt→∞P(Xt=xi) &amp;lt; ∞\lim_{t\to\infty}P(X_t=x_i)\ &amp;lt;\ \inftylimt→∞​P(Xt​=xi​) &amp;lt; ∞, that is, as time advances P(Xt=xi)P(X_t=x_i)P(Xt​=xi​) becomes independent of time. Here a solution for this limit is discussed and illustrated with examples.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/posts/discrete_state_markov_chain_equilibrium/distribution_comparison.png" /></entry><entry><title type="html">Rejection Sampling</title><link href="http://localhost:4000/2018/07/29/rejection_sampling.html" rel="alternate" type="text/html" title="Rejection Sampling" /><published>2018-07-29T00:00:00-07:00</published><updated>2018-07-29T00:00:00-07:00</updated><id>http://localhost:4000/2018/07/29/rejection_sampling</id><content type="html" xml:base="http://localhost:4000/2018/07/29/rejection_sampling.html">[Rejection Sampling](https://en.wikipedia.org/wiki/Rejection_sampling) is a method for obtaining samples for a known target probability distribution using samples from some other proposal distribution.
It is a more general method than
[Inverse CDF Sampling]({{ site.baseurl }}{% link _posts/2018-07-21-inverse_cdf_sampling.md %}) which requires
distribution to have an invertible CDF. Inverse CDF Sampling transforms a
{% katex %}\textbf{Uniform}(0,\ 1){% endkatex %} random variable into a random variable with
a desired target distribution using the inverted CDF of the target distribution. While, Rejection Sampling
is a method for transformation of random variables from arbitrary proposal distributions into a desired target
distribution.

&lt;!--more--&gt;

The implementation of Rejection Sampling requires the consideration of a target distribution,
{% katex %}f_X(X){% endkatex %}, a proposal distribution, {% katex %}f_Y(Y){% endkatex %}, and a {% katex %}\textbf{Uniform}(0,\ 1){% endkatex %} acceptance probability, {% katex %}U{% endkatex %}, with distribution {% katex %}f_U(U)=1{% endkatex %}. A proposal sample, {% katex %}Y{% endkatex %}, is generated using, {% katex %}f_Y(Y){% endkatex %}, and independently a uniform acceptance sample, {% katex %}U{% endkatex %}, is generated
using {% katex %}f_U(U){% endkatex %}.
A criterion is defined for acceptance of a sample, {% katex %}X{% endkatex %}, to be considered a
sample of {% katex %}f_X(X){% endkatex %},

{% katex display %}
U\ \leq\ \frac{f_X(Y)}{cf_Y(Y)}\ \ \ \ \ (1),
{% endkatex %}

where, {% katex %}c{% endkatex %}, is chosen to satisfy
{% katex %}0\ \leq\ f_X(Y)/cf_Y(Y)\ \leq\ 1, \ \ \forall\ Y{% endkatex %}. If equation
{% katex %}(1){% endkatex %} is satisfied the proposed sample {% katex %}Y{% endkatex %} is
accepted as a sample of {% katex %}f_X(X){% endkatex %} where {% katex %}X=Y{% endkatex %}.
If equation {% katex %}(1){% endkatex %} is not satisfied {% katex %}Y{% endkatex %} is discarded.

The acceptance function is defined by,

{% katex display %}
h(Y) = \frac{f_X(Y)}{f_Y(Y)}\ \ \ \ \ (2).
{% endkatex %}

It can be insightful to compare {% katex %}h(y){% endkatex %} to {% katex %}f_X(y){% endkatex %}
when choosing a proposal distribution. If {% katex %}h(y){% endkatex %} does not share sufficient mass with
{% katex %}f_X(Y){% endkatex %} then the choice of {% katex %}f_Y(Y){% endkatex %} should be reconsidered.

The Rejection Sampling algorithm can be summarized in the following steps that are repeated for the generation of each sample,

1. Generate a sample {% katex %}Y \sim f_Y(Y){% endkatex %}.
2. Generate a sample {% katex %}U\sim\textbf{Uniform}(0,\ 1){% endkatex %} independent of {% katex %}Y{% endkatex %}.
3. If equation {% katex %}(1){% endkatex %} is satisfied then {% katex %}X=Y{% endkatex %} is accepted as a sample
of {% katex %}f_X(X){% endkatex %}. If equation {% katex %}(1){% endkatex %} is not satisfied then {% katex %}Y{% endkatex %}
is discarded.

## Theory

To prove that Rejection Sampling works it must be shown that,
{% katex display %}
P\left[Y\ \leq\ y\ |\ U\ \leq\ \frac{f_X(Y)}{cf_Y(Y)}\right]=F_X(y)\ \ \ \ \ (3),
{% endkatex %}

where {% katex %}F_X(y){% endkatex %} is the CDF for {% katex %}f_X(y){% endkatex %},
{% katex display %}
F_X(y) = \int_{-\infty}^{y} f_X(w)dw.
{% endkatex %}

To prove equation {% katex %}(2){% endkatex %} a couple of intermediate steps are required. First,
The joint distribution of {% katex %}U{% endkatex %} and {% katex %}Y{% endkatex %} containing the
acceptance constraint will be shown to be,

{% katex display %}
P\left[U\ \leq\ \frac{f_X(Y)}{cf_Y(Y)},\ Y\ \leq\ y\right] = \frac{F_X(y)}{c}\ \ \ \ \ (4).
{% endkatex %}

Since the Rejection Sampling algorithm as described in the previous section assumes
that {% katex %}Y{% endkatex %} and {% katex %}U{% endkatex %} are independent random variables,
{% katex%}
f_{YU}(Y, U)\ =\ f_Y(Y)f_U(U)\ = f_Y(Y).
{% endkatex %} It follows that,

{% katex display %}
\begin{aligned}
P\left[U\ \leq\ \frac{f_X(Y)}{cf_Y(Y)},\ Y\ \leq y\right] &amp;= \int_{-\infty}^{y}\int_{0}^{f_X(w)/cf_Y(w)} f_{YU}(w, u) du dw\\
&amp;= \int_{-\infty}^{y}\int_{0}^{f_X(w)/cf_Y(w)} f_Y(w) du dw \\
&amp;= \int_{-\infty}^{y} f_Y(w) \int_{0}^{f_X(w)/cf_Y(w)} du dw \\
&amp;= \int_{-\infty}^{y} f_Y(w) \frac{f_X(w)}{cf_Y(w)} dw \\
&amp;= \frac{1}{c}\int_{-\infty}^y f_X(w) dw \\
&amp;= \frac{F_X(y)}{c}, \\
\end{aligned}
{% endkatex %}

Next, it will be shown that,
{% katex display %}
P\left[U\ \leq\ \frac{f_X(Y)}{cf_Y(Y)}\right] = \frac{1}{c}\ \ \ \ \ (5).
{% endkatex %}

This result follows from equation {% katex %}(4){% endkatex %} by taking the
limit {% katex %}y\to\infty{% endkatex %}
and noting that, {% katex %}\int_{-\infty}^{\infty} f_X(y) dy = 1{% endkatex %}.

{% katex display %}
\begin{aligned}
P\left[U\ \leq\ \frac{f_X(Y)}{cf_Y(Y)}\right] &amp;= \int_{-\infty}^{\infty}\int_{0}^{f_X(w)/cf_Y(w)} f_{YU}(w, u) du dw\\
&amp;= \frac{1}{c}\int_{-\infty}^{\infty} f_X(w) dw \\
&amp;= \frac{1}{c}
\end{aligned}
{% endkatex %}

Finally, equation {% katex %}(3){% endkatex %} can be proven, using the definition of [Conditional Probability](https://en.wikipedia.org/wiki/Conditional_probability),
equation {% katex %}(4){% endkatex %} and equation {% katex %}(5){% endkatex %},

{% katex display %}
\begin{aligned}
P\left[Y\ \leq\ y\ |\ U\ \leq\ \frac{f_X(Y)}{cf_Y(Y)}\right] &amp;= \frac{P\left[U\ \leq\ \frac{f_X(Y)}{cf_Y(Y)},\ Y \leq y\right]}{P\left[U\ \leq\ \frac{f_X(Y)}{cf_Y(Y)}\right]}\\
&amp;=\frac{F_X(y)}{c}\frac{1}{1/c}\\
&amp;=F_X(y)
\end{aligned}
{% endkatex %}

## Implementation

An implementation in Python of the Rejection Sampling algorithm is listed below,

```python
def rejection_sample(h, y_samples, c):
    nsamples = len(y_samples)
    u = numpy.random.rand(nsamples)
    accepted_mask = (u &lt;= h(y_samples) / c)
    return y_samples[accepted_mask]
```

The above function `rejection_sample(h, y_samples, c)` takes three arguments as input which are
described in the table below.

| Argument  | Description  |
| :-----: | :---- |
| `h` | The acceptance function. Defined by {% katex %}h(Y)=f_X(Y)/f_Y(Y){% endkatex %}.|
| `y_samples` | Array of samples of {% katex %}Y{% endkatex %} generated using {% katex %}f_Y(Y){% endkatex %}.|
|`c` | A constant chosen so {% katex %}0\ \leq\ h(Y)/c\ \leq\ 1, \ \ \forall\ Y{% endkatex %} |

The execution of `rejection_sample(h, y_samples, c)` begins by generating an appropriate number of acceptance variable samples, {% katex %}U{% endkatex %}, and
then determines which satisfy the acceptance criterion specified by equation (1). The accepted samples are then returned.

## Examples

Consider the [{% katex %}\textbf{Weibull}{% endkatex %} Distribution](https://en.wikipedia.org/wiki/Weibull_distribution). The PDF is
given by,

{% katex display %}
f_X(x; k, \lambda) =
\begin{cases}
\frac{k}{\lambda}\left(\frac{x}{\lambda} \right)^{k-1} e^{-\left(x/\lambda\right)^k} &amp; x\ \geq\ 0 \\
0 &amp; x &lt; 0
\end{cases} \ \ \ \ \ (4),
{% endkatex %}

where {% katex %}k\ &gt;\ 0{% endkatex %} is the shape parameter and {%katex %}\lambda\ &gt;\ 0{% endkatex %} the scale parameter.
The CDF is given by,

{% katex display %}
F_X(x; k, \lambda) =
\begin{cases}
1-e^{\left(\frac{-x}{\lambda}\right)^k
} &amp; x \geq 0 \\
0 &amp; x &lt; 0.
\end{cases}
{% endkatex %}

The first and second moments are,

{% katex display %}
\begin{aligned}
\mu &amp; = \lambda\Gamma\left(1+\frac{1}{k}\right) \\
\sigma^2 &amp; = \lambda^2\left[\Gamma\left(1+\frac{2}{k}\right)-\left(\Gamma\left(1+\frac{1}{k}\right)\right)^2\right]
\end{aligned} \ \ \ \ \ (5),
{% endkatex %}

where {% katex %}\Gamma(x){% endkatex %} is the [Gamma function](https://en.wikipedia.org/wiki/Gamma_function).
In the examples described here it will be assumed that {% katex %}k=5.0{% endkatex %} and
{% katex %}\lambda=1.0{% endkatex %}. The plot below shows the PDF and CDF using these values.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/rejection_sampling/weibull_pdf.png&quot;&gt;

The following sections will compare the performance of generating
{% katex %}\textbf{Weibull}{% endkatex %} samples using both
{% katex %}\textbf{Uniform}(0,\ m){% endkatex %} and {% katex %}\textbf{Normal}(\mu,\ \sigma){% endkatex %}
proposal distributions.

### Uniform Proposal Distribution

Here a {% katex %}\textbf{Uniform}(0,\ m){% endkatex %} proposal distribution will be used to
generate samples for the {% katex %}\textbf{Weibull}{% endkatex %} distribution
{% katex %}(4){% endkatex %}. It provides a simple and
illustrative example of the algorithm. The following plot shows the
target distribution {% katex %}f_X(y){% endkatex %}, the proposal distribution
{% katex %}f_Y(y){% endkatex %} and the acceptance function
{% katex %}h(y)=f_X(y)/f_Y(y){% endkatex %} used in this example. The
uniform proposal distribution requires that a bound be placed
on the proposal samples, which will be assumed to be {% katex %}m=1.6{% endkatex %}. Since
the proposal distribution is constant the acceptance function, {% katex %}h(y){% endkatex %}, will be
a constant multiple of the target distribution. This is illustrated in the plot below.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/rejection_sampling/weibull_uniform_sampled_functions.png&quot;&gt;

The Python code used to generate the samples using  `rejection_sample(h, y_samples, c)` is listed
below.

```python
weibull_pdf = lambda v: (k/λ)*(v/λ)**(k-1)*numpy.exp(-(v/λ)**k)

k = 5.0
λ = 1.0

xmax = 1.6
ymax = 2.0
nsamples = 100000

y_samples = numpy.random.rand(nsamples) * xmax
samples = rejection_sample(weibull_pdf, y_samples, ymax)
```

The following plot compares the histogram computed form the generated samples with the target
distribution {% katex %}(4){% endkatex %}. The fit is acceptable.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/rejection_sampling/weibull_uniform_sampled_distribution.png&quot;&gt;

The next two plots illustrate convergence of the sample mean, {% katex %}\mu{% endkatex %},
and standard deviation, {% katex %}\sigma{% endkatex %}, by comparing the cumulative sums
computed from the samples to target distribution values computed
from equation {% katex %}(5){% endkatex %}. The convergence of the sampled
{% katex %}\mu{% endkatex %} is quite rapid. Within only {% katex %}10^2{% endkatex %}
samples {% katex %}\mu{% endkatex %} computed form the samples is very close the the target value
and by {% katex %}10^4{% endkatex %} samples the two values are indistinguishable.
The convergence of the sampled {% katex %}\sigma{% endkatex %} to the target value is not as
rapid as the convergence of the sampled {% katex %}\mu{% endkatex %} but is still quick. By
{% katex %}10^4{% endkatex %} samples the two values are near indistinguishable.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/rejection_sampling/weibull_uniform_mean_convergence.png&quot;&gt;

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/rejection_sampling/weibull_uniform_sigma_convergence.png&quot;&gt;

Even though {% katex %}10^5{% endkatex %} proposal samples were generated not all were accepted. The
plot below provides insight into the efficiency of the algorithm. In the plot the generated pairs of
acceptance probability {% katex %}U{% endkatex %} and sample proposal {% katex %}Y{% endkatex %} are
plotted with {% katex %}U{% endkatex %} on the vertical axis and {% katex %}Y{% endkatex %} on
the horizontal axis. Also, shown is the scaled acceptance function {% katex %}h(Y)/c{% endkatex %}.
If {% katex %}U\ &gt;\ h(Y)/c{% endkatex %} the sample is rejected and colored orange in the plot and
if {% katex %}U\ \leq\ h(Y)/c{% endkatex %} the sample is accepted, {% katex %}X=Y{% endkatex %} and colored blue.
Only {% katex %}31\%{% endkatex %} of the generated samples were accepted.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/rejection_sampling/weibull_uniform_efficiency.png&quot;&gt;

To improve the acceptance percentage of proposed samples a different proposal distribution must be
considered. In the plot above it is seen that the {% katex %}\textbf{Uniform}(0,\ 1.6){% endkatex %}
proposal distribution uniformly samples the space enclosed by the rectangle it defines without consideration for the shape of
the target distribution. The acceptance percentage will be determined by the ratio of the target
distribution area enclosed by the proposal distribution and the proposal distribution area.
As the target distribution becomes sharp the acceptance percentage will decrease. A proposal distribution that samples the area under
{% katex %}h(Y)/c{% endkatex %} efficiently will have a higher acceptance percentage. It should be kept in mind that rejection of proposal samples is required for the algorithm to work.
If no proposal samples are rejected the proposal and target distributions will be equivalent.

### Normal Proposal Distribution

In this section a sampler using a {% katex %}\textbf{Normal}(\mu,\ \sigma){% endkatex %} proposal
distribution and target {% katex %}\textbf{Weibull}{% endkatex %} distribution is discussed.
A {% katex %}\textbf{Normal}{% endkatex %} proposal distribution has advantages over
the {% katex %}\textbf{Uniform}(0,\ m){% endkatex %} distribution discussed in the previous
section. First, it can provide unbounded samples, while a uniform proposal requires specifying bounds
on the samples. Second, it is a closer approximation to the target distribution so it should provide samples
that are accepted with greater frequency. A disadvantage of the {% katex %}\textbf{Normal}{% endkatex %}
proposal distribution is that it requires specification of {% katex %}\mu{% endkatex %} and
{% katex %}\sigma{% endkatex %}.
If these parameters are the slightest off the performance of the
sampler will be severely degraded. To learn this lesson the first attempt will assume values for
both the parameters that closely match the target distribution. The following plot compares the {% katex %}f_X(y){% endkatex %}, the proposal distribution {% katex %}f_Y(y){% endkatex %} and the acceptance function
{% katex %}h(y){% endkatex %}. There is a large peak in {% katex %}h(y){% endkatex %} to right caused
by the more rapid increase of the {% katex %}\textbf{Weibull}{% endkatex %} distribution relative to the
{% katex %}\textbf{Normal}{% endkatex %} distribution with the result
that most of its mass is not aligned with the target distribution.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/rejection_sampling/weibull_normal_1_sampled_functions.png&quot;&gt;

The Python code used to generate the samples using  `rejection_sample(h, y_samples, c)` is listed
below.

```python
weibull_pdf = lambda v: (k/λ)*(v/λ)**(k-1)*numpy.exp(-(v/λ)**k)

def normal(μ, σ):
    def f(x):
        ε = (x - μ)**2/(2.0*σ**2)
        return numpy.exp(-ε)/numpy.sqrt(2.0*numpy.pi*σ**2)
    return f

k = 5.0
λ = 1.0

σ = 0.2
μ = 0.95

xmax = 1.6
nsamples = 100000

y_samples = numpy.random.normal(μ, σ, nsamples)
ymax = h(x_values).max()
h = lambda x: weibull_pdf(x) / normal(μ, σ)(x)

samples = rejection_sample(h, y_samples, ymax)
```

The first of the following plots compares the histogram computed from the generated samples with the target
distribution {% katex %}(4){% endkatex %} and the second illustrates which proposal samples were accepted.
The histogram fit is good but only {% katex %}23\%{% endkatex %} of the samples were accepted which is worse
than the result obtained with the uniform proposal previously discussed.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/rejection_sampling/weibull_normal_1_sampled_distribution.png&quot;&gt;

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/rejection_sampling/weibull_normal_1_efficiency.png&quot;&gt;

In an attempt to improve the acceptance rate {% katex %}\mu{% endkatex %} of the proposal distribution
is decreased slightly and {% katex %}\sigma{% endkatex %} is increased.
The result is shown in the next plot.
The proposal distribution now covers the target distribution tails. The acceptance function,
{% katex %}h(Y){% endkatex %}, now has its peak inside the target distribution with significant
overlap of mass.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/rejection_sampling/weibull_normal_3_sampled_functions.png&quot;&gt;

The result is much improved. In the plot below it is seen that the percentage of accepted samples has
increased to {% katex %}79\%{% endkatex %}.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/rejection_sampling/weibull_normal_3_efficiency.png&quot;&gt;

The first of the plots below compares the histogram computed from generated samples with the target
distribution {% katex %}(4){% endkatex %} and next two compare the cumulative values of {% katex %}\mu{% endkatex %} and {% katex %}\sigma{% endkatex %} computed from the generated samples with the target distribution values from equation {% katex %}(5){% endkatex %}. The histogram is the best fit of the
examples discussed here and convergence of the sampled {% katex %}\mu{% endkatex %} and
{% katex %}\sigma{% endkatex %} occurs in about {% katex %}10^3{% endkatex %} samples.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/rejection_sampling/weibull_normal_3_sampled_distribution.png&quot;&gt;

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/rejection_sampling/weibull_normal_3_mean_convergence.png&quot;&gt;

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/rejection_sampling/weibull_normal_3_sigma_convergence.png&quot;&gt;

Sampling the {% katex %}\textbf{Weibull}{% endkatex %} distribution with a
{% katex %}\textbf{Normal}{% endkatex %} proposal distribution can produce a better result than a
uniform distribution but care must be exercised in selecting the
{% katex %}\textbf{Normal}{% endkatex %} distribution parameters.
Some choices can produce inferior results. Analysis of the the acceptance function
{% katex %}(2){% endkatex %} can provide guidance in parameter selection.

## Conclusions

Rejection Sampling provides a general method for generation of samples for a known
target distribution by rejecting or accepting samples from a known proposal distribution sampler.
It was analytically proven that if proposal samples
are accepted with a probability defined by equation {% katex %}(1){% endkatex %} the accepted samples have
the desired target distribution. An algorithm implementation was discussed and used in examples where
its performance in producing samples with a desired target distribution for several different proposal
distributions was investigated. Mean and standard deviations
computed from generated samples converged to the target distribution values in
{% katex %}O(10^3){% endkatex %} samples.for both the discrete and continuous cases. It was shown that the performance of the algorithm can vary significantly with chosen parameter values for the proposal distribution.
A criteria for evaluating the expected performance of a proposal distribution using the acceptance function,
defined by equation {% katex %}(2){% endkatex %}, was suggested. Performance was shown to improve if the
acceptance function has significant overlap with the proposal distribution.</content><author><name>Troy Stribling</name></author><summary type="html">Rejection Sampling is a method for obtaining samples for a known target probability distribution using samples from some other proposal distribution. It is a more general method than Inverse CDF Sampling which requires distribution to have an invertible CDF. Inverse CDF Sampling transforms a Uniform(0, 1)\textbf{Uniform}(0,\ 1)Uniform(0, 1) random variable into a random variable with a desired target distribution using the inverted CDF of the target distribution. While, Rejection Sampling is a method for transformation of random variables from arbitrary proposal distributions into a desired target distribution.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/posts/rejection_sampling/weibull_normal_3_efficiency.png" /></entry><entry><title type="html">Inverse CDF Sampling</title><link href="http://localhost:4000/2018/07/21/inverse_cdf_sampling.html" rel="alternate" type="text/html" title="Inverse CDF Sampling" /><published>2018-07-21T00:00:00-07:00</published><updated>2018-07-21T00:00:00-07:00</updated><id>http://localhost:4000/2018/07/21/inverse_cdf_sampling</id><content type="html" xml:base="http://localhost:4000/2018/07/21/inverse_cdf_sampling.html">[Inverse CDF](https://en.wikipedia.org/wiki/Inverse_transform_sampling) sampling is a method
for obtaining samples from both discrete and continuous probability distributions that requires the
CDF to be invertible.
The method assumes values of the CDF are Uniform random variables on {% katex %}[0, 1]{% endkatex %}.
CDF values are generated and used as input into the inverted CDF to obtain samples with the
distribution defined by the CDF.
&lt;!--more--&gt;

## Discrete Distributions

A discrete probability distribution consisting of a finite set of {% katex %}N{% endkatex %}
probability values is defined by,

{% katex display %}
\{p_1,\ p_2,\ \ldots,\ p_N\}\ \ \ \ \ (1),
{% endkatex %}

with {% katex %}p_i\ \geq\ 0, \  \forall i{% endkatex %} and {% katex %}\sum_{i=1}^N{p_i} = 1{% endkatex %}.
The CDF specifies the probability that {% katex %}i \leq n{% endkatex %} and is given by,

{% katex display %}
P(i\ \leq\ n)=P(n)=\sum_{i=1}^n{p_i},
{% endkatex %}

For a given CDF value, {% katex %}U{% endkatex %}, The equation for {% katex %}P(n){% endkatex %} can always
be inverted by evaluating it for each {% katex %}n{% endkatex %} and
searching for the smallest value of {% katex %}n{% endkatex %} that satisfies,
{% katex %}P(n)\ \geq\ U{% endkatex %}.
It follows that generated samples determined from {% katex %}U \sim \textbf{Uniform}(0, 1){% endkatex %}
will have distribution {% katex %}(1){% endkatex %} since the intervals {% katex %}P(n)-P(n-1) = p_n{% endkatex %}
are uniformly sampled.

Consider the distribution,

{% katex display %}
\left\{\frac{1}{12},\ \frac{1}{12},\ \frac{1}{6},\ \frac{1}{6},\ \frac{1}{12},\ \frac{5}{12} \right\} \ \ \ \ \ (2)
{% endkatex %}
It is shown in the following plot with its CDF. Note that the CDF is a monotonically increasing function.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/inverse_cdf_sampling/discrete_cdf.png&quot;&gt;

A sampler using the Inverse CDF method with target distribution specified in {% katex %}(2){% endkatex %} implemented in
Python is shown below.

```python
import numpy

n = 10000
df = numpy.array([1/12, 1/12, 1/6, 1/6, 1/12, 5/12])
cdf = numpy.cumsum(df)

samples = [numpy.flatnonzero(cdf &gt;= u)[0] for u in numpy.random.rand(n)]
```
The program first stores the CDF computed from the partial sums
{% katex %}P(n){% endkatex %} in an array. Next, CDF samples using
{% katex %}U \sim \textbf{Uniform}(0, 1){% endkatex %} are generated. Finally, for each sampled CDF value,
{% katex %}U{% endkatex %}, the array containing {% katex %}P(n){% endkatex %} is scanned for
the smallest value of {% katex %}n{% endkatex %} where {% katex %}P(n)\ \geq\ U{% endkatex %}. The resulting
values of {% katex %}n{% endkatex %} will have the target distribution {% katex %}(2){% endkatex %}. This is
shown in the figure below.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/inverse_cdf_sampling/discrete_sampled_distribution.png&quot;&gt;

A measure of convergence of the samples to the target distribution can be obtained by comparing the cumulative
moments of the distribution computed from the samples with the target value of the moment computed analytically.
In general for a discrete distribution the first and second moments are given by,

{% katex display %}
\begin{aligned}
\mu &amp; =  \sum_{i=1}^N ip_i\\
\sigma^2 &amp; = \sum_{i=1}^N i^2p_i - \mu^2,
\end{aligned}
{% endkatex %}

In the following two plots the cumulative values of {% katex %}\mu{% endkatex %} and
{% katex %}\sigma{% endkatex %} computed from the samples generated are compared with the target values
using the equations above.
The first shows the convergence of {% katex %}\mu{% endkatex %} and the second the convergence of
{% katex %}\sigma{% endkatex %}. Within only {% katex %}10^3{% endkatex %} samples both
{% katex %}\mu{% endkatex %} and {% katex %}\sigma{% endkatex %} computed from samples is comparable to the
target value and by {% katex %}10^4{% endkatex %} the values are indistinguishable.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/inverse_cdf_sampling/discrete_sampled_mean_convergence.png&quot;&gt;

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/inverse_cdf_sampling/discrete_sampled_sigma_convergence.png&quot;&gt;

The number of operations required for generating samples using Inverse CDF sampling from a discrete
distribution will scale {% katex %}O(N_{samples}N){% endkatex %} where {% katex %}N_{samples}{% endkatex %}
is the desired number of samples and {% katex %}N{% endkatex %} is the number of terms in the discrete distribution.

It is also possible to directly sample distribution {% katex %}(2){% endkatex %} using the `multinomial` sampler from `numpy`,

```python
import numpy

n = 10000
df = numpy.array([1/12, 1/12, 1/6, 1/6, 1/12, 5/12])
samples = numpy.random.multinomial(n, df, size=1)/n
```

## Continuous Distributions

A continuous probability distribution is defined by the [PDF](https://en.wikipedia.org/wiki/Probability_density_function),
{% katex %}f_X(x){% endkatex %}, where {% katex %}f_X(x) \geq 0,\ \forall x{% endkatex %} and
{% katex %}\int_{-\infty}^{\infty} f_X(x) dx = 1{% endkatex %}. The CDF is a monotonically increasing function
that specifies the probability that {% katex %}X\ \leq\ x{% endkatex %}, namely,

{% katex display %}
P(X \leq x) = F_X(x) = \int_{-\infty}^{x} f_X(w) dw.
{% endkatex %}

### Theory

To prove that Inverse CDF sampling works for continuous distributions it must be shown that,

{% katex display %}
P[F_X^{-1}(U)\ \leq\ x] = F_X(x) \ \ \ \ \ (3),
{% endkatex %}

where {% katex %}F_X^{-1}(x){% endkatex %} is the inverse of {% katex %}F_X(x){% endkatex %}
and {% katex %}U \sim \textbf{Uniform}(0, 1){% endkatex %}.

A more general result needed to complete this proof is obtained using a change of variable on a CDF.
If {% katex %}Y=G(X){% endkatex %} is a monotonically increasing invertible function
of {% katex %}X{% endkatex %} it will be shown that,

{% katex display %}
P(X\ \leq\ x) = P(Y\ \leq\ y) = P[G(X)\ \leq\ G(x)]. \ \ \ \ \ (4)
{% endkatex %}

To prove this note that {% katex %}G(x){% endkatex %} is monotonically increasing so the ordering of values is
preserved for all {% katex %}x{% endkatex %},

{% katex display %}
X\ \leq\ x\ \implies\ G(X)\ \leq\ G(x).
{% endkatex %}

Consequently, the order of the integration limits is maintained by the transformation.
Further, since {% katex %}y=G(x){% endkatex %} is invertible,
{% katex %}x = G^{-1}(y){% endkatex %} and {% katex %}dx = (dG^{-1}/dy) dy{% endkatex %}, so

{% katex display %}
\begin{aligned}
P(X\ \leq\ x) &amp; = \int_{-\infty}^{x} f_X(w) dw \\
&amp; = \int_{-\infty}^{y} f_X(G^{-1}(z)) \frac{dG^{-1}}{dz} dz \\
&amp; = \int_{-\infty}^{y} f_Y(z) dz \\
&amp; = P(Y\ \leq\ y) \\
&amp; = P[G(X)\ \leq\ G(x)],
\end{aligned}
{% endkatex %}

where,

{% katex display %}
f_Y(y) = f_X(G^{-1}(y)) \frac{dG^{-1}}{dy}
{% endkatex %}

For completeness consider the case where {% katex %}Y=G(X){% endkatex %} is a monotonically decreasing invertible function
of {% katex %}X{% endkatex %} then,

{% katex display %}
X\ \leq\ x\ \implies\ G(X)\ \geq\ G(x),
{% endkatex %}

it follows that,

{% katex display %}
\begin{aligned}
P(X\ \leq x) &amp; = \int_{-\infty}^{x} f_X(w) dw \\
&amp; = \int_{y}^{\infty} f_X(G^{-1}(z)) \frac{dG^{-1}}{dz} dz \\
&amp; = \int_{y}^{\infty} f_Y(z) dz \\
&amp; = P(Y\ \geq\ y) \\
&amp; = P[G(X)\ \geq\ G(x)] \\
&amp; = 1 - P[G(X)\ \leq\ G(x)]
\end{aligned}
{% endkatex %}

The desired proof of equation {% katex %}(3){% endkatex %} follows from equation {% katex %}(4){% endkatex %}
by noting that {% katex %}U \sim \textbf{Uniform}(0, 1){% endkatex %} so {% katex %}f_U(u) = 1{% endkatex %},

{% katex display %}
\begin{aligned}
P[F_X^{-1}(U)\ \leq\ x] &amp; = P[F_X(F_X^{-1}(U))\ \leq\ F_X(x)] \\
&amp; = P[U\ \leq\ F_X(x)] \\
&amp; = \int_{0}^{F_X(x)} f_U(w) dw \\
&amp; = \int_{0}^{F_X(x)} dw \\
&amp; = F_X(x).
\end{aligned}
{% endkatex %}

### Example

Consider the [Weibull Distribution](https://en.wikipedia.org/wiki/Weibull_distribution). The PDF is
given by,

{% katex display %}
f_X(x; k, \lambda) =
\begin{cases}
\frac{k}{\lambda}\left(\frac{x}{\lambda} \right)^{k-1} e^{-\left(x/\lambda\right)^k} &amp; x\ \geq\ 0 \\
0 &amp; x &lt; 0
\end{cases} \ \ \ \ \ (5)
{% endkatex %}

where {% katex %}k\ &gt;\ 0{% endkatex %} is the shape parameter and {%katex %}\lambda\ &gt;\ 0{% endkatex %} the scale parameter.
The CDF is given by,

{% katex display %}
F_X(x; k, \lambda) =
\begin{cases}
1-e^{\left(\frac{-x}{\lambda}\right)^k} &amp; x\ \geq\ 0 \\
0 &amp; x\ &lt;\ 0.
\end{cases}
{% endkatex %}

The CDF can be inverted to yield,

{% katex display %}
F_X^{-1}(u; k, \lambda) =
\begin{cases}
\lambda\ln\left(\frac{1}{1-u}\right)^{\frac{1}{k}} &amp; 0\ \leq\ u\ \leq 1 \\
0 &amp; u\ &lt;\ 0 \text{ or } u\ &gt;\ 1.
\end{cases}
{% endkatex %}

In the example described here it will be assumed that {% katex %}k=5.0{% endkatex %} and
{% katex %}\lambda=1.0{% endkatex %}. The following plot shows the PDF and CDF using these values.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/inverse_cdf_sampling/weibull_cdf.png&quot;&gt;

The sampler implementation for the continuous case is simpler than for the discrete case.
Just as in the discrete case CDF samples with distribution {% katex %}U \sim \textbf{Uniform}(0, 1){% endkatex %}
are generated. The desired samples with the target {% katex %}\textbf{Weibull}{% endkatex %}
distribution are then computed using the CDF inverse.
Below an implementation of this procedure in Python is given.

```python
import numpy

k = 5.0
λ = 1.0
nsamples = 100000

cdf_inv = lambda u: λ * (numpy.log(1.0/(1.0 - u)))**(1.0/k)
samples = [cdf_inv(u) for u in numpy.random.rand(nsamples)]
```

The following plot compares a histogram of the samples generated by the sampler above and the target
distribution (5). The fit is quite good. The subtle asymmetry of the
{% katex %}\textbf{Weibull}{% endkatex %} distribution is captured.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/inverse_cdf_sampling/weibull_sampled_distribution.png&quot;&gt;

The first and second moments for the {% katex %}\textbf{Weibull}{% endkatex %} distribution are given by,

{% katex display %}
\begin{aligned}
\mu &amp; = \lambda\Gamma\left(1+\frac{1}{k}\right) \\
\sigma^2 &amp; = \lambda^2\left[\Gamma\left(1+\frac{2}{k}\right)-\left(\Gamma\left(1+\frac{1}{k}\right)\right)^2\right],
\end{aligned}
{% endkatex %}

where {% katex %}\Gamma(x){% endkatex %} is the [Gamma function](https://en.wikipedia.org/wiki/Gamma_function).

The following two plots compare the cumulative values of {% katex %}\mu{% endkatex %} and {% katex %}\sigma{% endkatex %}
computed from sampling of the target distribution {% katex %}(5){% endkatex %} with the values from the equations above.
The first shows the convergence of {% katex %}\mu{% endkatex %} and the second the convergence of {% katex %}\sigma{% endkatex %}.
Within only {% katex %}10^3{% endkatex %} samples both {% katex %}\mu{% endkatex %} and {% katex %}\sigma{% endkatex %} computed from
samples are comparable to the target values and by {% katex %}10^4{% endkatex %} the values are indistinguishable.

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/inverse_cdf_sampling/weibull_sampled_mean_convergence.png&quot;&gt;

&lt;img class=&quot;post-image&quot; src=&quot;/assets/posts/inverse_cdf_sampling/weibull_sampled_std_convergence.png&quot;&gt;

### Performance

Any continuous distribution can be sampled by assuming that {% katex %}f_X(x){% endkatex %} can be approximated
by the discrete distribution, {% katex %}\left\{f_X(x_i)\Delta x_i \right\}_N{% endkatex %} for
{% katex %}i=1,2,3,\ldots,N{% endkatex %}, where {% katex %}\Delta x_i=(x_{max}-x_{min})/(N-1){% endkatex %} and
{% katex %}x_i = x_{min}+(i-1)\Delta x_i{% endkatex %}. This method has disadvantages compared to using
Inverse CDF sampling on the continuous distribution. First, a bounded range for the samples must
be assumed when in general the range of the samples can be unbounded while the Inverse CDF method can sample an unbounded range.
Second, the number of operations required for
sampling a discrete distribution scales {% katex %}O(N_{samples}N){% endkatex %} but sampling the
continuous distribution is {% katex %}O(N_{samples}){% endkatex %}.

## Conclusions

Inverse CDF Sampling provides a method for obtaining samples from a known target distribution using
a sampler with a {% katex %}\textbf{Uniform}(0, 1){% endkatex %} distribution that requires the
target distribution be invertible. Algorithms for both the discrete and continuous cases were
analytically proven to produce samples with distributions defined by the CDF.
Example implementations of the algorithms for both distribution cases were developed.
Samples produced by the algorithms for example target distributions were favorably compared. Mean and standard deviations computed from generated samples converged to the target distribution values
in {% katex %}O(10^3){% endkatex %} samples.
The continuous sampling algorithm was shown to be more performant than the discrete version.
The discrete version required {% katex %}O(N_{samples}N){% endkatex %}
operations while the continuous version required {% katex %}O(N_{samples}){% endkatex %} operations.</content><author><name>Troy Stribling</name></author><summary type="html">Inverse CDF sampling is a method for obtaining samples from both discrete and continuous probability distributions that requires the CDF to be invertible. The method assumes values of the CDF are Uniform random variables on [0,1][0, 1][0,1]. CDF values are generated and used as input into the inverted CDF to obtain samples with the distribution defined by the CDF.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/posts/inverse_cdf_sampling/weibull_sampled_distribution.png" /></entry></feed>